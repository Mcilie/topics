{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "from multiprocessing.sharedctypes import RawArray\n",
    "\n",
    "import torch\n",
    "import json\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from pqdm.processes import pqdm\n",
    "from IPython.core.display import HTML\n",
    "from scipy.special import softmax\n",
    "from scipy.spatial.distance import jensenshannon, cdist\n",
    "from kneed import KneeLocator\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "sys.path.append(\"../soup_nuts/models/dvae/\")\n",
    "\n",
    "from dvae import data_iterator, CollapsedMultinomial, DVAE\n",
    "from utils import load_sparse, compute_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path):\n",
    "    with open(path) as infile:\n",
    "        return json.load(infile)\n",
    "\n",
    "def load_yaml(path):\n",
    "    with open(path) as infile:\n",
    "        return yaml.load(infile, Loader=yaml.FullLoader)\n",
    "\n",
    "def load_text(path):\n",
    "    with open(path) as infile:\n",
    "        return [text.strip().split(\" \") for text in infile]\n",
    "\n",
    "def save_json(obj, path):\n",
    "    with open(path, 'w') as outfile:\n",
    "        return json.dump(obj, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_est_to_words(topic_words, inv_vocab, n=10):\n",
    "    return [inv_vocab[idx] for idx in (-topic_words).argsort()[:n]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_CUDA_AVAILABLE = torch.cuda.is_available()\n",
    "_data_cache = {}\n",
    "\n",
    "def load_mallet_estimates(fpath):\n",
    "    \"\"\"\n",
    "    Load the doc-topic and topic-word estimates from our mallet output folder\n",
    "    \"\"\"\n",
    "    topic_word = np.load(fpath / \"beta.npy\")\n",
    "    #topic_word = None \n",
    "    # Load the standard mallet document-topic estimate as a numpy matrix\n",
    "    with open(fpath / \"doctopics.txt\") as infile:\n",
    "        doc_topic = np.array([\n",
    "            [float(x) for x in line.strip().split(\"\\t\")[2:]]\n",
    "            for line in infile\n",
    "        ])\n",
    "        \n",
    "        \n",
    "    return topic_word, doc_topic, None # TODO: is loss available in mallet?\n",
    "\n",
    "def load_dvae_estimates(fpath): \n",
    "    \"\"\"\n",
    "    Loads the dvae model and gets the topic word distribution, then instantiates\n",
    "    the encoder portion and does a forward pass to get the \n",
    "    \"\"\"\n",
    "    # get the topic word\n",
    "    device = torch.device(\"cuda\") if _CUDA_AVAILABLE else torch.device(\"cpu\")\n",
    "\n",
    "    state_dict = torch.load(fpath / \"model.pt\", map_location=device)\n",
    "    beta = state_dict[\"params\"][\"decoder$$$eta_layer.weight\"]\n",
    "    topic_word = torch.transpose(beta, 0, 1).cpu().detach().numpy()\n",
    "\n",
    "    # do a forward pass to get the document topics\n",
    "    # first instantiate the model and load in the params\n",
    "    config = load_yaml(fpath / \"config.yml\")\n",
    "    \n",
    "    dvae = DVAE(\n",
    "        vocab_size=topic_word.shape[1],\n",
    "        num_topics=config[\"num_topics\"],\n",
    "        alpha_prior=config[\"alpha_prior\"],\n",
    "        embeddings_dim=config[\"encoder_embeddings_dim\"],\n",
    "        hidden_dim=config[\"encoder_hidden_dim\"],\n",
    "        dropout=config[\"dropout\"],\n",
    "        cuda=_CUDA_AVAILABLE,\n",
    "    )\n",
    "    dvae_dict = {\n",
    "        k.replace(\"$$$\", \".\"): v\n",
    "        for k, v in state_dict['params'].items()\n",
    "    }\n",
    "    dvae.load_state_dict(dvae_dict, strict=False)\n",
    "    dvae.eval()\n",
    "    turn_off_bn = 1 * (config[\"epochs_to_anneal_bn\"] > 0) # 0 means use BN, > 0 means no BN\n",
    "\n",
    "    # then load the data for the forward pass\n",
    "    data_fpath = Path(config[\"input_dir\"], config[\"train_path\"])\n",
    "    if data_fpath not in _data_cache:\n",
    "        data = load_sparse(data_fpath).astype(np.float32)\n",
    "        _data_cache[data_fpath] = data\n",
    "    else:\n",
    "        data = _data_cache[data_fpath]\n",
    "    \n",
    "    batch_size = config[\"batch_size\"]\n",
    "    epochs = config[\"num_epochs\"]\n",
    "    n = data.shape[0]\n",
    "    train_batches = n // batch_size + 1\n",
    "\n",
    "    # do the forward pass and collect outputs in an array\n",
    "    doc_topic = np.zeros((n, config[\"num_topics\"]), dtype=np.float32)\n",
    "    losses = np.zeros(n, dtype=np.float32)\n",
    "    for i, x_batch in enumerate(data_iterator(data, batch_size, train_batches)):\n",
    "        x_batch = x_batch.to(device)\n",
    "        doc_topic_batch = dvae.encoder(x_batch)\n",
    "        doc_topic_batch = doc_topic_batch / doc_topic_batch.sum(1, keepdims=True)\n",
    "        x_recon = dvae.decoder(doc_topic_batch, bn_annealing_factor=turn_off_bn)\n",
    "        loss_batch = -CollapsedMultinomial(1, probs=x_recon).log_prob(x_batch)\n",
    "\n",
    "        doc_topic[i * batch_size:(i + 1) * batch_size] = doc_topic_batch.detach().cpu().numpy().astype(np.float32)\n",
    "        losses[i * batch_size:(i + 1) * batch_size] = loss_batch.detach().cpu().numpy().astype(np.float32)\n",
    "    return topic_word, doc_topic, losses\n",
    "\n",
    "\n",
    "def load_etm_estimates(fpath):\n",
    "    \"\"\"\n",
    "    Load the ETM estimates from a model\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def load_estimates(fpath, model_type):\n",
    "    if model_type == \"dvae\":\n",
    "        return load_dvae_estimates(fpath)\n",
    "    if model_type == \"mallet\":\n",
    "        return load_mallet_estimates(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collect the runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roughly 7 GB RAM for k=100\n",
    "def get_estimates_over_runs(run_paths, overlap_words, exclude_dups=False):\n",
    "    doc_topics, topic_words, duplicates = [], [], [] # TODO: change to 3d tensors\n",
    "    for i, (p, model_type) in enumerate(tqdm(run_paths)):\n",
    "        t, d, l = load_estimates(p, model_type=model_type)\n",
    "        \n",
    "        # located duplicated topics\n",
    "        sorted_t = np.sort((-t).argsort(axis=1)[:, :overlap_words], axis=1)\n",
    "        counted_topics = Counter([tuple(t_) for t_ in sorted_t])\n",
    "        if exclude_dups and max(counted_topics.values()) > 1:\n",
    "            continue\n",
    "        doc_topics.append(d)\n",
    "        topic_words.append(t)\n",
    "        duplicates.append(sum(c > 1 for c in counted_topics.values()))\n",
    "\n",
    "    return doc_topics, topic_words, duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### takes relatively longer to run $\\downarrow$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_dir = \"../runs/outputs/url_partisanship_data\"\n",
    "run_dir = \"../runs/outputs/full-mindf_power_law-maxdf_0.9\"\n",
    "dataset = 'nytimes' #'url_partisan'\n",
    "\n",
    "mallet_paths = [\n",
    "    (p.parent, \"mallet\")\n",
    "    for p in Path(run_dir).glob(\"**/mallet-with-beta/**/doctopics.txt\")\n",
    "    if dataset in str(p)\n",
    "]\n",
    "dvae_paths = [\n",
    "    (p.parent, \"dvae\") for p in Path(run_dir).glob(\"**/dvae/**/model.pt\")\n",
    "    if dataset in str(p)\n",
    "]\n",
    "\n",
    "# should be independent of the model\n",
    "config = load_yaml(dvae_paths[0][0] / \"config.yml\")\n",
    "data = load_sparse(Path(config[\"input_dir\"], \"train.dtm.npz\"))\n",
    "vocab = load_json(Path(config[\"input_dir\"], \"vocab.json\"))\n",
    "inv_vocab = {v: k for k, v in vocab.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_coarse = np.load(Path(config[\"input_dir\"], \"train.labels.coarse.npy\"))\n",
    "labels_fine = np.load(Path(config[\"input_dir\"], \"train.labels.fine.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dvae_paths = dvae_paths\n",
    "# mallet_paths = mallet_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82, 84)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dvae_paths), len(mallet_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_topics = sorted(set(int(re.search(\"k-([0-9]+)\", str(p)).group(1)) for p in dvae_paths))\n",
    "num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topic_words = 15\n",
    "overlap_words = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gather the betas and thetas for all the mallet and numpy runs $\\downarrow$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On k=50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d7c0df7098472f96bf89be43b05715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17455/2649455796.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mruns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdvae_paths_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdvae_paths_k\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mdoc_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduplicates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_estimates_over_runs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdvae_paths_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverlap_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mestimates_dvae\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"doc_topics\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdoc_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"topic_words\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtopic_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"duplicates\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mduplicates\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_17455/2545229958.py\u001b[0m in \u001b[0;36mget_estimates_over_runs\u001b[0;34m(run_paths, overlap_words, exclude_dups)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdoc_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduplicates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# TODO: change to 3d tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_estimates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# located duplicated topics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_17455/2817226110.py\u001b[0m in \u001b[0;36mload_estimates\u001b[0;34m(fpath, model_type)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_estimates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"dvae\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_dvae_estimates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mallet\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_mallet_estimates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_17455/2817226110.py\u001b[0m in \u001b[0;36mload_dvae_estimates\u001b[0;34m(fpath)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mdoc_topic_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mdoc_topic_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc_topic_batch\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdoc_topic_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mx_recon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_topic_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbn_annealing_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mturn_off_bn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mloss_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mCollapsedMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_recon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/.conda/envs/cluster_ranking/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/topic-preprocessing/analysis/../soup_nuts/models/dvae/dvae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z, bn_annealing_factor)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbn_annealing_factor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0meta_bn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta_bn_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/.conda/envs/cluster_ranking/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/.conda/envs/cluster_ranking/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/.conda/envs/cluster_ranking/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "estimates_dvae, estimates_mallet = {}, {}\n",
    "for k in num_topics:\n",
    "    print(f\"On k={k}\")\n",
    "\n",
    "    dvae_paths_k = [p for p in dvae_paths if f'k-{k}/' in str(p[0])]\n",
    "    runs = len(dvae_paths_k)\n",
    "    if dvae_paths_k:\n",
    "        doc_topics, topic_words, duplicates = get_estimates_over_runs(dvae_paths_k, overlap_words, exclude_dups=False)\n",
    "        estimates_dvae[k] = {\"doc_topics\": doc_topics, \"topic_words\": topic_words, \"duplicates\": duplicates}\n",
    "    \n",
    "    mallet_paths_k = [p for p in mallet_paths if f'k-{k}/' in str(p[0])]\n",
    "    if mallet_paths_k:\n",
    "        doc_topics, topic_words, duplicates = get_estimates_over_runs(mallet_paths_k, overlap_words, exclude_dups=False)\n",
    "        estimates_mallet[k] = {\"doc_topics\": doc_topics, \"topic_words\": topic_words, \"duplicates\": duplicates}\n",
    "\n",
    "with open(f\"dvae-{dataset}-estimates.pkl\", \"wb\") as outfile:\n",
    "    pickle.dump(estimates_dvae, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the \"user labels\" for the documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topics = estimates_dvae[50]['doc_topics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_labels_dvae = {}\n",
    "for document_index in range(len(doc_topics)) : \n",
    "    user_labels = np.argmax(doc_topics[document_index], axis=1) \n",
    "    user_labels_dvae[document_index] = user_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([34, 34, 34, ..., 34, 39, 34]),\n",
       " 1: array([20, 20, 20, ..., 20, 20, 20]),\n",
       " 2: array([21, 40, 21, ..., 40, 21, 40]),\n",
       " 3: array([21, 21, 21, ..., 31, 21, 21]),\n",
       " 4: array([15, 46, 15, ..., 15, 24, 15]),\n",
       " 5: array([26, 26, 26, ..., 26, 26, 26]),\n",
       " 6: array([20, 20, 20, ..., 38, 20, 20]),\n",
       " 7: array([26, 27, 46, ..., 27, 46, 26]),\n",
       " 8: array([38, 31, 26, ..., 31, 38, 31]),\n",
       " 9: array([20, 38, 38, ..., 38, 20, 38]),\n",
       " 10: array([29,  8, 29, ...,  0, 29,  8]),\n",
       " 11: array([ 5, 47,  5, ..., 47,  5, 47]),\n",
       " 12: array([38, 34, 30, ..., 34, 19, 34]),\n",
       " 13: array([29, 27, 29, ..., 27, 29, 27]),\n",
       " 14: array([42, 20, 20, ..., 20, 42, 20]),\n",
       " 15: array([39, 34, 39, ..., 34, 39, 34]),\n",
       " 16: array([46, 46, 46, ..., 46, 46, 21]),\n",
       " 17: array([31, 21, 31, ..., 21, 31, 21]),\n",
       " 18: array([29, 29, 29, ..., 29, 29, 29]),\n",
       " 19: array([31, 31, 31, ..., 10, 31, 31]),\n",
       " 20: array([26,  4, 26, ..., 27, 26, 27]),\n",
       " 21: array([21,  0, 21, ..., 33, 20,  0]),\n",
       " 22: array([42, 16, 42, ..., 16, 42, 16]),\n",
       " 23: array([26, 31, 26, ..., 31, 26, 31]),\n",
       " 24: array([16, 38, 16, ..., 16, 16, 38]),\n",
       " 25: array([ 4, 26, 36, ..., 26, 36, 26]),\n",
       " 26: array([38, 38, 38, ..., 38, 38, 38]),\n",
       " 27: array([47, 47, 47, ..., 47, 12, 47]),\n",
       " 28: array([39, 38, 17, ..., 38, 39, 38]),\n",
       " 29: array([42, 16, 42, ..., 38, 42, 38]),\n",
       " 30: array([21, 27, 21, ..., 27, 21, 27]),\n",
       " 31: array([ 0,  0,  0, ...,  0, 29,  0]),\n",
       " 32: array([27, 27, 27, ..., 27,  7, 27]),\n",
       " 33: array([16, 42, 16, ..., 16, 16, 16]),\n",
       " 34: array([12,  0, 12, ...,  0, 12,  0]),\n",
       " 35: array([27, 46, 27, ..., 46, 27, 46]),\n",
       " 36: array([27,  0, 27, ...,  0, 27,  0]),\n",
       " 37: array([26, 21, 26, ..., 31, 26, 31]),\n",
       " 38: array([31, 21, 31, ..., 21, 31, 21]),\n",
       " 39: array([21,  0, 21, ...,  0, 21,  0]),\n",
       " 40: array([46, 26, 46, ..., 31, 46, 26]),\n",
       " 41: array([ 7,  7,  7, ..., 31,  7, 31]),\n",
       " 42: array([12,  5, 12, ...,  5, 12,  5]),\n",
       " 43: array([16, 20, 38, ..., 20, 16, 20]),\n",
       " 44: array([37, 37, 37, ..., 37, 37, 37]),\n",
       " 45: array([38, 42, 38, ..., 42, 38, 42]),\n",
       " 46: array([38, 27, 38, ..., 27, 38, 27]),\n",
       " 47: array([37, 47, 37, ..., 47, 37, 47]),\n",
       " 48: array([5, 8, 5, ..., 8, 5, 8]),\n",
       " 49: array([38, 16, 38, ..., 16, 38, 16]),\n",
       " 50: array([34, 44, 34, ..., 44, 34, 44]),\n",
       " 51: array([17, 17, 17, ..., 26, 17, 26]),\n",
       " 52: array([35, 38, 35, ..., 38, 30, 38]),\n",
       " 53: array([47, 47, 47, ..., 47, 47, 47]),\n",
       " 54: array([42, 20, 42, ..., 20, 42, 20]),\n",
       " 55: array([12, 27, 12, ..., 27,  0, 27]),\n",
       " 56: array([26, 27, 26, ...,  4, 26,  4]),\n",
       " 57: array([43, 33, 43, ..., 33, 43, 33]),\n",
       " 58: array([16, 20, 16, ..., 16, 16, 20]),\n",
       " 59: array([34, 44, 34, ..., 34, 34, 39]),\n",
       " 60: array([31, 31, 31, ..., 31, 31, 31]),\n",
       " 61: array([21, 27, 21, ..., 27, 44, 27]),\n",
       " 62: array([39, 39, 39, ..., 34, 39, 39]),\n",
       " 63: array([31, 31, 31, ..., 31, 31, 31]),\n",
       " 64: array([0, 0, 0, ..., 0, 0, 0]),\n",
       " 65: array([34, 34, 34, ..., 34, 34, 34]),\n",
       " 66: array([46, 26, 46, ..., 26, 46, 26]),\n",
       " 67: array([ 0, 27,  0, ..., 27,  0, 27]),\n",
       " 68: array([38, 31, 38, ..., 31, 38, 31]),\n",
       " 69: array([31, 31, 26, ..., 31, 26, 31]),\n",
       " 70: array([38, 38, 38, ..., 38, 38, 38]),\n",
       " 71: array([26, 26, 26, ..., 26, 26, 26]),\n",
       " 72: array([ 8, 27,  8, ..., 27,  8, 27]),\n",
       " 73: array([26, 17, 46, ..., 36, 26, 36]),\n",
       " 74: array([ 7,  7, 21, ...,  7, 21,  7]),\n",
       " 75: array([0, 8, 0, ..., 8, 0, 0]),\n",
       " 76: array([31, 21, 31, ..., 21, 31, 21]),\n",
       " 77: array([26,  4, 26, ...,  4, 26,  4]),\n",
       " 78: array([27,  0, 27, ...,  0, 27,  0]),\n",
       " 79: array([29, 29, 12, ..., 29, 37, 29]),\n",
       " 80: array([ 0,  8,  0, ...,  8, 37,  8]),\n",
       " 81: array([ 5, 47,  5, ..., 27,  5, 27])}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_labels_dvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topics_mallet = estimates_mallet[50]['doc_topics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_labels_mallet = {}\n",
    "for document_index in range(len(doc_topics_mallet)) : \n",
    "    user_labels = np.argmax(doc_topics_mallet[document_index], axis=1) \n",
    "    user_labels_mallet[document_index] = user_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([28, 10, 28, ..., 10, 28, 10]),\n",
       " 1: array([41, 45, 41, ..., 45, 41, 45]),\n",
       " 2: array([10, 14, 10, ..., 14, 10, 14]),\n",
       " 3: array([46, 46, 46, ..., 46, 46, 46]),\n",
       " 4: array([18, 18, 18, ..., 18, 18, 18]),\n",
       " 5: array([41, 45, 41, ..., 45, 41, 45]),\n",
       " 6: array([6, 6, 6, ..., 6, 6, 6]),\n",
       " 7: array([6, 6, 6, ..., 6, 6, 6]),\n",
       " 8: array([28, 10, 28, ..., 10, 28, 10]),\n",
       " 9: array([18, 18, 18, ..., 18, 18, 18]),\n",
       " 10: array([28, 10, 28, ..., 10, 28, 10]),\n",
       " 11: array([17, 14, 17, ..., 14, 17, 10]),\n",
       " 12: array([48, 18, 48, ..., 18, 48, 18]),\n",
       " 13: array([18, 37, 31, ..., 18, 18, 31]),\n",
       " 14: array([20, 20, 20, ..., 20, 20, 20]),\n",
       " 15: array([21, 21,  0, ..., 21,  0, 21]),\n",
       " 16: array([18, 18, 18, ..., 18, 18, 18]),\n",
       " 17: array([ 3, 19,  3, ..., 19,  3, 19]),\n",
       " 18: array([37, 37, 37, ..., 37, 37, 37]),\n",
       " 19: array([10, 14, 10, ..., 14, 10, 14]),\n",
       " 20: array([6, 6, 6, ..., 6, 6, 6]),\n",
       " 21: array([17, 17, 17, ..., 17, 17, 17]),\n",
       " 22: array([10, 10, 10, ..., 10, 10, 10]),\n",
       " 23: array([35, 32, 18, ..., 32, 31, 32]),\n",
       " 24: array([17, 17, 17, ..., 17, 17, 17]),\n",
       " 25: array([18, 18, 18, ..., 18, 18, 18]),\n",
       " 26: array([14, 14, 14, ..., 14, 14, 14]),\n",
       " 27: array([10, 10, 10, ..., 10, 10, 10]),\n",
       " 28: array([33, 33, 33, ..., 33, 33, 33]),\n",
       " 29: array([10, 10, 10, ..., 10, 10, 10]),\n",
       " 30: array([46,  5, 46, ...,  5, 46,  5]),\n",
       " 31: array([6, 6, 6, ..., 6, 6, 6]),\n",
       " 32: array([10, 10, 10, ..., 10, 10, 10]),\n",
       " 33: array([10, 10, 10, ..., 10, 10, 10]),\n",
       " 34: array([17, 17, 17, ..., 17, 17, 17]),\n",
       " 35: array([6, 6, 6, ..., 6, 6, 6]),\n",
       " 36: array([10, 10, 10, ..., 10, 10, 10]),\n",
       " 37: array([17, 17, 17, ..., 17, 17, 17]),\n",
       " 38: array([6, 6, 6, ..., 6, 6, 6]),\n",
       " 39: array([18, 18, 18, ..., 18, 18, 18]),\n",
       " 40: array([37, 37, 37, ..., 37, 37, 37]),\n",
       " 41: array([33, 33, 33, ..., 33, 33, 33]),\n",
       " 42: array([17, 17, 17, ..., 17, 17, 17]),\n",
       " 43: array([33, 33, 33, ..., 33, 33, 33]),\n",
       " 44: array([32, 32, 32, ..., 32, 32, 32]),\n",
       " 45: array([17, 14, 17, ..., 14, 17, 14]),\n",
       " 46: array([6, 6, 6, ..., 6, 6, 6]),\n",
       " 47: array([18, 18, 18, ..., 18, 18, 18]),\n",
       " 48: array([18, 18, 18, ..., 18, 18, 18]),\n",
       " 49: array([10, 10, 10, ..., 10, 10, 10]),\n",
       " 50: array([46, 46, 46, ..., 46, 46, 46]),\n",
       " 51: array([18, 18, 18, ..., 18, 18, 18]),\n",
       " 52: array([10, 10, 10, ..., 10, 10, 10]),\n",
       " 53: array([43, 43, 43, ..., 43, 43, 43]),\n",
       " 54: array([41, 45, 41, ..., 45, 41, 45]),\n",
       " 55: array([14, 14, 14, ..., 14, 14, 14]),\n",
       " 56: array([18, 18, 18, ..., 18, 18, 18]),\n",
       " 57: array([31, 18, 31, ..., 18, 31, 18]),\n",
       " 58: array([37, 37, 37, ..., 37, 37, 37]),\n",
       " 59: array([47, 47, 47, ..., 47, 47, 47]),\n",
       " 60: array([6, 6, 6, ..., 6, 6, 6]),\n",
       " 61: array([ 3, 19,  3, ..., 19,  3, 19]),\n",
       " 62: array([21,  6, 21, ..., 21,  0, 21]),\n",
       " 63: array([18, 45, 18, ..., 45, 18, 45]),\n",
       " 64: array([35, 32, 18, ..., 32, 31, 32]),\n",
       " 65: array([6, 6, 6, ..., 6, 6, 6]),\n",
       " 66: array([18, 18, 18, ..., 18, 18, 18]),\n",
       " 67: array([18, 41, 18, ..., 41, 18, 41]),\n",
       " 68: array([10, 10,  6, ...,  6,  6, 10]),\n",
       " 69: array([10, 10, 10, ..., 10, 10, 10]),\n",
       " 70: array([18, 18, 18, ..., 18, 18, 18]),\n",
       " 71: array([33, 39, 33, ..., 39, 33, 39]),\n",
       " 72: array([28, 28, 28, ..., 28, 28, 28]),\n",
       " 73: array([41, 45, 41, ..., 45, 41, 45]),\n",
       " 74: array([33, 39, 33, ..., 39, 33, 39]),\n",
       " 75: array([43, 43, 43, ..., 43, 43, 43]),\n",
       " 76: array([18, 18, 18, ..., 18, 18, 18]),\n",
       " 77: array([ 3, 19,  3, ..., 19,  3, 19]),\n",
       " 78: array([18, 18, 18, ..., 18, 18, 18]),\n",
       " 79: array([46, 46, 46, ..., 46, 46, 46]),\n",
       " 80: array([17, 17, 17, ..., 17, 17, 17]),\n",
       " 81: array([18, 18, 18, ..., 18, 18, 18]),\n",
       " 82: array([18, 18, 18, ..., 18, 18, 18]),\n",
       " 83: array([10, 10, 10, ..., 10, 10, 10])}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_labels_mallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]),\n",
       " array([ 2036,  4390,  6060,  7542,  5712,  2903,  4754,  4596,  4961,\n",
       "         4274,  4789,  4424,  3732,  4219,  7316,  5351,  5121,  8968,\n",
       "        18312,  8332,  3944,  2136,  2996,  5380,  8896,  3479,  4283,\n",
       "        15141,  3005,  3310,  4952, 10375,  2682, 11379,  6229, 10150,\n",
       "         8651,  2753,  3072,  6140,  2899,  3182,  3381,  1749,  4530,\n",
       "         4371,  4781,  4441,  1507,  4784]))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(user_labels_mallet[4], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purity(user_labels, gold_labels): \n",
    "    \"\"\"\n",
    "    Calculates the Purity metric as described in https://aclanthology.org/P16-1110/\n",
    "    \"ALTO: Active Learning with Topic Overviews for Speeding Label Induction and Document Labeling\"\n",
    "    \n",
    "    For sanity check - The purity of any two user labels should be 1\n",
    "    \"\"\"\n",
    "    assert len(user_labels) == len(gold_labels)\n",
    "    \n",
    "    user_label_clusters = defaultdict(list)\n",
    "    for doc_index, label in enumerate(user_labels): \n",
    "        user_label_clusters[label].append(doc_index) \n",
    "    \n",
    "    # main step : \n",
    "    purity_sum = 0 \n",
    "    for cluster_label, user_document_set in user_label_clusters.items(): \n",
    "        gold_label_distribution = Counter([gold_labels[i] for i in  user_document_set])\n",
    "        most_frequent_cluster_freq = sorted(gold_label_distribution.items(), key = lambda x:x[1], reverse=True)[0][1]\n",
    "        purity_sum += most_frequent_cluster_freq\n",
    "        \n",
    "    return purity_sum/len(user_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import rand_score, normalized_mutual_info_score , adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_labels_dvae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17455/1059553365.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpurity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_labels_dvae\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_labels_dvae\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'user_labels_dvae' is not defined"
     ]
    }
   ],
   "source": [
    "purity(user_labels_dvae[1], user_labels_dvae[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9700630406253116"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_score(user_labels_dvae[1], user_labels_dvae[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6056388595988299"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_mutual_info_score(user_labels_dvae[1], user_labels_dvae[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = (purity, rand_score, normalized_mutual_info_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2877, 31)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Counter(labels_fine)), len(Counter(labels_coarse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_labels_dvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(user_labels_list, model) :\n",
    "    stuff = []\n",
    "    for index in range(len(user_labels_list)) : \n",
    "        user_labels = user_labels_list[index]\n",
    "\n",
    "        d = {\n",
    "        \"model\": f\"{model}\",\n",
    "        \"index\": f\"{model}_{index}\",\n",
    "        \"rand_fine\" : adjusted_rand_score(user_labels, labels_fine), \n",
    "        \"rand_coarse\" : adjusted_rand_score(user_labels, labels_coarse), \n",
    "        \"nmi_fine\": normalized_mutual_info_score(user_labels, labels_fine),\n",
    "        \"nmi_coarse\": normalized_mutual_info_score(user_labels, labels_coarse),\n",
    "        \"purity_fine\": purity(user_labels, labels_fine),\n",
    "        \"purity_coarse\": purity(user_labels, labels_coarse)\n",
    "        }\n",
    "\n",
    "    #     print(f\"Model {index}\\n\\t Rand Scores: {rand_coarse:.3f},{rand_fine:.3f} \\\n",
    "    #              \\tNMI Scores: {nmi_coarse:.3f},{nmi_fine:.3f} \\\n",
    "    #              \\tPurity Scores: {purity_coarse:.3f},{purity_fine:.3f}\")\n",
    "\n",
    "        stuff.append(d)\n",
    "        \n",
    "    df = pd.DataFrame(stuff)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvae = get_dataframe(user_labels_dvae, \"dvae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>index</th>\n",
       "      <th>rand_fine</th>\n",
       "      <th>rand_coarse</th>\n",
       "      <th>nmi_fine</th>\n",
       "      <th>nmi_coarse</th>\n",
       "      <th>purity_fine</th>\n",
       "      <th>purity_coarse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dvae</td>\n",
       "      <td>dvae_0</td>\n",
       "      <td>0.316941</td>\n",
       "      <td>0.156117</td>\n",
       "      <td>0.446646</td>\n",
       "      <td>0.364865</td>\n",
       "      <td>0.321519</td>\n",
       "      <td>0.515589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dvae</td>\n",
       "      <td>dvae_1</td>\n",
       "      <td>0.394868</td>\n",
       "      <td>0.173889</td>\n",
       "      <td>0.467502</td>\n",
       "      <td>0.376476</td>\n",
       "      <td>0.333767</td>\n",
       "      <td>0.535815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dvae</td>\n",
       "      <td>dvae_2</td>\n",
       "      <td>0.257027</td>\n",
       "      <td>0.142913</td>\n",
       "      <td>0.466106</td>\n",
       "      <td>0.387155</td>\n",
       "      <td>0.353181</td>\n",
       "      <td>0.550420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dvae</td>\n",
       "      <td>dvae_3</td>\n",
       "      <td>0.350939</td>\n",
       "      <td>0.179454</td>\n",
       "      <td>0.484734</td>\n",
       "      <td>0.383542</td>\n",
       "      <td>0.354966</td>\n",
       "      <td>0.545049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dvae</td>\n",
       "      <td>dvae_4</td>\n",
       "      <td>0.282265</td>\n",
       "      <td>0.143717</td>\n",
       "      <td>0.392989</td>\n",
       "      <td>0.322242</td>\n",
       "      <td>0.312131</td>\n",
       "      <td>0.507714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model   index  rand_fine  rand_coarse  nmi_fine  nmi_coarse  purity_fine  \\\n",
       "0  dvae  dvae_0   0.316941     0.156117  0.446646    0.364865     0.321519   \n",
       "1  dvae  dvae_1   0.394868     0.173889  0.467502    0.376476     0.333767   \n",
       "2  dvae  dvae_2   0.257027     0.142913  0.466106    0.387155     0.353181   \n",
       "3  dvae  dvae_3   0.350939     0.179454  0.484734    0.383542     0.354966   \n",
       "4  dvae  dvae_4   0.282265     0.143717  0.392989    0.322242     0.312131   \n",
       "\n",
       "   purity_coarse  \n",
       "0       0.515589  \n",
       "1       0.535815  \n",
       "2       0.550420  \n",
       "3       0.545049  \n",
       "4       0.507714  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dvae.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet = get_dataframe(user_labels_mallet, \"mallet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>index</th>\n",
       "      <th>rand_fine</th>\n",
       "      <th>rand_coarse</th>\n",
       "      <th>nmi_fine</th>\n",
       "      <th>nmi_coarse</th>\n",
       "      <th>purity_fine</th>\n",
       "      <th>purity_coarse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mallet</td>\n",
       "      <td>mallet_0</td>\n",
       "      <td>0.350499</td>\n",
       "      <td>0.182586</td>\n",
       "      <td>0.455902</td>\n",
       "      <td>0.371386</td>\n",
       "      <td>0.326765</td>\n",
       "      <td>0.545684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mallet</td>\n",
       "      <td>mallet_1</td>\n",
       "      <td>0.343367</td>\n",
       "      <td>0.178253</td>\n",
       "      <td>0.459810</td>\n",
       "      <td>0.370611</td>\n",
       "      <td>0.333029</td>\n",
       "      <td>0.543213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mallet</td>\n",
       "      <td>mallet_2</td>\n",
       "      <td>0.317573</td>\n",
       "      <td>0.154060</td>\n",
       "      <td>0.456268</td>\n",
       "      <td>0.374088</td>\n",
       "      <td>0.332316</td>\n",
       "      <td>0.551709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mallet</td>\n",
       "      <td>mallet_3</td>\n",
       "      <td>0.407702</td>\n",
       "      <td>0.190262</td>\n",
       "      <td>0.468044</td>\n",
       "      <td>0.377941</td>\n",
       "      <td>0.342655</td>\n",
       "      <td>0.552440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mallet</td>\n",
       "      <td>mallet_4</td>\n",
       "      <td>0.422896</td>\n",
       "      <td>0.194206</td>\n",
       "      <td>0.468109</td>\n",
       "      <td>0.370147</td>\n",
       "      <td>0.348897</td>\n",
       "      <td>0.541473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model     index  rand_fine  rand_coarse  nmi_fine  nmi_coarse  \\\n",
       "0  mallet  mallet_0   0.350499     0.182586  0.455902    0.371386   \n",
       "1  mallet  mallet_1   0.343367     0.178253  0.459810    0.370611   \n",
       "2  mallet  mallet_2   0.317573     0.154060  0.456268    0.374088   \n",
       "3  mallet  mallet_3   0.407702     0.190262  0.468044    0.377941   \n",
       "4  mallet  mallet_4   0.422896     0.194206  0.468109    0.370147   \n",
       "\n",
       "   purity_fine  purity_coarse  \n",
       "0     0.326765       0.545684  \n",
       "1     0.333029       0.543213  \n",
       "2     0.332316       0.551709  \n",
       "3     0.342655       0.552440  \n",
       "4     0.348897       0.541473  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mallet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([dvae, mallet], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 8)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>index</th>\n",
       "      <th>rand_fine</th>\n",
       "      <th>rand_coarse</th>\n",
       "      <th>nmi_fine</th>\n",
       "      <th>nmi_coarse</th>\n",
       "      <th>purity_fine</th>\n",
       "      <th>purity_coarse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dvae</td>\n",
       "      <td>dvae_0</td>\n",
       "      <td>0.316941</td>\n",
       "      <td>0.156117</td>\n",
       "      <td>0.446646</td>\n",
       "      <td>0.364865</td>\n",
       "      <td>0.321519</td>\n",
       "      <td>0.515589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dvae</td>\n",
       "      <td>dvae_1</td>\n",
       "      <td>0.394868</td>\n",
       "      <td>0.173889</td>\n",
       "      <td>0.467502</td>\n",
       "      <td>0.376476</td>\n",
       "      <td>0.333767</td>\n",
       "      <td>0.535815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dvae</td>\n",
       "      <td>dvae_2</td>\n",
       "      <td>0.257027</td>\n",
       "      <td>0.142913</td>\n",
       "      <td>0.466106</td>\n",
       "      <td>0.387155</td>\n",
       "      <td>0.353181</td>\n",
       "      <td>0.550420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dvae</td>\n",
       "      <td>dvae_3</td>\n",
       "      <td>0.350939</td>\n",
       "      <td>0.179454</td>\n",
       "      <td>0.484734</td>\n",
       "      <td>0.383542</td>\n",
       "      <td>0.354966</td>\n",
       "      <td>0.545049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dvae</td>\n",
       "      <td>dvae_4</td>\n",
       "      <td>0.282265</td>\n",
       "      <td>0.143717</td>\n",
       "      <td>0.392989</td>\n",
       "      <td>0.322242</td>\n",
       "      <td>0.312131</td>\n",
       "      <td>0.507714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model   index  rand_fine  rand_coarse  nmi_fine  nmi_coarse  purity_fine  \\\n",
       "0  dvae  dvae_0   0.316941     0.156117  0.446646    0.364865     0.321519   \n",
       "1  dvae  dvae_1   0.394868     0.173889  0.467502    0.376476     0.333767   \n",
       "2  dvae  dvae_2   0.257027     0.142913  0.466106    0.387155     0.353181   \n",
       "3  dvae  dvae_3   0.350939     0.179454  0.484734    0.383542     0.354966   \n",
       "4  dvae  dvae_4   0.282265     0.143717  0.392989    0.322242     0.312131   \n",
       "\n",
       "   purity_coarse  \n",
       "0       0.515589  \n",
       "1       0.535815  \n",
       "2       0.550420  \n",
       "3       0.545049  \n",
       "4       0.507714  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"coverage_results_for_viz.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0\n",
      "\t Rand Scores: 0.156,0.317              \tNMI Scores: 0.365,0.447              \tPurity Scores: 0.516,0.322\n",
      "Model 1\n",
      "\t Rand Scores: 0.174,0.395              \tNMI Scores: 0.376,0.468              \tPurity Scores: 0.536,0.334\n",
      "Model 2\n",
      "\t Rand Scores: 0.143,0.257              \tNMI Scores: 0.387,0.466              \tPurity Scores: 0.550,0.353\n",
      "Model 3\n",
      "\t Rand Scores: 0.179,0.351              \tNMI Scores: 0.384,0.485              \tPurity Scores: 0.545,0.355\n",
      "Model 4\n",
      "\t Rand Scores: 0.144,0.282              \tNMI Scores: 0.322,0.393              \tPurity Scores: 0.508,0.312\n"
     ]
    }
   ],
   "source": [
    "dvae_stuff = []\n",
    "for index in range(len(user_labels_dvae)) : \n",
    "    user_labels = user_labels_dvae[index]\n",
    "    \n",
    "    d = {\n",
    "    \"rand_fine\" : adjusted_rand_score(user_labels, labels_fine), \n",
    "    \"rand_coarse\" : adjusted_rand_score(user_labels, labels_coarse), \n",
    "    \"nmi_fine\": normalized_mutual_info_score(user_labels, labels_fine),\n",
    "    \"nmi_coarse\": normalized_mutual_info_score(user_labels, labels_coarse),\n",
    "    \"purity_fine\": purity(user_labels, labels_fine),\n",
    "    \"purity_coarse\" = purity(user_labels, labels_coarse)\n",
    "    \"model\":\"dvae\",\n",
    "    \"index\":f\"dvae_{index}\"\n",
    "    }\n",
    "    \n",
    "#     print(f\"Model {index}\\n\\t Rand Scores: {rand_coarse:.3f},{rand_fine:.3f} \\\n",
    "#              \\tNMI Scores: {nmi_coarse:.3f},{nmi_fine:.3f} \\\n",
    "#              \\tPurity Scores: {purity_coarse:.3f},{purity_fine:.3f}\")\n",
    "\n",
    "    dvae_stuff.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0\n",
      "\t Rand Scores: 0.156,0.317              \tNMI Scores: 0.365,0.447              \tPurity Scores: 0.516,0.322\n",
      "Model 1\n",
      "\t Rand Scores: 0.174,0.395              \tNMI Scores: 0.376,0.468              \tPurity Scores: 0.536,0.334\n",
      "Model 2\n",
      "\t Rand Scores: 0.143,0.257              \tNMI Scores: 0.387,0.466              \tPurity Scores: 0.550,0.353\n",
      "Model 3\n",
      "\t Rand Scores: 0.179,0.351              \tNMI Scores: 0.384,0.485              \tPurity Scores: 0.545,0.355\n",
      "Model 4\n",
      "\t Rand Scores: 0.144,0.282              \tNMI Scores: 0.322,0.393              \tPurity Scores: 0.508,0.312\n",
      "Model 5\n",
      "\t Rand Scores: 0.203,0.404              \tNMI Scores: 0.380,0.481              \tPurity Scores: 0.546,0.361\n",
      "Model 6\n",
      "\t Rand Scores: 0.156,0.336              \tNMI Scores: 0.367,0.444              \tPurity Scores: 0.534,0.329\n",
      "Model 7\n",
      "\t Rand Scores: 0.148,0.252              \tNMI Scores: 0.364,0.436              \tPurity Scores: 0.521,0.308\n",
      "Model 8\n",
      "\t Rand Scores: 0.164,0.316              \tNMI Scores: 0.392,0.477              \tPurity Scores: 0.554,0.349\n",
      "Model 9\n",
      "\t Rand Scores: 0.172,0.344              \tNMI Scores: 0.377,0.473              \tPurity Scores: 0.540,0.341\n",
      "Model 10\n",
      "\t Rand Scores: 0.165,0.320              \tNMI Scores: 0.388,0.484              \tPurity Scores: 0.557,0.364\n",
      "Model 11\n",
      "\t Rand Scores: 0.160,0.306              \tNMI Scores: 0.383,0.479              \tPurity Scores: 0.541,0.356\n",
      "Model 12\n",
      "\t Rand Scores: 0.138,0.280              \tNMI Scores: 0.372,0.450              \tPurity Scores: 0.531,0.330\n",
      "Model 13\n",
      "\t Rand Scores: 0.158,0.290              \tNMI Scores: 0.384,0.458              \tPurity Scores: 0.535,0.323\n",
      "Model 14\n",
      "\t Rand Scores: 0.155,0.316              \tNMI Scores: 0.371,0.479              \tPurity Scores: 0.536,0.362\n",
      "Model 15\n",
      "\t Rand Scores: 0.143,0.285              \tNMI Scores: 0.390,0.469              \tPurity Scores: 0.559,0.356\n",
      "Model 16\n",
      "\t Rand Scores: 0.185,0.342              \tNMI Scores: 0.388,0.468              \tPurity Scores: 0.552,0.331\n",
      "Model 17\n",
      "\t Rand Scores: 0.163,0.334              \tNMI Scores: 0.370,0.457              \tPurity Scores: 0.534,0.340\n",
      "Model 18\n",
      "\t Rand Scores: 0.176,0.379              \tNMI Scores: 0.389,0.492              \tPurity Scores: 0.553,0.351\n",
      "Model 19\n",
      "\t Rand Scores: 0.168,0.354              \tNMI Scores: 0.383,0.491              \tPurity Scores: 0.547,0.350\n",
      "Model 20\n",
      "\t Rand Scores: 0.150,0.279              \tNMI Scores: 0.365,0.450              \tPurity Scores: 0.528,0.319\n",
      "Model 21\n",
      "\t Rand Scores: 0.155,0.255              \tNMI Scores: 0.387,0.460              \tPurity Scores: 0.544,0.331\n",
      "Model 22\n",
      "\t Rand Scores: 0.165,0.316              \tNMI Scores: 0.380,0.480              \tPurity Scores: 0.551,0.364\n",
      "Model 23\n",
      "\t Rand Scores: 0.122,0.277              \tNMI Scores: 0.365,0.478              \tPurity Scores: 0.540,0.361\n",
      "Model 24\n",
      "\t Rand Scores: 0.165,0.348              \tNMI Scores: 0.384,0.487              \tPurity Scores: 0.551,0.348\n",
      "Model 25\n",
      "\t Rand Scores: 0.175,0.269              \tNMI Scores: 0.393,0.457              \tPurity Scores: 0.557,0.333\n",
      "Model 26\n",
      "\t Rand Scores: 0.156,0.325              \tNMI Scores: 0.373,0.461              \tPurity Scores: 0.549,0.342\n",
      "Model 27\n",
      "\t Rand Scores: 0.133,0.251              \tNMI Scores: 0.362,0.441              \tPurity Scores: 0.520,0.309\n",
      "Model 28\n",
      "\t Rand Scores: 0.156,0.285              \tNMI Scores: 0.385,0.457              \tPurity Scores: 0.539,0.334\n",
      "Model 29\n",
      "\t Rand Scores: 0.143,0.292              \tNMI Scores: 0.382,0.479              \tPurity Scores: 0.553,0.362\n",
      "Model 30\n",
      "\t Rand Scores: 0.155,0.319              \tNMI Scores: 0.375,0.480              \tPurity Scores: 0.546,0.361\n",
      "Model 31\n",
      "\t Rand Scores: 0.187,0.365              \tNMI Scores: 0.381,0.471              \tPurity Scores: 0.540,0.342\n",
      "Model 32\n",
      "\t Rand Scores: 0.194,0.357              \tNMI Scores: 0.388,0.464              \tPurity Scores: 0.549,0.326\n",
      "Model 33\n",
      "\t Rand Scores: 0.176,0.343              \tNMI Scores: 0.385,0.469              \tPurity Scores: 0.547,0.341\n",
      "Model 34\n",
      "\t Rand Scores: 0.168,0.342              \tNMI Scores: 0.399,0.487              \tPurity Scores: 0.573,0.349\n",
      "Model 35\n",
      "\t Rand Scores: 0.176,0.350              \tNMI Scores: 0.406,0.476              \tPurity Scores: 0.575,0.351\n",
      "Model 36\n",
      "\t Rand Scores: 0.172,0.331              \tNMI Scores: 0.394,0.487              \tPurity Scores: 0.548,0.350\n",
      "Model 37\n",
      "\t Rand Scores: 0.159,0.297              \tNMI Scores: 0.381,0.471              \tPurity Scores: 0.545,0.346\n",
      "Model 38\n",
      "\t Rand Scores: 0.145,0.283              \tNMI Scores: 0.369,0.454              \tPurity Scores: 0.524,0.317\n",
      "Model 39\n",
      "\t Rand Scores: 0.155,0.280              \tNMI Scores: 0.386,0.473              \tPurity Scores: 0.558,0.344\n",
      "Model 40\n",
      "\t Rand Scores: 0.141,0.321              \tNMI Scores: 0.383,0.495              \tPurity Scores: 0.548,0.360\n",
      "Model 41\n",
      "\t Rand Scores: 0.152,0.288              \tNMI Scores: 0.358,0.434              \tPurity Scores: 0.523,0.310\n",
      "Model 42\n",
      "\t Rand Scores: 0.151,0.296              \tNMI Scores: 0.370,0.470              \tPurity Scores: 0.531,0.324\n",
      "Model 43\n",
      "\t Rand Scores: 0.135,0.250              \tNMI Scores: 0.347,0.418              \tPurity Scores: 0.511,0.300\n",
      "Model 44\n",
      "\t Rand Scores: 0.184,0.405              \tNMI Scores: 0.373,0.467              \tPurity Scores: 0.533,0.328\n",
      "Model 45\n",
      "\t Rand Scores: 0.176,0.311              \tNMI Scores: 0.397,0.474              \tPurity Scores: 0.555,0.350\n",
      "Model 46\n",
      "\t Rand Scores: 0.157,0.313              \tNMI Scores: 0.387,0.482              \tPurity Scores: 0.554,0.349\n",
      "Model 47\n",
      "\t Rand Scores: 0.149,0.284              \tNMI Scores: 0.362,0.451              \tPurity Scores: 0.528,0.313\n",
      "Model 48\n",
      "\t Rand Scores: 0.174,0.385              \tNMI Scores: 0.392,0.505              \tPurity Scores: 0.561,0.370\n",
      "Model 49\n",
      "\t Rand Scores: 0.173,0.333              \tNMI Scores: 0.390,0.478              \tPurity Scores: 0.557,0.356\n",
      "Model 50\n",
      "\t Rand Scores: 0.168,0.339              \tNMI Scores: 0.387,0.478              \tPurity Scores: 0.551,0.347\n",
      "Model 51\n",
      "\t Rand Scores: 0.150,0.256              \tNMI Scores: 0.379,0.446              \tPurity Scores: 0.532,0.312\n",
      "Model 52\n",
      "\t Rand Scores: 0.159,0.275              \tNMI Scores: 0.376,0.442              \tPurity Scores: 0.536,0.308\n",
      "Model 53\n",
      "\t Rand Scores: 0.187,0.402              \tNMI Scores: 0.369,0.461              \tPurity Scores: 0.522,0.330\n",
      "Model 54\n",
      "\t Rand Scores: 0.158,0.330              \tNMI Scores: 0.378,0.484              \tPurity Scores: 0.550,0.372\n",
      "Model 55\n",
      "\t Rand Scores: 0.151,0.304              \tNMI Scores: 0.383,0.473              \tPurity Scores: 0.545,0.344\n",
      "Model 56\n",
      "\t Rand Scores: 0.151,0.311              \tNMI Scores: 0.375,0.470              \tPurity Scores: 0.532,0.330\n",
      "Model 57\n",
      "\t Rand Scores: 0.165,0.276              \tNMI Scores: 0.395,0.468              \tPurity Scores: 0.564,0.342\n",
      "Model 58\n",
      "\t Rand Scores: 0.147,0.298              \tNMI Scores: 0.383,0.475              \tPurity Scores: 0.553,0.345\n",
      "Model 59\n",
      "\t Rand Scores: 0.152,0.251              \tNMI Scores: 0.369,0.435              \tPurity Scores: 0.523,0.301\n",
      "Model 60\n",
      "\t Rand Scores: 0.157,0.331              \tNMI Scores: 0.348,0.415              \tPurity Scores: 0.506,0.296\n",
      "Model 61\n",
      "\t Rand Scores: 0.121,0.241              \tNMI Scores: 0.342,0.432              \tPurity Scores: 0.512,0.349\n",
      "Model 62\n",
      "\t Rand Scores: 0.168,0.348              \tNMI Scores: 0.366,0.451              \tPurity Scores: 0.526,0.314\n",
      "Model 63\n",
      "\t Rand Scores: 0.191,0.392              \tNMI Scores: 0.371,0.454              \tPurity Scores: 0.524,0.308\n",
      "Model 64\n",
      "\t Rand Scores: 0.181,0.366              \tNMI Scores: 0.386,0.466              \tPurity Scores: 0.554,0.337\n",
      "Model 65\n",
      "\t Rand Scores: 0.184,0.395              \tNMI Scores: 0.375,0.474              \tPurity Scores: 0.545,0.341\n",
      "Model 66\n",
      "\t Rand Scores: 0.165,0.350              \tNMI Scores: 0.375,0.478              \tPurity Scores: 0.536,0.344\n",
      "Model 67\n",
      "\t Rand Scores: 0.160,0.330              \tNMI Scores: 0.397,0.484              \tPurity Scores: 0.563,0.358\n",
      "Model 68\n",
      "\t Rand Scores: 0.168,0.314              \tNMI Scores: 0.397,0.485              \tPurity Scores: 0.563,0.357\n",
      "Model 69\n",
      "\t Rand Scores: 0.165,0.345              \tNMI Scores: 0.361,0.437              \tPurity Scores: 0.524,0.315\n",
      "Model 70\n",
      "\t Rand Scores: 0.184,0.396              \tNMI Scores: 0.372,0.462              \tPurity Scores: 0.524,0.332\n",
      "Model 71\n",
      "\t Rand Scores: 0.201,0.423              \tNMI Scores: 0.383,0.489              \tPurity Scores: 0.551,0.366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 72\n",
      "\t Rand Scores: 0.142,0.292              \tNMI Scores: 0.373,0.478              \tPurity Scores: 0.539,0.352\n",
      "Model 73\n",
      "\t Rand Scores: 0.141,0.253              \tNMI Scores: 0.383,0.458              \tPurity Scores: 0.540,0.339\n",
      "Model 74\n",
      "\t Rand Scores: 0.194,0.380              \tNMI Scores: 0.393,0.474              \tPurity Scores: 0.552,0.336\n",
      "Model 75\n",
      "\t Rand Scores: 0.160,0.310              \tNMI Scores: 0.386,0.474              \tPurity Scores: 0.555,0.350\n",
      "Model 76\n",
      "\t Rand Scores: 0.166,0.337              \tNMI Scores: 0.381,0.476              \tPurity Scores: 0.547,0.348\n",
      "Model 77\n",
      "\t Rand Scores: 0.162,0.323              \tNMI Scores: 0.388,0.484              \tPurity Scores: 0.554,0.357\n",
      "Model 78\n",
      "\t Rand Scores: 0.171,0.355              \tNMI Scores: 0.391,0.493              \tPurity Scores: 0.557,0.365\n",
      "Model 79\n",
      "\t Rand Scores: 0.136,0.241              \tNMI Scores: 0.346,0.414              \tPurity Scores: 0.515,0.294\n",
      "Model 80\n",
      "\t Rand Scores: 0.151,0.292              \tNMI Scores: 0.358,0.443              \tPurity Scores: 0.518,0.325\n",
      "Model 81\n",
      "\t Rand Scores: 0.155,0.287              \tNMI Scores: 0.382,0.473              \tPurity Scores: 0.545,0.349\n"
     ]
    }
   ],
   "source": [
    "for index in range(len(user_labels_dvae)) : \n",
    "    user_labels = user_labels_dvae[index]\n",
    "    rand_fine = adjusted_rand_score(user_labels, labels_fine)\n",
    "    rand_coarse = adjusted_rand_score(user_labels, labels_coarse)\n",
    "    nmi_fine = normalized_mutual_info_score(user_labels, labels_fine)\n",
    "    nmi_coarse = normalized_mutual_info_score(user_labels, labels_coarse)\n",
    "    purity_fine = purity(user_labels, labels_fine)\n",
    "    purity_coarse = purity(user_labels, labels_coarse)\n",
    "    \n",
    "    print(f\"Model {index}\\n\\t Rand Scores: {rand_coarse:.3f},{rand_fine:.3f} \\\n",
    "             \\tNMI Scores: {nmi_coarse:.3f},{nmi_fine:.3f} \\\n",
    "             \\tPurity Scores: {purity_coarse:.3f},{purity_fine:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0\n",
      "\t Rand Scores: 0.183,0.350              \tNMI Scores: 0.371,0.456              \tPurity Scores: 0.546,0.327\n",
      "Model 1\n",
      "\t Rand Scores: 0.178,0.343              \tNMI Scores: 0.371,0.460              \tPurity Scores: 0.543,0.333\n",
      "Model 2\n",
      "\t Rand Scores: 0.154,0.318              \tNMI Scores: 0.374,0.456              \tPurity Scores: 0.552,0.332\n",
      "Model 3\n",
      "\t Rand Scores: 0.190,0.408              \tNMI Scores: 0.378,0.468              \tPurity Scores: 0.552,0.343\n",
      "Model 4\n",
      "\t Rand Scores: 0.194,0.423              \tNMI Scores: 0.370,0.468              \tPurity Scores: 0.541,0.349\n",
      "Model 5\n",
      "\t Rand Scores: 0.167,0.352              \tNMI Scores: 0.371,0.467              \tPurity Scores: 0.552,0.353\n",
      "Model 6\n",
      "\t Rand Scores: 0.190,0.406              \tNMI Scores: 0.363,0.445              \tPurity Scores: 0.531,0.320\n",
      "Model 7\n",
      "\t Rand Scores: 0.199,0.430              \tNMI Scores: 0.372,0.466              \tPurity Scores: 0.548,0.341\n",
      "Model 8\n",
      "\t Rand Scores: 0.183,0.359              \tNMI Scores: 0.369,0.458              \tPurity Scores: 0.546,0.331\n",
      "Model 9\n",
      "\t Rand Scores: 0.198,0.419              \tNMI Scores: 0.373,0.467              \tPurity Scores: 0.546,0.341\n",
      "Model 10\n",
      "\t Rand Scores: 0.183,0.350              \tNMI Scores: 0.372,0.455              \tPurity Scores: 0.548,0.326\n",
      "Model 11\n",
      "\t Rand Scores: 0.122,0.223              \tNMI Scores: 0.316,0.370              \tPurity Scores: 0.486,0.251\n",
      "Model 12\n",
      "\t Rand Scores: 0.169,0.359              \tNMI Scores: 0.369,0.465              \tPurity Scores: 0.547,0.351\n",
      "Model 13\n",
      "\t Rand Scores: 0.128,0.270              \tNMI Scores: 0.350,0.422              \tPurity Scores: 0.527,0.304\n",
      "Model 14\n",
      "\t Rand Scores: 0.192,0.417              \tNMI Scores: 0.371,0.460              \tPurity Scores: 0.543,0.334\n",
      "Model 15\n",
      "\t Rand Scores: 0.174,0.371              \tNMI Scores: 0.369,0.458              \tPurity Scores: 0.543,0.331\n",
      "Model 16\n",
      "\t Rand Scores: 0.199,0.437              \tNMI Scores: 0.375,0.470              \tPurity Scores: 0.541,0.345\n",
      "Model 17\n",
      "\t Rand Scores: 0.171,0.340              \tNMI Scores: 0.373,0.459              \tPurity Scores: 0.545,0.328\n",
      "Model 18\n",
      "\t Rand Scores: 0.196,0.417              \tNMI Scores: 0.375,0.465              \tPurity Scores: 0.549,0.341\n",
      "Model 19\n",
      "\t Rand Scores: 0.169,0.356              \tNMI Scores: 0.372,0.464              \tPurity Scores: 0.544,0.342\n",
      "Model 20\n",
      "\t Rand Scores: 0.192,0.419              \tNMI Scores: 0.372,0.465              \tPurity Scores: 0.543,0.346\n",
      "Model 21\n",
      "\t Rand Scores: 0.196,0.408              \tNMI Scores: 0.380,0.471              \tPurity Scores: 0.552,0.351\n",
      "Model 22\n",
      "\t Rand Scores: 0.204,0.419              \tNMI Scores: 0.379,0.457              \tPurity Scores: 0.558,0.332\n",
      "Model 23\n",
      "\t Rand Scores: 0.103,0.183              \tNMI Scores: 0.303,0.353              \tPurity Scores: 0.476,0.240\n",
      "Model 24\n",
      "\t Rand Scores: 0.194,0.406              \tNMI Scores: 0.378,0.470              \tPurity Scores: 0.551,0.350\n",
      "Model 25\n",
      "\t Rand Scores: 0.192,0.405              \tNMI Scores: 0.379,0.465              \tPurity Scores: 0.553,0.335\n",
      "Model 26\n",
      "\t Rand Scores: 0.189,0.420              \tNMI Scores: 0.375,0.467              \tPurity Scores: 0.548,0.352\n",
      "Model 27\n",
      "\t Rand Scores: 0.199,0.438              \tNMI Scores: 0.375,0.470              \tPurity Scores: 0.548,0.348\n",
      "Model 28\n",
      "\t Rand Scores: 0.197,0.421              \tNMI Scores: 0.378,0.468              \tPurity Scores: 0.550,0.348\n",
      "Model 29\n",
      "\t Rand Scores: 0.196,0.425              \tNMI Scores: 0.377,0.470              \tPurity Scores: 0.554,0.353\n",
      "Model 30\n",
      "\t Rand Scores: 0.163,0.349              \tNMI Scores: 0.366,0.461              \tPurity Scores: 0.541,0.336\n",
      "Model 31\n",
      "\t Rand Scores: 0.196,0.428              \tNMI Scores: 0.368,0.465              \tPurity Scores: 0.542,0.344\n",
      "Model 32\n",
      "\t Rand Scores: 0.202,0.422              \tNMI Scores: 0.375,0.454              \tPurity Scores: 0.553,0.330\n",
      "Model 33\n",
      "\t Rand Scores: 0.193,0.421              \tNMI Scores: 0.376,0.462              \tPurity Scores: 0.548,0.343\n",
      "Model 34\n",
      "\t Rand Scores: 0.197,0.425              \tNMI Scores: 0.372,0.465              \tPurity Scores: 0.543,0.347\n",
      "Model 35\n",
      "\t Rand Scores: 0.195,0.425              \tNMI Scores: 0.369,0.464              \tPurity Scores: 0.545,0.343\n",
      "Model 36\n",
      "\t Rand Scores: 0.186,0.402              \tNMI Scores: 0.364,0.462              \tPurity Scores: 0.533,0.332\n",
      "Model 37\n",
      "\t Rand Scores: 0.196,0.410              \tNMI Scores: 0.379,0.471              \tPurity Scores: 0.551,0.352\n",
      "Model 38\n",
      "\t Rand Scores: 0.195,0.424              \tNMI Scores: 0.369,0.466              \tPurity Scores: 0.543,0.345\n",
      "Model 39\n",
      "\t Rand Scores: 0.195,0.422              \tNMI Scores: 0.371,0.466              \tPurity Scores: 0.543,0.345\n",
      "Model 40\n",
      "\t Rand Scores: 0.199,0.423              \tNMI Scores: 0.374,0.465              \tPurity Scores: 0.546,0.341\n",
      "Model 41\n",
      "\t Rand Scores: 0.196,0.419              \tNMI Scores: 0.377,0.467              \tPurity Scores: 0.549,0.348\n",
      "Model 42\n",
      "\t Rand Scores: 0.198,0.437              \tNMI Scores: 0.370,0.466              \tPurity Scores: 0.541,0.349\n",
      "Model 43\n",
      "\t Rand Scores: 0.198,0.438              \tNMI Scores: 0.376,0.466              \tPurity Scores: 0.550,0.350\n",
      "Model 44\n",
      "\t Rand Scores: 0.190,0.399              \tNMI Scores: 0.371,0.461              \tPurity Scores: 0.545,0.336\n",
      "Model 45\n",
      "\t Rand Scores: 0.166,0.332              \tNMI Scores: 0.366,0.444              \tPurity Scores: 0.542,0.323\n",
      "Model 46\n",
      "\t Rand Scores: 0.188,0.414              \tNMI Scores: 0.368,0.446              \tPurity Scores: 0.539,0.327\n",
      "Model 47\n",
      "\t Rand Scores: 0.195,0.422              \tNMI Scores: 0.371,0.466              \tPurity Scores: 0.543,0.345\n",
      "Model 48\n",
      "\t Rand Scores: 0.190,0.420              \tNMI Scores: 0.366,0.462              \tPurity Scores: 0.535,0.339\n",
      "Model 49\n",
      "\t Rand Scores: 0.193,0.420              \tNMI Scores: 0.376,0.462              \tPurity Scores: 0.548,0.343\n",
      "Model 50\n",
      "\t Rand Scores: 0.189,0.412              \tNMI Scores: 0.371,0.464              \tPurity Scores: 0.544,0.343\n",
      "Model 51\n",
      "\t Rand Scores: 0.194,0.420              \tNMI Scores: 0.370,0.464              \tPurity Scores: 0.540,0.337\n",
      "Model 52\n",
      "\t Rand Scores: 0.196,0.426              \tNMI Scores: 0.378,0.470              \tPurity Scores: 0.554,0.355\n",
      "Model 53\n",
      "\t Rand Scores: 0.201,0.415              \tNMI Scores: 0.368,0.456              \tPurity Scores: 0.539,0.330\n",
      "Model 54\n",
      "\t Rand Scores: 0.178,0.343              \tNMI Scores: 0.371,0.461              \tPurity Scores: 0.544,0.334\n",
      "Model 55\n",
      "\t Rand Scores: 0.190,0.427              \tNMI Scores: 0.377,0.469              \tPurity Scores: 0.548,0.351\n",
      "Model 56\n",
      "\t Rand Scores: 0.193,0.426              \tNMI Scores: 0.372,0.469              \tPurity Scores: 0.546,0.345\n",
      "Model 57\n",
      "\t Rand Scores: 0.139,0.308              \tNMI Scores: 0.369,0.450              \tPurity Scores: 0.545,0.329\n",
      "Model 58\n",
      "\t Rand Scores: 0.201,0.434              \tNMI Scores: 0.375,0.462              \tPurity Scores: 0.547,0.344\n",
      "Model 59\n",
      "\t Rand Scores: 0.195,0.429              \tNMI Scores: 0.372,0.465              \tPurity Scores: 0.541,0.343\n",
      "Model 60\n",
      "\t Rand Scores: 0.197,0.408              \tNMI Scores: 0.378,0.471              \tPurity Scores: 0.548,0.347\n",
      "Model 61\n",
      "\t Rand Scores: 0.167,0.329              \tNMI Scores: 0.365,0.447              \tPurity Scores: 0.542,0.323\n",
      "Model 62\n",
      "\t Rand Scores: 0.164,0.325              \tNMI Scores: 0.359,0.443              \tPurity Scores: 0.535,0.326\n",
      "Model 63\n",
      "\t Rand Scores: 0.171,0.343              \tNMI Scores: 0.368,0.461              \tPurity Scores: 0.543,0.342\n",
      "Model 64\n",
      "\t Rand Scores: 0.114,0.214              \tNMI Scores: 0.313,0.368              \tPurity Scores: 0.488,0.255\n",
      "Model 65\n",
      "\t Rand Scores: 0.185,0.408              \tNMI Scores: 0.371,0.455              \tPurity Scores: 0.544,0.337\n",
      "Model 66\n",
      "\t Rand Scores: 0.181,0.399              \tNMI Scores: 0.368,0.453              \tPurity Scores: 0.539,0.327\n",
      "Model 67\n",
      "\t Rand Scores: 0.174,0.346              \tNMI Scores: 0.369,0.457              \tPurity Scores: 0.546,0.336\n",
      "Model 68\n",
      "\t Rand Scores: 0.137,0.279              \tNMI Scores: 0.333,0.390              \tPurity Scores: 0.498,0.270\n",
      "Model 69\n",
      "\t Rand Scores: 0.193,0.418              \tNMI Scores: 0.377,0.462              \tPurity Scores: 0.549,0.341\n",
      "Model 70\n",
      "\t Rand Scores: 0.191,0.419              \tNMI Scores: 0.366,0.462              \tPurity Scores: 0.536,0.340\n",
      "Model 71\n",
      "\t Rand Scores: 0.173,0.347              \tNMI Scores: 0.380,0.471              \tPurity Scores: 0.555,0.355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 72\n",
      "\t Rand Scores: 0.193,0.408              \tNMI Scores: 0.372,0.457              \tPurity Scores: 0.544,0.329\n",
      "Model 73\n",
      "\t Rand Scores: 0.168,0.354              \tNMI Scores: 0.372,0.468              \tPurity Scores: 0.553,0.353\n",
      "Model 74\n",
      "\t Rand Scores: 0.173,0.345              \tNMI Scores: 0.380,0.470              \tPurity Scores: 0.555,0.354\n",
      "Model 75\n",
      "\t Rand Scores: 0.201,0.422              \tNMI Scores: 0.368,0.459              \tPurity Scores: 0.539,0.333\n",
      "Model 76\n",
      "\t Rand Scores: 0.195,0.427              \tNMI Scores: 0.371,0.467              \tPurity Scores: 0.543,0.345\n",
      "Model 77\n",
      "\t Rand Scores: 0.170,0.340              \tNMI Scores: 0.370,0.457              \tPurity Scores: 0.545,0.329\n",
      "Model 78\n",
      "\t Rand Scores: 0.197,0.433              \tNMI Scores: 0.380,0.472              \tPurity Scores: 0.552,0.359\n",
      "Model 79\n",
      "\t Rand Scores: 0.192,0.417              \tNMI Scores: 0.379,0.470              \tPurity Scores: 0.554,0.344\n",
      "Model 80\n",
      "\t Rand Scores: 0.197,0.431              \tNMI Scores: 0.370,0.465              \tPurity Scores: 0.541,0.348\n",
      "Model 81\n",
      "\t Rand Scores: 0.198,0.420              \tNMI Scores: 0.372,0.467              \tPurity Scores: 0.546,0.342\n",
      "Model 82\n",
      "\t Rand Scores: 0.193,0.427              \tNMI Scores: 0.370,0.462              \tPurity Scores: 0.544,0.337\n",
      "Model 83\n",
      "\t Rand Scores: 0.186,0.402              \tNMI Scores: 0.363,0.461              \tPurity Scores: 0.532,0.328\n"
     ]
    }
   ],
   "source": [
    "for index in range(len(user_labels_mallet)) : \n",
    "    user_labels = user_labels_mallet[index]\n",
    "    rand_fine = adjusted_rand_score(user_labels, labels_fine)\n",
    "    rand_coarse = adjusted_rand_score(user_labels, labels_coarse)\n",
    "    nmi_fine = normalized_mutual_info_score(user_labels, labels_fine)\n",
    "    nmi_coarse = normalized_mutual_info_score(user_labels, labels_coarse)\n",
    "    purity_fine = purity(user_labels, labels_fine)\n",
    "    purity_coarse = purity(user_labels, labels_coarse)\n",
    "    \n",
    "    print(f\"Model {index}\\n\\t Rand Scores: {rand_coarse:.3f},{rand_fine:.3f} \\\n",
    "             \\tNMI Scores: {nmi_coarse:.3f},{nmi_fine:.3f} \\\n",
    "             \\tPurity Scores: {purity_coarse:.3f},{purity_fine:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cc6a37dc584c4a360ff3ecf424cce2628e732b1d4f3b37dd63babf9eae293401"
  },
  "kernelspec": {
   "display_name": "cluster_ranking",
   "language": "python",
   "name": "cluster_ranking"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
