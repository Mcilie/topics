{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "from multiprocessing.sharedctypes import RawArray\n",
    "\n",
    "import torch\n",
    "import json\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.special import softmax, log_softmax\n",
    "from scipy.spatial.distance import jensenshannon, cdist\n",
    "\n",
    "sys.path.append(\"../soup_nuts/models/dvae/\")\n",
    "\n",
    "from dvae import data_iterator, CollapsedMultinomial, DVAE\n",
    "from utils import load_sparse, compute_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path):\n",
    "    with open(path) as infile:\n",
    "        return json.load(infile)\n",
    "\n",
    "def load_yaml(path):\n",
    "    with open(path) as infile:\n",
    "        return yaml.load(infile, Loader=yaml.FullLoader)\n",
    "\n",
    "def load_text(path):\n",
    "    with open(path) as infile:\n",
    "        return [text.strip().split(\" \") for text in infile]\n",
    "\n",
    "def save_json(obj, path):\n",
    "    with open(path, 'w') as outfile:\n",
    "        return json.dump(obj, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_est_to_words(topic_words, inv_vocab, n=10):\n",
    "    return [inv_vocab[idx] for idx in (-topic_words).argsort()[:n]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_CUDA_AVAILABLE = torch.cuda.is_available()\n",
    "_data_cache = {}\n",
    "\n",
    "def load_mallet_estimates(fpath):\n",
    "    \"\"\"\n",
    "    Load the doc-topic and topic-word estimates from our mallet output folder\n",
    "    \"\"\"\n",
    "    topic_word = np.load(fpath / \"beta.npy\")\n",
    "    # Load the standard mallet document-topic estimate as a numpy matrix\n",
    "    with open(fpath / \"doctopics.txt\") as infile:\n",
    "        doc_topic = np.array([\n",
    "            [float(x) for x in line.strip().split(\"\\t\")[2:]]\n",
    "            for line in infile\n",
    "        ])\n",
    "    return topic_word, doc_topic, None # TODO: is loss available in mallet?\n",
    "\n",
    "def load_dvae_estimates(fpath): \n",
    "    \"\"\"\n",
    "    Loads the dvae model and gets the topic word distribution, then instantiates\n",
    "    the encoder portion and does a forward pass to get the \n",
    "    \"\"\"\n",
    "    # get the topic word\n",
    "    device = torch.device(\"cuda\") if _CUDA_AVAILABLE else torch.device(\"cpu\")\n",
    "\n",
    "    state_dict = torch.load(fpath / \"model.pt\", map_location=device)\n",
    "    beta = state_dict[\"params\"][\"decoder$$$eta_layer.weight\"]\n",
    "    topic_word = torch.transpose(beta, 0, 1).detach().numpy()\n",
    "\n",
    "    # do a forward pass to get the document topics\n",
    "    # first instantiate the model and load in the params\n",
    "    config = load_yaml(fpath / \"config.yml\")\n",
    "    \n",
    "    dvae = DVAE(\n",
    "        vocab_size=topic_word.shape[1],\n",
    "        num_topics=config[\"num_topics\"],\n",
    "        alpha_prior=config[\"alpha_prior\"],\n",
    "        embeddings_dim=config[\"encoder_embeddings_dim\"],\n",
    "        hidden_dim=config[\"encoder_hidden_dim\"],\n",
    "        dropout=config[\"dropout\"],\n",
    "        cuda=_CUDA_AVAILABLE,\n",
    "    )\n",
    "    dvae_dict = {\n",
    "        k.replace(\"$$$\", \".\"): v\n",
    "        for k, v in state_dict['params'].items()\n",
    "    }\n",
    "    dvae.load_state_dict(dvae_dict, strict=False)\n",
    "    dvae.eval()\n",
    "    turn_off_bn = 1 * (config[\"epochs_to_anneal_bn\"] > 0) # 0 means use BN, > 0 means no BN\n",
    "\n",
    "    # then load the data for the forward pass\n",
    "    data_fpath = Path(config[\"input_dir\"], config[\"train_path\"])\n",
    "    if data_fpath not in _data_cache:\n",
    "        data = load_sparse(data_fpath).astype(np.float32)\n",
    "        _data_cache[data_fpath] = data\n",
    "    else:\n",
    "        data = _data_cache[data_fpath]\n",
    "    \n",
    "    batch_size = config[\"batch_size\"]\n",
    "    epochs = config[\"num_epochs\"]\n",
    "    n = data.shape[0]\n",
    "    train_batches = n // batch_size + 1\n",
    "\n",
    "    # do the forward pass and collect outputs in an array\n",
    "    doc_topic = np.zeros((n, config[\"num_topics\"]), dtype=np.float32)\n",
    "    losses = np.zeros(n, dtype=np.float32)\n",
    "    for i, x_batch in enumerate(data_iterator(data, batch_size, train_batches)):\n",
    "        x_batch = x_batch.to(device)\n",
    "        doc_topic_batch = dvae.encoder(x_batch)\n",
    "        doc_topic_batch = doc_topic_batch / doc_topic_batch.sum(1, keepdims=True)\n",
    "        x_recon = dvae.decoder(doc_topic_batch, bn_annealing_factor=turn_off_bn)\n",
    "        loss_batch = -CollapsedMultinomial(1, probs=x_recon).log_prob(x_batch)\n",
    "\n",
    "        doc_topic[i * batch_size:(i + 1) * batch_size] = doc_topic_batch.detach().cpu().numpy().astype(np.float32)\n",
    "        losses[i * batch_size:(i + 1) * batch_size] = loss_batch.detach().cpu().numpy().astype(np.float32)\n",
    "    return topic_word, doc_topic, losses\n",
    "\n",
    "\n",
    "def load_etm_estimates(fpath):\n",
    "    \"\"\"\n",
    "    Load the ETM estimates from a model\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def load_estimates(fpath, model_type):\n",
    "    if model_type == \"dvae\":\n",
    "        return load_dvae_estimates(fpath)\n",
    "    if model_type == \"mallet\":\n",
    "        return load_mallet_estimates(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stability metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_document_word_stability(doc_topics, topic_words, top_n=15):\n",
    "    \"\"\"\n",
    "    Given a collection of estimates of document-topic distributions, determine\n",
    "    how stable the topic assignments are by comparing the set of top words\n",
    "\n",
    "    TODO: just uses top topic for now\n",
    "    \"\"\"\n",
    "    runs = len(doc_topics)\n",
    "    n = doc_topics[0].shape[0]\n",
    "    top_words_over_runs = np.zeros((n, runs * top_n))\n",
    "    probs = np.zeros((n, runs))\n",
    "    \n",
    "    for i, (doc_topic, topic_word) in enumerate(tqdm(zip(doc_topics, topic_words), total=runs)):\n",
    "        top_words = (-topic_word).argsort()[:, :top_n]\n",
    "        top_words_over_runs[:, i*top_n:(i+1)*top_n] = top_words[doc_topic.argmax(1)]\n",
    "             #* (doc_topic.max(1, keepdims=True) >= min_prob)\n",
    "        #)\n",
    "        probs[:, i] = doc_topic.max(1)\n",
    "\n",
    "    # https://stackoverflow.com/questions/48473056/number-of-unique-elements-per-row-in-a-numpy-array\n",
    "    nunique = np.count_nonzero(np.diff(np.sort(top_words_over_runs)), axis=1) + 1\n",
    "    punique = (nunique - n_topic_words) / (n_topic_words * (runs - 1))\n",
    "    return nunique, punique, probs\n",
    "\n",
    "def estimate_topic_word_stability(topic_words, top_n=15):\n",
    "    \"\"\"\n",
    "    Given a collection of estimates of topic-word distributions, determine\n",
    "    how stable the topics are by comparing the set of top words\n",
    "    \"\"\"\n",
    "    runs = len(topic_words)\n",
    "    top_words_over_runs = np.zeros((n, runs * top_n))\n",
    "    probs = np.zeros((n, runs))\n",
    "    pass # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_topic_stability(topic_words, iters=1, sample_n=1, softmax_ests=False, seed=None):\n",
    "    \"\"\"\n",
    "    Estimate the stability of topics by running pairwise comparisons\n",
    "    of all runs: take the js-divergence of the topic pairs, then match each topic\n",
    "    with its closest pair, per run. Repeat `iters` times to get a \"pseudo-best\" matching\n",
    "\n",
    "    To speed up computation, can set `sample_pct` to use only a subset of possible combinations\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    num_topics = topic_words[0].shape[0]\n",
    "    runs = len(topic_words)\n",
    "    combins = (runs * (runs - 1)) // 2\n",
    "    sample_pct = sample_n if sample_n <= 1 else sample_n / combins\n",
    "    to_keep = [np.random.rand() <= sample_pct for _ in range(combins)]\n",
    "    kept = sum(to_keep)\n",
    "    min_dists = np.zeros((kept, num_topics))\n",
    "    c = 0\n",
    "    if softmax_ests:\n",
    "        topic_words = [softmax(t, axis=1) for t in topic_words]\n",
    "    pbar = tqdm(range(kept))\n",
    "    for keep, (t_a, t_b) in zip(to_keep, (combinations(topic_words, 2))):\n",
    "        if not keep:\n",
    "            continue\n",
    "        dists = cdist(t_a, t_b, metric='jensenshannon')\n",
    "\n",
    "        # algorithm is greedy: we randomize every iteration to get a pseudo-best estimate\n",
    "        # of the distances\n",
    "        for i in range(iters):\n",
    "            dists_ = dists[np.random.permutation(num_topics), :].copy()\n",
    "\n",
    "            min_dists_i = np.zeros(num_topics)\n",
    "            for k in range(num_topics):\n",
    "                min_idx = dists_[k].argmin() # match this topic to its lowest pair\n",
    "                min_dists_i[k] = dists_[k, min_idx] # record this minimum distance\n",
    "                dists_[k+1:, min_idx] = 1. # remove this index from consideration for later topics\n",
    "            if i == 0 or min_dists_i.mean() < min_dists[c].mean():\n",
    "                min_dists[c] = np.sort(min_dists_i)\n",
    "        c += 1\n",
    "        pbar.update()\n",
    "    pbar.close()\n",
    "    return min_dists\n",
    "\n",
    "def estimate_effective_topics(topic_words, iters):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collect the runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roughly 7 GB RAM for k=100\n",
    "def get_estimates_over_runs(run_paths, overlap_words, exclude_dups=False):\n",
    "    doc_topics, topic_words, duplicates = [], [], [] # TODO: change to 3d tensors\n",
    "    for i, (p, model_type) in enumerate(tqdm(run_paths)):\n",
    "        t, d, l = load_estimates(p, model_type=model_type)\n",
    "        \n",
    "        # located duplicated topics\n",
    "        sorted_t = np.sort((-t).argsort(axis=1)[:, :overlap_words], axis=1)\n",
    "        counted_topics = Counter([tuple(t_) for t_ in sorted_t])\n",
    "        if exclude_dups and max(counted_topics.values()) > 1:\n",
    "            continue\n",
    "        doc_topics.append(d)\n",
    "        topic_words.append(t)\n",
    "        duplicates.append(sum(c > 1 for c in counted_topics.values()))\n",
    "\n",
    "    return doc_topics, topic_words, duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_dir = \"../runs/outputs/url_partisanship_data\"\n",
    "run_dir = \"../runs/outputs/full-mindf_power_law-maxdf_0.9\"\n",
    "dataset = 'wikitext' #'url_partisan'\n",
    "\n",
    "mallet_paths = [\n",
    "    (p.parent, \"mallet\")\n",
    "    for p in Path(run_dir).glob(\"**/mallet-with-beta/**/doctopics.txt\")\n",
    "    if dataset in str(p) and \"_run-logs\" not in str(p)\n",
    "]\n",
    "dvae_paths = [\n",
    "    (p.parent, \"dvae\") for p in Path(run_dir).glob(\"**/dvae/**/model.pt\")\n",
    "    if dataset in str(p) and \"_run-logs\" not in str(p)\n",
    "]\n",
    "\n",
    "# should be independent of the model\n",
    "config = load_yaml(dvae_paths[0][0] / \"config.yml\")\n",
    "data = load_sparse(Path(config[\"input_dir\"], \"train.dtm.npz\"))\n",
    "vocab = load_json(Path(config[\"input_dir\"], \"vocab.json\"))\n",
    "inv_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_topics = sorted(set(int(re.search(\"k-([0-9]+)\", str(p)).group(1)) for p in dvae_paths))\n",
    "num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topic_words = 15\n",
    "overlap_words = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On k=50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e321f62045a2408991803c6fa47592df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "estimates_dvae, estimates_mallet = {}, {}\n",
    "for k in num_topics:\n",
    "    print(f\"On k={k}\")\n",
    "\n",
    "    # dvae_paths_k = [p for p in dvae_paths if f'k-{k}/' in str(p[0])]\n",
    "    # runs = len(dvae_paths_k)\n",
    "    # if dvae_paths_k:\n",
    "    #     doc_topics, topic_words, duplicates = get_estimates_over_runs(dvae_paths_k, overlap_words, exclude_dups=False)\n",
    "    #     estimates_dvae[k] = {\"doc_topics\": doc_topics, \"topic_words\": topic_words, \"duplicates\": duplicates}\n",
    "    \n",
    "    mallet_paths_k = [p for p in mallet_paths if f'k-{k}/' in str(p[0])]\n",
    "    if mallet_paths_k:\n",
    "        doc_topics, topic_words, duplicates = get_estimates_over_runs(mallet_paths_k, overlap_words, exclude_dups=False)\n",
    "        estimates_mallet[k] = {\"doc_topics\": doc_topics, \"topic_words\": topic_words, \"duplicates\": duplicates}\n",
    "\n",
    "# with open(f\"dvae-{dataset}-estimates.pkl\", \"wb\") as outfile:\n",
    "#     pickle.dump(estimates_dvae, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11476.642 , 11715.563 , 11440.037 , ..., 11428.749 , 11875.249 ,\n",
       "        11409.578 ],\n",
       "       [11940.236 , 12202.471 , 12010.1   , ..., 11977.722 , 12136.514 ,\n",
       "        12092.146 ],\n",
       "       [ 9013.488 ,  9227.204 ,  9028.507 , ...,  9075.722 ,  9206.195 ,\n",
       "         8975.454 ],\n",
       "       ...,\n",
       "       [ 4204.35  ,  4298.3613,  4001.2158, ...,  4016.9077,  4247.805 ,\n",
       "         3961.6814],\n",
       "       [ 2128.3608,  2228.5117,  2139.183 , ...,  2142.7175,  2265.1128,\n",
       "         2120.1372],\n",
       "       [ 4695.365 ,  4739.498 ,  4699.868 , ...,  4702.74  ,  4821.3086,\n",
       "         4667.9683]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f\"dvae-{dataset}-estimates.pkl\", \"rb\") as infile:\n",
    "    estimates_dvae = pickle.load(infile)\n",
    "\n",
    "estimates_dvae[50].pop(\"losses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8620c6cc5ad846ca8626585108710727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6d6243e3314ba4be1eaece2f941fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_word_data = {\"mallet\": {}, \"dvae\": {}}\n",
    "for model, estimates in [(\"mallet\", estimates_mallet), (\"dvae\", estimates_dvae)]:\n",
    "    model_data = {}\n",
    "    for k, est in estimates.items():\n",
    "        _, topic_words, duplicates = (\n",
    "            est[\"doc_topics\"], est[\"topic_words\"], est[\"duplicates\"]\n",
    "        )\n",
    "\n",
    "        dt, tw = doc_topics, topic_words\n",
    "        \n",
    "        nunique, punique, probs = estimate_document_word_stability(dt, tw, top_n=n_topic_words)\n",
    "        pct_assigned = (probs < 0.5).mean(1)\n",
    "        nsummary = pd.Series(nunique).describe()\n",
    "        psummary = pd.Series(punique).describe()\n",
    "        asummary = pd.Series(pct_assigned).describe()\n",
    "        \n",
    "        # model_data.update({f\"pct_unique_{k}\": psummary, f\"nuniuqe_{k}\": nsummary, f\"assigned_{k}\": asummary})\n",
    "        model_data.update({f\"pct_unique_{k}\": punique, f\"nuniuqe_{k}\": nunique, f\"assigned_{k}\": pct_assigned})\n",
    "    doc_word_data[model] = model_data\n",
    "\n",
    "doc_word_data = pd.concat({k: pd.DataFrame(v) for k, v in doc_word_data.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pct_unique_50</th>\n",
       "      <th>nuniuqe_50</th>\n",
       "      <th>assigned_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">mallet</th>\n",
       "      <th>0</th>\n",
       "      <td>0.012658</td>\n",
       "      <td>30</td>\n",
       "      <td>0.2375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.070042</td>\n",
       "      <td>98</td>\n",
       "      <td>0.9875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.042194</td>\n",
       "      <td>65</td>\n",
       "      <td>0.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025316</td>\n",
       "      <td>45</td>\n",
       "      <td>0.2875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022785</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dvae</th>\n",
       "      <th>28467</th>\n",
       "      <td>0.716456</td>\n",
       "      <td>864</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28468</th>\n",
       "      <td>0.735021</td>\n",
       "      <td>886</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28469</th>\n",
       "      <td>0.731646</td>\n",
       "      <td>882</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28470</th>\n",
       "      <td>0.735021</td>\n",
       "      <td>886</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28471</th>\n",
       "      <td>0.711392</td>\n",
       "      <td>858</td>\n",
       "      <td>0.8875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56944 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              pct_unique_50  nuniuqe_50  assigned_50\n",
       "mallet 0           0.012658          30       0.2375\n",
       "       1           0.070042          98       0.9875\n",
       "       2           0.042194          65       0.9500\n",
       "       3           0.025316          45       0.2875\n",
       "       4           0.022785          42       0.0000\n",
       "...                     ...         ...          ...\n",
       "dvae   28467       0.716456         864       0.0125\n",
       "       28468       0.735021         886       0.0000\n",
       "       28469       0.731646         882       0.0000\n",
       "       28470       0.735021         886       0.0000\n",
       "       28471       0.711392         858       0.8875\n",
       "\n",
       "[56944 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_word_data.to_csv(f\"document_word_stability-{dataset}-20220428.csv\")\n",
    "doc_word_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f77c0cf22a4f27b6e0fb278c917a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/274 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a784614421e448cabb09ca9bec166c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/273 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic_word_data = {\"mallet\": {}, \"dvae\": {}}\n",
    "for model, estimates in [(\"mallet\", estimates_mallet), (\"dvae\", estimates_dvae)]:\n",
    "    for k, est in estimates.items():\n",
    "        _, topic_words, duplicates = (\n",
    "            est[\"doc_topics\"], est[\"topic_words\"], est[\"duplicates\"]\n",
    "        )\n",
    "\n",
    "        tw = topic_words\n",
    "        # TODO: dvae may take longer since it should be float64?\n",
    "        dists = estimate_topic_stability(tw, softmax_ests=model=='dvae', iters=2, sample_n=250, seed=42)\n",
    "        summary = pd.Series(dists.flatten()).describe()\n",
    "        topic_word_data[model][f\"min_dists_{k}\"] = dists.mean(1) #summary\n",
    "\n",
    "topic_word_data = pd.concat({k: pd.DataFrame(v) for k, v in topic_word_data.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>min_dists_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">mallet</th>\n",
       "      <th>0</th>\n",
       "      <td>0.349347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.325461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.307134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.306972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.315830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dvae</th>\n",
       "      <th>268</th>\n",
       "      <td>0.568489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0.482378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.502758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0.142594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0.411130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>547 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            min_dists_50\n",
       "mallet 0        0.349347\n",
       "       1        0.325461\n",
       "       2        0.307134\n",
       "       3        0.306972\n",
       "       4        0.315830\n",
       "...                  ...\n",
       "dvae   268      0.568489\n",
       "       269      0.482378\n",
       "       270      0.502758\n",
       "       271      0.142594\n",
       "       272      0.411130\n",
       "\n",
       "[547 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word_data.to_csv(f\"topic_word_stability-{dataset}-20220428.csv\")\n",
    "topic_word_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: run over mallet as well\n",
    "data = {}\n",
    "\n",
    "for k, est in estimates_dvae.items():\n",
    "    doc_topics, topic_words, duplicates, losses = (\n",
    "        est[\"doc_topics\"], est[\"topic_words\"], est[\"duplicates\"], est[\"losses\"]\n",
    "    )\n",
    "    for exclude in [False, True]:\n",
    "        dt, tw = doc_topics, topic_words\n",
    "        if exclude:\n",
    "            dt, tw = exclude_dupes(dt, duplicates), exclude_dupes(tw, duplicates)\n",
    "        nunique, punique, probs = estimate_document_word_stability(dt, tw, top_n=n_topic_words)\n",
    "        pct_assigned = (probs < 0.5).mean(1)\n",
    "        nsummary = pd.Series(nunique).describe()\n",
    "        psummary = pd.Series(punique).describe()\n",
    "        asummary = pd.Series(pct_assigned).describe()\n",
    "        \n",
    "        data.update({f\"pct_unique_{k}\": psummary, f\"nuniuqe_{k}\": nsummary, f\"assigned_{k}\": asummary})\n",
    "\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>176377.000000</td>\n",
       "      <td>176377.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.749403</td>\n",
       "      <td>0.438181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.175117</td>\n",
       "      <td>0.137653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.326667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.436667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.886667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   a              b\n",
       "count  176377.000000  176377.000000\n",
       "mean        0.749403       0.438181\n",
       "std         0.175117       0.137653\n",
       "min         0.142857       0.150000\n",
       "25%         0.619048       0.326667\n",
       "50%         0.761905       0.436667\n",
       "75%         0.904762       0.540000\n",
       "max         1.000000       0.886667"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.to_csv(\"stability_summary-dvae-url_partisan-20220428.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>min_dists_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">mallet</th>\n",
       "      <th>count</th>\n",
       "      <td>750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.178525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.038807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.162107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.266771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.424182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.739950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dvae</th>\n",
       "      <th>count</th>\n",
       "      <td>850.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.346190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.168464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.010362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.217179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.341245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.466584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.785016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              min_dists_50\n",
       "mallet count    750.000000\n",
       "       mean       0.307692\n",
       "       std        0.178525\n",
       "       min        0.038807\n",
       "       25%        0.162107\n",
       "       50%        0.266771\n",
       "       75%        0.424182\n",
       "       max        0.739950\n",
       "dvae   count    850.000000\n",
       "       mean       0.346190\n",
       "       std        0.168464\n",
       "       min        0.010362\n",
       "       25%        0.217179\n",
       "       50%        0.341245\n",
       "       75%        0.466584\n",
       "       max        0.785016"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cc6a37dc584c4a360ff3ecf424cce2628e732b1d4f3b37dd63babf9eae293401"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 ('topic-evaluation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
