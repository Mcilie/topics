job_name: "mallet-cord19-256"

## These will be populated by the code
# Note the pipe | before `slurm_header` is necessary to parse as separate lines
templates:
    command: "export PATH=$PATH:/workspace/.conda/envs/gensim/bin && export JAVA_HOME=/workspace/.conda/envs/gensim && /workspace/.conda/envs/gensim/bin/python /workspace/rupak/topics/soup_nuts/models/gensim/lda.py --config {config_path} --output_dir {output_dir}/"
    slurm_header: |
        #!/bin/bash
        #SBATCH --array=0-{n_jobs}%75
        #SBATCH --job-name={job_name}
        #SBATCH --output={log_dir}/{job_name}-%A-%a.log
        #SBATCH --constraint=cpu-med
        #SBATCH --partition=cpu
        #SBATCH --exclusive
    # scheme for naming folders
    run_name: "{input_dir}/k-{num_topics}/mallet/alpha_{alpha}-beta_{beta}-iter_{iterations}-opt_{optimize_interval}/{run_seeds}"

  
## Hyperparams
hyper:
    input_dir: {
        "/workspace/rupak/cord19/data/": "cord19",
    }
    alpha: [0.01, 0.1] 
    beta: [0.01, 0.1]
    iterations: [2000]
    run_seeds: [42, 11235, 5591]
    optimize_interval: [0, 10, 20, 100]
    num_topics: [50, 100, 150, 200]

# Optional: specify directories or filenames of code which will be copied to the ouput dir for posterity
# Git hashes will also be saved, if available, for these directories
code_locations:
    - /workspace/rupak/topics/soup_nuts/models/gensim/


# defaults
params:
    model: "mallet"

    train_path: train.dtm.npz
    eval_path: train.dtm.npz
    vocab_path: vocab.json
    temp_output_dir: /scratch/

    num_topics: 50

    alpha: 5.0
    beta: 0.01
    iterations: 1000
    optimize_interval: 10
    
    eval_words: 10
    topic_words_to_save: 50
    optimize_for_coherence: false
    workers: 8
