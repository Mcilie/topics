{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd0724588c769277eec1559a818f4d33dcaba65e848ce2ee61833dc206a0b8113e6",
   "display_name": "Python 3.9.4 64-bit ('topic-evaluation': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "724588c769277eec1559a818f4d33dcaba65e848ce2ee61833dc206a0b8113e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path):\n",
    "    with open(path) as infile:\n",
    "        return json.load(infile)\n",
    "\n",
    "def load_yaml(path):\n",
    "    with open(path) as infile:\n",
    "        return yaml.load(infile, Loader=yaml.FullLoader)\n",
    "\n",
    "def load_text(path):\n",
    "    with open(path) as infile:\n",
    "        return [text.strip().split(\" \") for text in infile]\n",
    "\n",
    "def save_json(obj, path):\n",
    "    with open(path, 'w') as outfile:\n",
    "        return json.dump(obj, outfile)"
   ]
  },
  {
   "source": [
    "## Collect results from runs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# run_dir = \"./outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9\"\n",
    "run_dir = \"./outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9\"\n",
    "\n",
    "mallet_paths = [p for p in Path(run_dir).glob(\"**/mallet/**/metrics.json\") if 'with_unk' not in str(p)]\n",
    "dvae_paths = [p for p in Path(run_dir).glob(\"**/dvae/**/results.csv\") if 'with_unk' not in str(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_to_cols(path_col, config_keys):\n",
    "    return path_col.apply(\n",
    "        lambda x: pd.Series({\n",
    "            k: v for k, v in load_yaml(x / 'config.yml').items()\n",
    "            if k in config_keys\n",
    "        })\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_results = pd.DataFrame(\n",
    "    {\n",
    "        k: v for k, v in list(load_json(p).items())\n",
    "        if k in ['npmi', 'tu_mean', 'to', 'entire_overlaps', 'path']\n",
    "    }\n",
    "    for p in mallet_paths\n",
    ")\n",
    "\n",
    "mallet_results['model'] = 'mallet'\n",
    "mallet_results['path'] = [p.parent for p in mallet_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_config_keys = ['alpha', 'beta', 'input_dir', 'run_seeds', 'iterations']\n",
    "mallet_results = pd.concat(\n",
    "    [mallet_results, config_to_cols(mallet_results.path, mallet_config_keys)], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvae_results = pd.concat([\n",
    "    pd.read_csv(p.parent / \"run_results.csv\", index_col=0) for p in dvae_paths\n",
    "], ignore_index=True)\n",
    "dvae_results['model'] = 'dvae'\n",
    "dvae_results['path'] = [p.parent for p in dvae_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvae_config_keys = [\n",
    "    \"input_dir\",\n",
    "    \"alpha_prior\",\n",
    "    \"learning_rate\",\n",
    "    \"encoder_hidden_dim\",\n",
    "    \"topic_word_regularization\",\n",
    "    \"num_epochs\",\n",
    "    \"epochs_to_anneal_bn\",\n",
    "    \"epochs_to_anneal_kl\",\n",
    "    \"run_seeds\"\n",
    "]\n",
    "dvae_results = pd.concat(\n",
    "    [dvae_results, config_to_cols(dvae_results.path, dvae_config_keys)], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = Path(run_dir).name\n",
    "input_dir_map = {\n",
    "    f\"/workspace/topic-preprocessing/data/nytimes/processed/{run_name}\": \"nytimes\",\n",
    "    f\"/workspace/topic-preprocessing/data/wikitext/processed/{run_name}\": \"wikitext\",\n",
    "    f\"/workspace/topic-preprocessing/data/bbc/processed/{run_name}\": \"bbc\",\n",
    "}\n",
    "mallet_results['input_dir'] = mallet_results.input_dir.replace(input_dir_map)\n",
    "dvae_results['input_dir'] = dvae_results.input_dir.replace(input_dir_map)"
   ]
  },
  {
   "source": [
    "## Retrieve best-performing models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     seed  best_npmi  best_npmi_epoch  best_tu_at_best_npmi  \\\n",
       "91     42   0.405203              137                  0.98   \n",
       "45     42   0.526151               91                  0.99   \n",
       "161  5591   0.557972              151                  1.00   \n",
       "\n",
       "     best_to_at_best_npmi  overlaps_at_best_npmi model  \\\n",
       "91               0.013450                      0  dvae   \n",
       "45               0.008187                      0  dvae   \n",
       "161              0.000000                      0  dvae   \n",
       "\n",
       "                                                  path  alpha_prior  \\\n",
       "91   outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9/...        0.100   \n",
       "45   outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9/...        0.001   \n",
       "161  outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9/...        0.100   \n",
       "\n",
       "     encoder_hidden_dim  epochs_to_anneal_bn  epochs_to_anneal_kl input_dir  \\\n",
       "91                    0                  100                  100       bbc   \n",
       "45                    0                    1                  200   nytimes   \n",
       "161                   0                  100                  200  wikitext   \n",
       "\n",
       "     learning_rate  num_epochs  run_seeds  topic_word_regularization  \\\n",
       "91           0.010         200         42                       0.01   \n",
       "45           0.010         500         42                       0.00   \n",
       "161          0.001         500       5591                       0.00   \n",
       "\n",
       "     mean_npmi_to  \n",
       "91       0.695876  \n",
       "45       0.758982  \n",
       "161      0.778986  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seed</th>\n      <th>best_npmi</th>\n      <th>best_npmi_epoch</th>\n      <th>best_tu_at_best_npmi</th>\n      <th>best_to_at_best_npmi</th>\n      <th>overlaps_at_best_npmi</th>\n      <th>model</th>\n      <th>path</th>\n      <th>alpha_prior</th>\n      <th>encoder_hidden_dim</th>\n      <th>epochs_to_anneal_bn</th>\n      <th>epochs_to_anneal_kl</th>\n      <th>input_dir</th>\n      <th>learning_rate</th>\n      <th>num_epochs</th>\n      <th>run_seeds</th>\n      <th>topic_word_regularization</th>\n      <th>mean_npmi_to</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>91</th>\n      <td>42</td>\n      <td>0.405203</td>\n      <td>137</td>\n      <td>0.98</td>\n      <td>0.013450</td>\n      <td>0</td>\n      <td>dvae</td>\n      <td>outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9/...</td>\n      <td>0.100</td>\n      <td>0</td>\n      <td>100</td>\n      <td>100</td>\n      <td>bbc</td>\n      <td>0.010</td>\n      <td>200</td>\n      <td>42</td>\n      <td>0.01</td>\n      <td>0.695876</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>42</td>\n      <td>0.526151</td>\n      <td>91</td>\n      <td>0.99</td>\n      <td>0.008187</td>\n      <td>0</td>\n      <td>dvae</td>\n      <td>outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9/...</td>\n      <td>0.001</td>\n      <td>0</td>\n      <td>1</td>\n      <td>200</td>\n      <td>nytimes</td>\n      <td>0.010</td>\n      <td>500</td>\n      <td>42</td>\n      <td>0.00</td>\n      <td>0.758982</td>\n    </tr>\n    <tr>\n      <th>161</th>\n      <td>5591</td>\n      <td>0.557972</td>\n      <td>151</td>\n      <td>1.00</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>dvae</td>\n      <td>outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9/...</td>\n      <td>0.100</td>\n      <td>0</td>\n      <td>100</td>\n      <td>200</td>\n      <td>wikitext</td>\n      <td>0.001</td>\n      <td>500</td>\n      <td>5591</td>\n      <td>0.00</td>\n      <td>0.778986</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "import numpy as np\n",
    "dvae_results['mean_npmi_to'] = np.array(\n",
    "    [dvae_results.best_npmi, 1 - dvae_results.best_to_at_best_npmi]\n",
    ").mean(axis=0)\n",
    "dvae_results.iloc[dvae_results.groupby(\"input_dir\")[\"mean_npmi_to\"].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         npmi  tu_mean        to  entire_overlaps   model  \\\n",
       "130  0.191584    0.715  0.177778                0  mallet   \n",
       "69   0.255506    0.740  0.310234                0  mallet   \n",
       "180  0.249380    0.800  0.162281                0  mallet   \n",
       "\n",
       "                                                  path  alpha  beta input_dir  \\\n",
       "130  outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9/...    1.0  0.10       bbc   \n",
       "69   outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9/...    0.1  0.05   nytimes   \n",
       "180  outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9/...    0.1  0.10  wikitext   \n",
       "\n",
       "     iterations  run_seeds  mean_npmi_to  \n",
       "130        1000       5591      0.506903  \n",
       "69         1000       5591      0.472636  \n",
       "180        1000       5591      0.543550  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>npmi</th>\n      <th>tu_mean</th>\n      <th>to</th>\n      <th>entire_overlaps</th>\n      <th>model</th>\n      <th>path</th>\n      <th>alpha</th>\n      <th>beta</th>\n      <th>input_dir</th>\n      <th>iterations</th>\n      <th>run_seeds</th>\n      <th>mean_npmi_to</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>130</th>\n      <td>0.191584</td>\n      <td>0.715</td>\n      <td>0.177778</td>\n      <td>0</td>\n      <td>mallet</td>\n      <td>outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9/...</td>\n      <td>1.0</td>\n      <td>0.10</td>\n      <td>bbc</td>\n      <td>1000</td>\n      <td>5591</td>\n      <td>0.506903</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>0.255506</td>\n      <td>0.740</td>\n      <td>0.310234</td>\n      <td>0</td>\n      <td>mallet</td>\n      <td>outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9/...</td>\n      <td>0.1</td>\n      <td>0.05</td>\n      <td>nytimes</td>\n      <td>1000</td>\n      <td>5591</td>\n      <td>0.472636</td>\n    </tr>\n    <tr>\n      <th>180</th>\n      <td>0.249380</td>\n      <td>0.800</td>\n      <td>0.162281</td>\n      <td>0</td>\n      <td>mallet</td>\n      <td>outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9/...</td>\n      <td>0.1</td>\n      <td>0.10</td>\n      <td>wikitext</td>\n      <td>1000</td>\n      <td>5591</td>\n      <td>0.543550</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "import numpy as np\n",
    "mallet_results['mean_npmi_to'] = np.array(\n",
    "    [mallet_results.npmi, 1 - mallet_results.to]\n",
    ").mean(axis=0)\n",
    "mallet_results.iloc[mallet_results.groupby(\"input_dir\")[\"mean_npmi_to\"].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      seed  best_npmi  best_npmi_epoch  best_tu_at_best_npmi  \\\n",
       "91      42   0.405203              137                  0.98   \n",
       "44   11235   0.582163              271                  0.06   \n",
       "161   5591   0.557972              151                  1.00   \n",
       "\n",
       "     best_to_at_best_npmi  overlaps_at_best_npmi model  \\\n",
       "91               0.013450                      0  dvae   \n",
       "44               0.983333                     17  dvae   \n",
       "161              0.000000                      0  dvae   \n",
       "\n",
       "                                                  path  alpha_prior  \\\n",
       "91   outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9/...        0.100   \n",
       "44   outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9/...        0.001   \n",
       "161  outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9/...        0.100   \n",
       "\n",
       "     encoder_hidden_dim  epochs_to_anneal_bn  epochs_to_anneal_kl input_dir  \\\n",
       "91                    0                  100                  100       bbc   \n",
       "44                    0                  200                  200   nytimes   \n",
       "161                   0                  100                  200  wikitext   \n",
       "\n",
       "     learning_rate  num_epochs  run_seeds  topic_word_regularization  \\\n",
       "91           0.010         200         42                       0.01   \n",
       "44           0.010         500      11235                       0.00   \n",
       "161          0.001         500       5591                       0.00   \n",
       "\n",
       "     mean_npmi_to  \n",
       "91       0.695876  \n",
       "44       0.299415  \n",
       "161      0.778986  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seed</th>\n      <th>best_npmi</th>\n      <th>best_npmi_epoch</th>\n      <th>best_tu_at_best_npmi</th>\n      <th>best_to_at_best_npmi</th>\n      <th>overlaps_at_best_npmi</th>\n      <th>model</th>\n      <th>path</th>\n      <th>alpha_prior</th>\n      <th>encoder_hidden_dim</th>\n      <th>epochs_to_anneal_bn</th>\n      <th>epochs_to_anneal_kl</th>\n      <th>input_dir</th>\n      <th>learning_rate</th>\n      <th>num_epochs</th>\n      <th>run_seeds</th>\n      <th>topic_word_regularization</th>\n      <th>mean_npmi_to</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>91</th>\n      <td>42</td>\n      <td>0.405203</td>\n      <td>137</td>\n      <td>0.98</td>\n      <td>0.013450</td>\n      <td>0</td>\n      <td>dvae</td>\n      <td>outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9/...</td>\n      <td>0.100</td>\n      <td>0</td>\n      <td>100</td>\n      <td>100</td>\n      <td>bbc</td>\n      <td>0.010</td>\n      <td>200</td>\n      <td>42</td>\n      <td>0.01</td>\n      <td>0.695876</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>11235</td>\n      <td>0.582163</td>\n      <td>271</td>\n      <td>0.06</td>\n      <td>0.983333</td>\n      <td>17</td>\n      <td>dvae</td>\n      <td>outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9/...</td>\n      <td>0.001</td>\n      <td>0</td>\n      <td>200</td>\n      <td>200</td>\n      <td>nytimes</td>\n      <td>0.010</td>\n      <td>500</td>\n      <td>11235</td>\n      <td>0.00</td>\n      <td>0.299415</td>\n    </tr>\n    <tr>\n      <th>161</th>\n      <td>5591</td>\n      <td>0.557972</td>\n      <td>151</td>\n      <td>1.00</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>dvae</td>\n      <td>outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9/...</td>\n      <td>0.100</td>\n      <td>0</td>\n      <td>100</td>\n      <td>200</td>\n      <td>wikitext</td>\n      <td>0.001</td>\n      <td>500</td>\n      <td>5591</td>\n      <td>0.00</td>\n      <td>0.778986</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "dvae_top_npmi = dvae_results.iloc[dvae_results.groupby(\"input_dir\")[\"best_npmi\"].idxmax()]\n",
    "dvae_top_npmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         npmi  tu_mean        to  entire_overlaps   model  \\\n",
       "108  0.217124    0.750  0.259942                0  mallet   \n",
       "65   0.268696    0.735  0.460819                0  mallet   \n",
       "194  0.251148    0.800  0.164327                0  mallet   \n",
       "\n",
       "                                                  path  alpha  beta input_dir  \\\n",
       "108  outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9/...   0.10  0.01       bbc   \n",
       "65   outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9/...   0.25  0.10   nytimes   \n",
       "194  outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9/...   0.10  0.10  wikitext   \n",
       "\n",
       "     iterations  run_seeds  mean_npmi_to  \n",
       "108        2000      11235      0.478591  \n",
       "65         2000      11235      0.403939  \n",
       "194        2000         42      0.543410  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>npmi</th>\n      <th>tu_mean</th>\n      <th>to</th>\n      <th>entire_overlaps</th>\n      <th>model</th>\n      <th>path</th>\n      <th>alpha</th>\n      <th>beta</th>\n      <th>input_dir</th>\n      <th>iterations</th>\n      <th>run_seeds</th>\n      <th>mean_npmi_to</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>108</th>\n      <td>0.217124</td>\n      <td>0.750</td>\n      <td>0.259942</td>\n      <td>0</td>\n      <td>mallet</td>\n      <td>outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9/...</td>\n      <td>0.10</td>\n      <td>0.01</td>\n      <td>bbc</td>\n      <td>2000</td>\n      <td>11235</td>\n      <td>0.478591</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>0.268696</td>\n      <td>0.735</td>\n      <td>0.460819</td>\n      <td>0</td>\n      <td>mallet</td>\n      <td>outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9/...</td>\n      <td>0.25</td>\n      <td>0.10</td>\n      <td>nytimes</td>\n      <td>2000</td>\n      <td>11235</td>\n      <td>0.403939</td>\n    </tr>\n    <tr>\n      <th>194</th>\n      <td>0.251148</td>\n      <td>0.800</td>\n      <td>0.164327</td>\n      <td>0</td>\n      <td>mallet</td>\n      <td>outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9/...</td>\n      <td>0.10</td>\n      <td>0.10</td>\n      <td>wikitext</td>\n      <td>2000</td>\n      <td>42</td>\n      <td>0.543410</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "mallet_top_npmi = mallet_results.iloc[mallet_results.groupby(\"input_dir\")[\"npmi\"].idxmax()]\n",
    "mallet_top_npmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_top_topics = {\n",
    "    row.input_dir: {\n",
    "        'topics': load_text(row.path / \"topics.txt\"),\n",
    "        'path': str(row.path),\n",
    "    }\n",
    "    for idx, row in mallet_top_npmi.iterrows()\n",
    "}\n",
    "\n",
    "dvae_top_topics = {\n",
    "    row.input_dir: {\n",
    "        'topics': load_text(row.path / \"topics.txt\"),\n",
    "        'path': str(row.path),\n",
    "    }\n",
    "    for idx, row in dvae_top_npmi.iterrows()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = Path(\"./results\", Path(run_dir).name)\n",
    "out_path.mkdir(exist_ok=True)\n",
    "save_json(mallet_top_topics, Path(out_path, \"mallet-topics-best-npmi.json\"))\n",
    "save_json(dvae_top_topics, Path(out_path, \"dvae-topics-best-npmi.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "pd.DataFrame(\n",
    "    [model, dataset, \", \".join(topic[:n])]\n",
    "    for (model, model_topics) in [('mallet',  mallet_top_topics), ('dvae', dvae_top_topics)]\n",
    "    for dataset, dataset_topics in model_topics.items()\n",
    "    for topic in dataset_topics['topics']\n",
    ").to_csv(out_path / f\"topics-best-npmi.csv\", index=False)"
   ]
  },
  {
   "source": [
    "## Get bad hyperparams"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                         npmi_rank  best_npmi\n",
       "variable                  value                              \n",
       "learning_rate             0.01            0.339639   0.420558\n",
       "kl_bn_anneal              bn_1-kl_100     0.345546   0.405940\n",
       "                          bn_100-kl_100   0.389201   0.387570\n",
       "topic_word_regularization 0.1             0.427566   0.370420\n",
       "epochs_to_anneal_bn       100             0.446917   0.370799\n",
       "learning_rate             0.001           0.449209   0.371320\n",
       "num_epochs                500             0.453567   0.373120\n",
       "epochs_to_anneal_kl       100             0.469510   0.367679\n",
       "kl_bn_anneal              bn_0-kl_200     0.472113   0.373419\n",
       "                          bn_100-kl_1     0.474366   0.353205\n",
       "                          bn_100-kl_200   0.478798   0.370587\n",
       "encoder_hidden_dim        0               0.491007   0.371563\n",
       "alpha_prior               0.1             0.494727   0.346865\n",
       "run_seeds                 5591            0.497550   0.356655\n",
       "                          42              0.498924   0.357313\n",
       "alpha_prior               0.001           0.499459   0.377466\n",
       "topic_word_regularization 0               0.499654   0.382254\n",
       "epochs_to_anneal_bn       1.0             0.505294   0.353148\n",
       "epochs_to_anneal_kl       200             0.505300   0.367100\n",
       "input_dir                 bbc             0.507143   0.237472\n",
       "                          wikitext        0.507937   0.433394\n",
       "topic_word_regularization 0.01            0.509462   0.351739\n",
       "input_dir                 nytimes         0.512195   0.432261\n",
       "kl_bn_anneal              bn_200-kl_200   0.517634   0.361460\n",
       "                          bn_1-kl_200     0.522606   0.367515\n",
       "encoder_hidden_dim        100             0.523611   0.339622\n",
       "run_seeds                 11235           0.524068   0.350341\n",
       "epochs_to_anneal_bn       0               0.526507   0.346357\n",
       "alpha_prior               0.01            0.534894   0.336079\n",
       "kl_bn_anneal              bn_0-kl_100     0.538291   0.336268\n",
       "                          bn_0-kl_1       0.540290   0.346261\n",
       "num_epochs                200             0.563675   0.335495\n",
       "epochs_to_anneal_kl       1.0             0.566099   0.317932\n",
       "epochs_to_anneal_bn       200             0.572410   0.342114\n",
       "kl_bn_anneal              bn_200-kl_100   0.586779   0.346866\n",
       "topic_word_regularization 1.0             0.625097   0.304440\n",
       "kl_bn_anneal              bn_1-kl_1       0.633080   0.273831\n",
       "                          bn_200-kl_1     0.688247   0.278740\n",
       "learning_rate             0.0001          0.741423   0.270101"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>npmi_rank</th>\n      <th>best_npmi</th>\n    </tr>\n    <tr>\n      <th>variable</th>\n      <th>value</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>learning_rate</th>\n      <th>0.01</th>\n      <td>0.339639</td>\n      <td>0.420558</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">kl_bn_anneal</th>\n      <th>bn_1-kl_100</th>\n      <td>0.345546</td>\n      <td>0.405940</td>\n    </tr>\n    <tr>\n      <th>bn_100-kl_100</th>\n      <td>0.389201</td>\n      <td>0.387570</td>\n    </tr>\n    <tr>\n      <th>topic_word_regularization</th>\n      <th>0.1</th>\n      <td>0.427566</td>\n      <td>0.370420</td>\n    </tr>\n    <tr>\n      <th>epochs_to_anneal_bn</th>\n      <th>100</th>\n      <td>0.446917</td>\n      <td>0.370799</td>\n    </tr>\n    <tr>\n      <th>learning_rate</th>\n      <th>0.001</th>\n      <td>0.449209</td>\n      <td>0.371320</td>\n    </tr>\n    <tr>\n      <th>num_epochs</th>\n      <th>500</th>\n      <td>0.453567</td>\n      <td>0.373120</td>\n    </tr>\n    <tr>\n      <th>epochs_to_anneal_kl</th>\n      <th>100</th>\n      <td>0.469510</td>\n      <td>0.367679</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">kl_bn_anneal</th>\n      <th>bn_0-kl_200</th>\n      <td>0.472113</td>\n      <td>0.373419</td>\n    </tr>\n    <tr>\n      <th>bn_100-kl_1</th>\n      <td>0.474366</td>\n      <td>0.353205</td>\n    </tr>\n    <tr>\n      <th>bn_100-kl_200</th>\n      <td>0.478798</td>\n      <td>0.370587</td>\n    </tr>\n    <tr>\n      <th>encoder_hidden_dim</th>\n      <th>0</th>\n      <td>0.491007</td>\n      <td>0.371563</td>\n    </tr>\n    <tr>\n      <th>alpha_prior</th>\n      <th>0.1</th>\n      <td>0.494727</td>\n      <td>0.346865</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">run_seeds</th>\n      <th>5591</th>\n      <td>0.497550</td>\n      <td>0.356655</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>0.498924</td>\n      <td>0.357313</td>\n    </tr>\n    <tr>\n      <th>alpha_prior</th>\n      <th>0.001</th>\n      <td>0.499459</td>\n      <td>0.377466</td>\n    </tr>\n    <tr>\n      <th>topic_word_regularization</th>\n      <th>0</th>\n      <td>0.499654</td>\n      <td>0.382254</td>\n    </tr>\n    <tr>\n      <th>epochs_to_anneal_bn</th>\n      <th>1.0</th>\n      <td>0.505294</td>\n      <td>0.353148</td>\n    </tr>\n    <tr>\n      <th>epochs_to_anneal_kl</th>\n      <th>200</th>\n      <td>0.505300</td>\n      <td>0.367100</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">input_dir</th>\n      <th>bbc</th>\n      <td>0.507143</td>\n      <td>0.237472</td>\n    </tr>\n    <tr>\n      <th>wikitext</th>\n      <td>0.507937</td>\n      <td>0.433394</td>\n    </tr>\n    <tr>\n      <th>topic_word_regularization</th>\n      <th>0.01</th>\n      <td>0.509462</td>\n      <td>0.351739</td>\n    </tr>\n    <tr>\n      <th>input_dir</th>\n      <th>nytimes</th>\n      <td>0.512195</td>\n      <td>0.432261</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">kl_bn_anneal</th>\n      <th>bn_200-kl_200</th>\n      <td>0.517634</td>\n      <td>0.361460</td>\n    </tr>\n    <tr>\n      <th>bn_1-kl_200</th>\n      <td>0.522606</td>\n      <td>0.367515</td>\n    </tr>\n    <tr>\n      <th>encoder_hidden_dim</th>\n      <th>100</th>\n      <td>0.523611</td>\n      <td>0.339622</td>\n    </tr>\n    <tr>\n      <th>run_seeds</th>\n      <th>11235</th>\n      <td>0.524068</td>\n      <td>0.350341</td>\n    </tr>\n    <tr>\n      <th>epochs_to_anneal_bn</th>\n      <th>0</th>\n      <td>0.526507</td>\n      <td>0.346357</td>\n    </tr>\n    <tr>\n      <th>alpha_prior</th>\n      <th>0.01</th>\n      <td>0.534894</td>\n      <td>0.336079</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">kl_bn_anneal</th>\n      <th>bn_0-kl_100</th>\n      <td>0.538291</td>\n      <td>0.336268</td>\n    </tr>\n    <tr>\n      <th>bn_0-kl_1</th>\n      <td>0.540290</td>\n      <td>0.346261</td>\n    </tr>\n    <tr>\n      <th>num_epochs</th>\n      <th>200</th>\n      <td>0.563675</td>\n      <td>0.335495</td>\n    </tr>\n    <tr>\n      <th>epochs_to_anneal_kl</th>\n      <th>1.0</th>\n      <td>0.566099</td>\n      <td>0.317932</td>\n    </tr>\n    <tr>\n      <th>epochs_to_anneal_bn</th>\n      <th>200</th>\n      <td>0.572410</td>\n      <td>0.342114</td>\n    </tr>\n    <tr>\n      <th>kl_bn_anneal</th>\n      <th>bn_200-kl_100</th>\n      <td>0.586779</td>\n      <td>0.346866</td>\n    </tr>\n    <tr>\n      <th>topic_word_regularization</th>\n      <th>1.0</th>\n      <td>0.625097</td>\n      <td>0.304440</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">kl_bn_anneal</th>\n      <th>bn_1-kl_1</th>\n      <td>0.633080</td>\n      <td>0.273831</td>\n    </tr>\n    <tr>\n      <th>bn_200-kl_1</th>\n      <td>0.688247</td>\n      <td>0.278740</td>\n    </tr>\n    <tr>\n      <th>learning_rate</th>\n      <th>0.0001</th>\n      <td>0.741423</td>\n      <td>0.270101</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "dvae_results['npmi_rank'] = dvae_results.groupby(\"input_dir\")[\"best_npmi\"].rank(pct=True, ascending=False)\n",
    "dvae_results[\"kl_bn_anneal\"] = (\n",
    "    \"bn_\" + dvae_results.epochs_to_anneal_bn.astype(str) +\n",
    "    \"-kl_\" + dvae_results.epochs_to_anneal_kl.astype(str)\n",
    ")\n",
    "(\n",
    "    pd.melt(dvae_results, id_vars=['path', 'best_npmi', 'best_to_at_best_npmi', 'npmi_rank'], value_vars=dvae_config_keys + ['kl_bn_anneal'])\n",
    "      .groupby([\"variable\", \"value\"])[[\"npmi_rank\", \"best_npmi\"]]\n",
    "      .mean()\n",
    "      .sort_values(\"npmi_rank\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     npmi_rank      npmi\n",
       "variable   value                        \n",
       "beta       0.1        0.420436  0.247764\n",
       "iterations 2000       0.426668  0.248478\n",
       "alpha      0.1        0.456801  0.248297\n",
       "beta       0.05       0.457972  0.248563\n",
       "run_seeds  11235      0.461451  0.244701\n",
       "beta       0.01       0.465410  0.246997\n",
       "run_seeds  42         0.492032  0.248104\n",
       "alpha      10.0       0.496176  0.247158\n",
       "           0.25       0.497192  0.244788\n",
       "input_dir  wikitext   0.505155  0.227564\n",
       "           nytimes    0.505435  0.268894\n",
       "           bbc        0.506329  0.240080\n",
       "alpha      5.0        0.508678  0.243230\n",
       "iterations 1000       0.512818  0.244219\n",
       "alpha      1.0        0.514653  0.244858\n",
       "           0.05       0.563505  0.245180\n",
       "run_seeds  5591       0.563805  0.243527\n",
       "iterations 500        0.587616  0.243186\n",
       "beta       1.0        0.659705  0.239045"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>npmi_rank</th>\n      <th>npmi</th>\n    </tr>\n    <tr>\n      <th>variable</th>\n      <th>value</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>beta</th>\n      <th>0.1</th>\n      <td>0.420436</td>\n      <td>0.247764</td>\n    </tr>\n    <tr>\n      <th>iterations</th>\n      <th>2000</th>\n      <td>0.426668</td>\n      <td>0.248478</td>\n    </tr>\n    <tr>\n      <th>alpha</th>\n      <th>0.1</th>\n      <td>0.456801</td>\n      <td>0.248297</td>\n    </tr>\n    <tr>\n      <th>beta</th>\n      <th>0.05</th>\n      <td>0.457972</td>\n      <td>0.248563</td>\n    </tr>\n    <tr>\n      <th>run_seeds</th>\n      <th>11235</th>\n      <td>0.461451</td>\n      <td>0.244701</td>\n    </tr>\n    <tr>\n      <th>beta</th>\n      <th>0.01</th>\n      <td>0.465410</td>\n      <td>0.246997</td>\n    </tr>\n    <tr>\n      <th>run_seeds</th>\n      <th>42</th>\n      <td>0.492032</td>\n      <td>0.248104</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">alpha</th>\n      <th>10.0</th>\n      <td>0.496176</td>\n      <td>0.247158</td>\n    </tr>\n    <tr>\n      <th>0.25</th>\n      <td>0.497192</td>\n      <td>0.244788</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">input_dir</th>\n      <th>wikitext</th>\n      <td>0.505155</td>\n      <td>0.227564</td>\n    </tr>\n    <tr>\n      <th>nytimes</th>\n      <td>0.505435</td>\n      <td>0.268894</td>\n    </tr>\n    <tr>\n      <th>bbc</th>\n      <td>0.506329</td>\n      <td>0.240080</td>\n    </tr>\n    <tr>\n      <th>alpha</th>\n      <th>5.0</th>\n      <td>0.508678</td>\n      <td>0.243230</td>\n    </tr>\n    <tr>\n      <th>iterations</th>\n      <th>1000</th>\n      <td>0.512818</td>\n      <td>0.244219</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">alpha</th>\n      <th>1.0</th>\n      <td>0.514653</td>\n      <td>0.244858</td>\n    </tr>\n    <tr>\n      <th>0.05</th>\n      <td>0.563505</td>\n      <td>0.245180</td>\n    </tr>\n    <tr>\n      <th>run_seeds</th>\n      <th>5591</th>\n      <td>0.563805</td>\n      <td>0.243527</td>\n    </tr>\n    <tr>\n      <th>iterations</th>\n      <th>500</th>\n      <td>0.587616</td>\n      <td>0.243186</td>\n    </tr>\n    <tr>\n      <th>beta</th>\n      <th>1.0</th>\n      <td>0.659705</td>\n      <td>0.239045</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "mallet_results['npmi_rank'] = mallet_results.groupby(\"input_dir\")[\"npmi\"].rank(pct=True, ascending=False)\n",
    "(\n",
    "    pd.melt(mallet_results, id_vars=['path', 'npmi', 'to', 'npmi_rank'], value_vars=mallet_config_keys)\n",
    "      .groupby([\"variable\", \"value\"])[[\"npmi_rank\", \"npmi\"]]\n",
    "      .mean()\n",
    "      .sort_values(\"npmi_rank\")\n",
    ")"
   ]
  },
  {
   "source": [
    "## Other coherence measures"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/workspace/.conda/envs/topic-evaluation/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = {\n",
    "    name: {\n",
    "        \"train_dict\": Dictionary(load_text(Path(input_dir, \"train.txt\"))),\n",
    "        \"val_text\": load_text(Path(input_dir, \"val.txt\")),\n",
    "    }\n",
    "    for input_dir, name in input_dir_map.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/174 [00:00<?, ?it/s]/workspace/.conda/envs/topic-evaluation/lib/python3.9/site-packages/gensim/topic_coherence/direct_confirmation_measure.py:204: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  m_lr_i = np.log(numerator / denominator)\n",
      "/workspace/.conda/envs/topic-evaluation/lib/python3.9/site-packages/gensim/topic_coherence/indirect_confirmation_measure.py:323: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return cv1.T.dot(cv2)[0, 0] / (_magnitude(cv1) * _magnitude(cv2))\n",
      "100%|██████████| 174/174 [32:11<00:00, 11.10s/it]\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "\n",
    "dvae_coherences = []\n",
    "for idx, row in tqdm(dvae_results.iterrows(), total=len(dvae_results)):\n",
    "    cm = CoherenceModel(\n",
    "        topics=[t[:n] for t in load_text(row.path / \"topics.txt\")],\n",
    "        texts=texts[row.input_dir]['val_text'],\n",
    "        dictionary=texts[row.input_dir]['train_dict'],\n",
    "        coherence='c_v',\n",
    "    )\n",
    "    dvae_coherences.append(cm.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = Path(\"./results\", Path(run_dir).name)\n",
    "dvae_results['c_v'] = dvae_coherences\n",
    "dvae_results.to_csv(out_path / \"dvae_results_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "\n",
    "mallet_coherences = []\n",
    "for idx, row in tqdm(mallet_results.iterrows(), total=len(mallet_results)):\n",
    "    cm = CoherenceModel(\n",
    "        topics=[t[:n] for t in load_text(row.path / \"topics.txt\")],\n",
    "        texts=texts[row.input_dir]['val_text'],\n",
    "        dictionary=texts[row.input_dir]['train_dict'],\n",
    "        coherence='c_v'\n",
    "    )\n",
    "    mallet_coherences.append(cm.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = Path(\"./results\", Path(run_dir).name)\n",
    "mallet_results['c_v'] = mallet_coherences\n",
    "mallet_results.to_csv(out_path / \"mallet_results_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvae_top_c_v = dvae_results.iloc[dvae_results.groupby(\"input_dir\")[\"c_v\"].idxmax()]\n",
    "dvae_top_c_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_top_c_v = mallet_results.iloc[mallet_results.groupby(\"input_dir\")[\"c_v\"].idxmax()]\n",
    "mallet_top_c_v"
   ]
  },
  {
   "source": [
    "## Coherences Computed Outside"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/workspace/topic-preprocessing/soup_nuts/models/dvae/\")\n",
    "from utils import compute_to, compute_tu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = \"./outputs/full-mindf_power_law-maxdf_0.9\"\n",
    "#run_dir = \"./outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9\"\n",
    "coherence_measure = \"c_v_full\" # npmi test, npmi full yield same results\n",
    "\n",
    "max_overlapping_words = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_paths = [p for p in Path(run_dir).glob(\"**/mallet/**/coherences.json\")]\n",
    "dvae_paths = [p for p in Path(run_dir).glob(\"**/dvae/**/coherences.json\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = Path(run_dir).name\n",
    "input_dir_map = {\n",
    "    f\"/workspace/topic-preprocessing/data/nytimes/processed/{run_name}\": \"nytimes\",\n",
    "    f\"/workspace/topic-preprocessing/data/wikitext/processed/{run_name}\": \"wikitext\",\n",
    "    f\"/workspace/topic-preprocessing/data/bbc/processed/{run_name}\": \"bbc\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_config_keys = ['alpha', 'beta', 'input_dir', 'run_seeds', 'iterations']\n",
    "mallet_results = []\n",
    "for p in mallet_paths:\n",
    "    coherences = load_json(p)\n",
    "    config = {k: v for k, v in load_yaml(p.parent / \"config.yml\").items() if k in mallet_config_keys}\n",
    "    config[\"input_dir\"] = input_dir_map[config[\"input_dir\"]]\n",
    "    # TODO: select best if desired\n",
    "    final_coherence = list(coherences[coherence_measure].values())[-1]\n",
    "    topics = load_text(final_coherence[\"path\"])\n",
    "    to, overlaps = compute_to(topics, n=max_overlapping_words, return_overlaps=True)\n",
    "    tu = np.mean(compute_tu(topics, n=10))\n",
    "\n",
    "    mallet_results.append({\n",
    "        coherence_measure: np.nan if np.isinf(final_coherence[\"aggregate\"]) else final_coherence[\"aggregate\"],\n",
    "        f\"{coherence_measure}_sd\": np.std(final_coherence[\"by_topic\"]),\n",
    "        \"tu\": tu,\n",
    "        \"to\": to,\n",
    "        f\"mean_{coherence_measure}_tu\": np.mean([tu, final_coherence[\"aggregate\"]]),\n",
    "        \"overlaps\": np.sum(overlaps >= max_overlapping_words),\n",
    "        **config,\n",
    "        \"topics\": topics,\n",
    "        \"path\": str(p.parent),\n",
    "    })\n",
    "mallet_results = pd.DataFrame(mallet_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_top_coh = (\n",
    "    mallet_results.loc[mallet_results.overlaps == 0]\n",
    "                  .sort_values([\"input_dir\", coherence_measure], ascending=False)\n",
    "                  .groupby(\"input_dir\").head(1)\n",
    ")\n",
    "mallet_top_topics = {\n",
    "    input_dir: data.to_dict('records')[0]\n",
    "    for input_dir, data in mallet_top_coh.groupby(\"input_dir\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvae_config_keys = [\n",
    "    \"input_dir\",\n",
    "    \"alpha_prior\",\n",
    "    \"learning_rate\",\n",
    "    \"encoder_hidden_dim\",\n",
    "    \"topic_word_regularization\",\n",
    "    \"num_epochs\",\n",
    "    \"epochs_to_anneal_bn\",\n",
    "    \"epochs_to_anneal_kl\",\n",
    "    \"run_seeds\"\n",
    "]\n",
    "\n",
    "dvae_results = []\n",
    "for p in dvae_paths:\n",
    "    coherences = load_json(p)\n",
    "    config = {k: v for k, v in load_yaml(p.parent / \"config.yml\").items() if k in dvae_config_keys}\n",
    "    config[\"input_dir\"] = input_dir_map[config[\"input_dir\"]]\n",
    "    final_coherence = list(coherences[coherence_measure].values())[-1]\n",
    "    topics = load_text(final_coherence[\"path\"])\n",
    "    to, overlaps = compute_to(topics, n=max_overlapping_words, return_overlaps=True)\n",
    "    tu = np.mean(compute_tu(topics, n=10))\n",
    "\n",
    "    coh_values = np.nan_to_num(final_coherence[\"by_topic\"], nan=0, posinf=0)\n",
    "\n",
    "    dvae_results.append({\n",
    "        coherence_measure: np.mean(coh_values),\n",
    "        f\"{coherence_measure}_sd\": np.std(coh_values),\n",
    "        \"tu\": tu,\n",
    "        \"to\": to,\n",
    "        f\"mean_{coherence_measure}_tu\": np.mean([tu, final_coherence[\"aggregate\"]]),\n",
    "        \"overlaps\": np.sum(overlaps >= max_overlapping_words),\n",
    "        **config,\n",
    "        \"topics\": topics,\n",
    "        \"path\": str(p.parent),\n",
    "    })\n",
    "dvae_results = pd.DataFrame(dvae_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvae_top_coh = (\n",
    "    dvae_results.loc[dvae_results.overlaps == 0]\n",
    "                .sort_values([\"input_dir\", coherence_measure], ascending=False)\n",
    "                .groupby(\"input_dir\").head(1)\n",
    ")\n",
    "dvae_top_topics = {\n",
    "    input_dir: data.to_dict('records')[0]\n",
    "    for input_dir, data in dvae_top_coh.groupby(\"input_dir\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = Path(\"./results\", Path(run_dir).name)\n",
    "out_path.mkdir(exist_ok=True)\n",
    "save_json(mallet_top_topics, Path(out_path, f\"mallet-topics-best-{coherence_measure}.json\"))\n",
    "save_json(dvae_top_topics, Path(out_path, f\"dvae-topics-best-{coherence_measure}.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "pd.DataFrame(\n",
    "    [model, dataset, \", \".join(topic[:n])]\n",
    "    for (model, model_topics) in [('mallet',  mallet_top_topics), ('dvae', dvae_top_topics)]\n",
    "    for dataset, dataset_topics in model_topics.items()\n",
    "    for topic in dataset_topics['topics']\n",
    ").to_csv(out_path / f\"topics-best-{coherence_measure}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     c_v_full  c_v_full_sd     tu        to  mean_c_v_full_tu  overlaps  \\\n",
       "74   0.841277     0.096112  0.920  0.055102          0.880638         0   \n",
       "125  0.844652     0.128574  0.948  0.046939          0.896326         0   \n",
       "\n",
       "     alpha_prior  encoder_hidden_dim  epochs_to_anneal_bn  \\\n",
       "74          0.01                   0                    1   \n",
       "125         0.01                   0                  200   \n",
       "\n",
       "     epochs_to_anneal_kl input_dir  learning_rate  num_epochs  run_seeds  \\\n",
       "74                   100  wikitext           0.01         500         42   \n",
       "125                  200   nytimes           0.01         500       5591   \n",
       "\n",
       "     topic_word_regularization  \\\n",
       "74                         0.0   \n",
       "125                        0.1   \n",
       "\n",
       "                                                topics  \\\n",
       "74   [[certifications, mtv_news, australian_recordi...   \n",
       "125  [[bridegroom, officiated, laude, bride, cum, m...   \n",
       "\n",
       "                                                  path  \n",
       "74   outputs/full-mindf_power_law-maxdf_0.9/wikitex...  \n",
       "125  outputs/full-mindf_power_law-maxdf_0.9/nytimes...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>c_v_full</th>\n      <th>c_v_full_sd</th>\n      <th>tu</th>\n      <th>to</th>\n      <th>mean_c_v_full_tu</th>\n      <th>overlaps</th>\n      <th>alpha_prior</th>\n      <th>encoder_hidden_dim</th>\n      <th>epochs_to_anneal_bn</th>\n      <th>epochs_to_anneal_kl</th>\n      <th>input_dir</th>\n      <th>learning_rate</th>\n      <th>num_epochs</th>\n      <th>run_seeds</th>\n      <th>topic_word_regularization</th>\n      <th>topics</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>74</th>\n      <td>0.841277</td>\n      <td>0.096112</td>\n      <td>0.920</td>\n      <td>0.055102</td>\n      <td>0.880638</td>\n      <td>0</td>\n      <td>0.01</td>\n      <td>0</td>\n      <td>1</td>\n      <td>100</td>\n      <td>wikitext</td>\n      <td>0.01</td>\n      <td>500</td>\n      <td>42</td>\n      <td>0.0</td>\n      <td>[[certifications, mtv_news, australian_recordi...</td>\n      <td>outputs/full-mindf_power_law-maxdf_0.9/wikitex...</td>\n    </tr>\n    <tr>\n      <th>125</th>\n      <td>0.844652</td>\n      <td>0.128574</td>\n      <td>0.948</td>\n      <td>0.046939</td>\n      <td>0.896326</td>\n      <td>0</td>\n      <td>0.01</td>\n      <td>0</td>\n      <td>200</td>\n      <td>200</td>\n      <td>nytimes</td>\n      <td>0.01</td>\n      <td>500</td>\n      <td>5591</td>\n      <td>0.1</td>\n      <td>[[bridegroom, officiated, laude, bride, cum, m...</td>\n      <td>outputs/full-mindf_power_law-maxdf_0.9/nytimes...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "sorted_dvae = (dvae_results.loc[dvae_results.overlaps == 0]\n",
    "                .sort_values([\"input_dir\", coherence_measure], ascending=False)\n",
    "                .groupby(\"input_dir\").head(1))\n",
    "sorted_dvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\n====wikitext (74)====\nalpha_0.01-lr_0.01-h2dim_0-reg_0.0-epochs_500-anneal_bn_1-anneal_kl_100\ncertifications  mtv_news  australian_recording_industry_association  chart  sal_cinquemani\nstonework  nave  castle  vaulted  architectural\nhouse_of_commons  church_of_england  protestant  highness  queen_victoria\njuveniles  females  iucn  males  species\nmanhattan_project  los_alamos_laboratory  robert_oppenheimer  enrico_fermi  physicist\nepidemiology  symptoms  clinical  diagnosis  therapy\nalbum  certifications  chart  billboard  recording_industry_association_of_america\nsupreme_court  constitutional  courts  statutory  statute\nhindu  inscriptions  dynasty  deity  temple\nnhl  national_hockey_league  playoffs  american_hockey_league  hockey\nfilm  filmography  screenplay  roger_ebert  times_of_india\ncomposer  composers  orchestral  opera  soloists\ntheory  philosopher  empirical  philosophers  thinkers\ndemography  parish  constituency  councillors  domesday\npainting  paintings  painter  literary  poems\nlandfall  gusts  flooding  hurricane  winds\ninfantry  flank  casualties  battalion  battalions\nroyal_australian_air_force  raaf  australian_imperial_force  distinguished_flying_cross  distinguished_service_order\nmanga  anime  anime_news_network  famitsu  serialized\nrotten_tomatoes  roger_ebert  film  screenplay  grossing\nwaterline  conning  turrets  boilers  amidships\nnovel  novels  homer  warren_martyn  simpsons\nchronicler  archbishop  bishops  heir  archbishop_of_canterbury\namidships  ships  conning  ship  torpedoed\ncommunist  soviet_union  coup  communists  nationalist\ninvestigators  testified  prosecution  police  prosecutors\nepisode  dana_scully  robert_shearman  gillian_anderson  fox_mulder\nalbum  albums  guitarist  band  bassist\nastronomers  orbit  brightest  orbiting  orbital\ntrains  electrified  railway  traffic  terminus\nrenumbering  intersection  intersects  intersections  national_highway_system\nuefa  relegation  club  footballer  midfielder\nringo_starr  george_harrison  beatles  simon_leng  guitarist\ntropical  landfall  cyclone  utc  weakening\nflows  tributaries  tributary  watershed  hiking\nrace  lap  laps  drivers  riders\nfuselage  engine  cockpit  airframe  aerodynamic\ncampus  alumni  faculty  students  undergraduate\ndemographics  census  capita  united_states_census_bureau  köppen\ncontinental_army  expedition  militia  frigate  musket\nwicket  match  wrestlers  matches  innings\nspore  basidia  spores  mycologist  hyphae\ntouchdowns  quarterback  touchdown  yards  offense\ncoaster  roller  ride  coasters  national_register_of_historic_places\naircraft  bombers  bomber  pilots  destroyers\nmint  numismatic  obverse  coin  coins\nstorylines  episode  viewers  realises  alan_sepinwall\nrepublican  democratic  democrat  democratic_party  republicans\nlyrically  certifications  mtv_news  sal_cinquemani  chart\ngameplay  gamespot  graphics  game  multiplayer\n\n\n====nytimes (125)====\nalpha_0.01-lr_0.01-h2dim_0-reg_0.1-epochs_500-anneal_bn_200-anneal_kl_200\nbridegroom  officiated  laude  bride  cum\ninc  6mo  earns  otc  rev\nshareholders  earnings  federated  mci  shares\njustices  jurors  supreme_court  united_states_court_of_appeals  justice\nabc  nbc  cbs  nielsen  viewers\ncondolences  mourns  mourn  board_of_directors  heartfelt\npaintings  sculptures  galleries  picasso  sculpture\ndow  tenths  index  stocks  federal_reserve\ninterment  nee  cherished  loving  adored\nmedicaid  medicare  hospitals  welfare  uninsured\ndetectives  precinct  police  robbery  police_department\nteachers  curriculum  regents  educators  graders\nskirts  dresses  chanel  couture  fashion\nalbum  pareles  albums  songs  guitar\narafat  hamas  gaza  palestinians  west_bank\nairlines  airline  fares  passengers  federal_aviation_administration\ndinkins  giuliani  ferrer  bloomberg  vallone\ntouchdown  touchdowns  quarterback  parcells  linebacker\nrhp  lhp  ahl  optioned  pcl\nspecies  wildlife  salmon  fishermen  fishing\nknopf  bantam  random_house  harpercollins  giroux\ntablespoons  teaspoon  servings  tablespoon  garlic\nenron  stocks  investors  hedge  derivatives\ntenants  tenant  zoning  rents  landlords\nbishops  catholics  pope  priests  vatican\nserbs  serbian  serb  bosnian  sunni\nmicrosoft  google  desktop  macintosh  software\nlewinsky  meese  starr  gotti  prosecutors\nrebounds  knicks  nets  ewing  lakers\naddenda  billings  omnicom_group  interpublic_group_of_companies  interpublic\naristide  gorbachev  yeltsin  khmer_rouge  communist_party\ngardeners  bulbs  foliage  shrubs  gardening\nspade  derby  belmont  colt  spades\ninc  otc  qtr  earns  rev\nnasa  emissions  dioxide  ozone  spacecraft\npg-13  screenplay  film  films  comedy\ngenes  cells  vaccine  virus  infected\ngrandchildren  survived  obituary  died  lieu\ninc  9mo  earns  otc  qtr\nconcerto  balanchine  mozart  orchestra  brahms\nsaturdays  tuesdays  fridays  sundays  thursdays\nbathrooms  bath  bedrooms  fireplace  broker\nyea  nay  gore  dukakis  kerry\ndevils  islanders  puck  rangers  defenseman\ntreas  telerate  yield  bonds  municipal_bond_index\nmedicare  republicans  gingrich  social_security  senate\ninning  innings  torre  mets  hitter\nwines  wine  cabernet  bordeaux  vineyards\nnorth_korea  missiles  security_council  nuclear  warheads\ntariffs  exports  international_monetary_fund  imports  world_bank\n"
     ]
    }
   ],
   "source": [
    "for idx, row in sorted_dvae.iterrows():\n",
    "    print(f\"\\n\\n===={row.input_dir} ({idx})====\\n{Path(row.path).parent.name}\")\n",
    "    for topic in row.topics:\n",
    "        print(\"  \".join(topic[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     c_v_full  c_v_full_sd     tu        to  mean_c_v_full_tu  overlaps  \\\n",
       "36   0.682233     0.097854  0.718  0.291327          0.700117         0   \n",
       "102  0.696388     0.111192  0.764  0.202551          0.730194         0   \n",
       "\n",
       "     alpha  beta input_dir  iterations  run_seeds  \\\n",
       "36    1.00  0.10  wikitext        2000      11235   \n",
       "102   0.05  0.01   nytimes        1000      11235   \n",
       "\n",
       "                                                topics  \\\n",
       "36   [[division, north, battalion, forces, attack, ...   \n",
       "102  [[water, miles, town, day, people, island, par...   \n",
       "\n",
       "                                                  path  \n",
       "36   outputs/full-mindf_power_law-maxdf_0.9/wikitex...  \n",
       "102  outputs/full-mindf_power_law-maxdf_0.9/nytimes...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>c_v_full</th>\n      <th>c_v_full_sd</th>\n      <th>tu</th>\n      <th>to</th>\n      <th>mean_c_v_full_tu</th>\n      <th>overlaps</th>\n      <th>alpha</th>\n      <th>beta</th>\n      <th>input_dir</th>\n      <th>iterations</th>\n      <th>run_seeds</th>\n      <th>topics</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>36</th>\n      <td>0.682233</td>\n      <td>0.097854</td>\n      <td>0.718</td>\n      <td>0.291327</td>\n      <td>0.700117</td>\n      <td>0</td>\n      <td>1.00</td>\n      <td>0.10</td>\n      <td>wikitext</td>\n      <td>2000</td>\n      <td>11235</td>\n      <td>[[division, north, battalion, forces, attack, ...</td>\n      <td>outputs/full-mindf_power_law-maxdf_0.9/wikitex...</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>0.696388</td>\n      <td>0.111192</td>\n      <td>0.764</td>\n      <td>0.202551</td>\n      <td>0.730194</td>\n      <td>0</td>\n      <td>0.05</td>\n      <td>0.01</td>\n      <td>nytimes</td>\n      <td>1000</td>\n      <td>11235</td>\n      <td>[[water, miles, town, day, people, island, par...</td>\n      <td>outputs/full-mindf_power_law-maxdf_0.9/nytimes...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "sorted_mallet = (mallet_results.loc[mallet_results.overlaps == 0]\n",
    "                .sort_values([\"input_dir\", coherence_measure], ascending=False)\n",
    "                .groupby(\"input_dir\").head(1))\n",
    "sorted_mallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\n====wikitext (36)====\nalpha_1.0-beta_0.1-iter_2000-opt_0\ndivision  north  battalion  forces  attack\nspecies  found  large  females  long\nseason  game  games  home  baseball\nspecies  birds  white  bird  black\nship  ships  british  french  island\nfrench  army  war  battle  men\nband  album  music  song  rock\nstation  line  bridge  railway  construction\ncourt  law  case  police  act\nschool  students  university  college  year\nfilm  films  production  role  million\nwomen  work  god  social  world\nchinese  china  government  language  country\nmatch  event  world  team  championship\nnuclear  water  gas  metal  high\ncharacter  characters  story  series  love\nroute  highway  road  state  north\nbook  published  work  story  books\ndisease  cells  cell  blood  people\ngame  season  yards  yard  team\nepisode  series  season  doctor  episodes\nking  england  english  royal  scotland\nclub  season  team  cup  league\nepisode  season  series  television  viewers\naircraft  flight  air  engine  design\nbuilding  built  century  house  site\nindia  temple  century  indian  king\nship  ships  guns  war  class\nsong  video  number  music  single\ncompany  million  market  system  year\nrace  stage  time  lap  team\nhorses  horse  breed  dog  animals\nstar  earth  system  formula  planet\ncity  town  area  population  local\ntelevision  people  media  year  time\nwater  area  river  park  miles\naustralia  test  match  england  runs\nemperor  city  army  greek  roman\nwar  japanese  squadron  aircraft  air\nspecies  brown  shark  cap  found\namerican  united_states  war  washington  state\nalbum  music  song  released  number\nepisode  homer  series  season  simpsons\ngame  games  player  released  series\nwar  government  german  military  soviet\nelection  president  government  state  party\nstorm  tropical  hurricane  winds  damage\nmusic  work  works  art  musical\nseason  team  game  games  points\nfamily  years  life  time  father\n\n\n====nytimes (102)====\nalpha_0.05-beta_0.01-iter_1000-opt_10\nwater  miles  town  day  people\nart  museum  work  artist  artists\nmusic  band  songs  jazz  rock\nhealth  care  medical  drug  hospital\nmoney  bank  fund  companies  financial\ncase  trial  charges  judge  investigation\nchildren  women  child  family  woman\ndisease  people  study  aids  cancer\nunited_states  american  china  japan  world\nyankees  game  baseball  season  mets\nworld  year  won  team  round\ncity  mayor  black  new_york_city  white\npercent  year  market  prices  rate\nnet  share  earns  company  reports\nchurch  religious  jewish  gay  people\nfashion  store  black  white  clothes\nminutes  add  oil  salt  cup\npolice  officers  yesterday  man  year\ncampaign  state  election  governor  political\neditor  book  books  article  page\nstreet  tickets  sunday  avenue  information\nofficials  united_states  american  government  security\npeople  time  years  day  year\ngame  season  coach  team  football\ntelevision  advertising  media  news  million\nschool  students  schools  education  college\ntax  year  million  state  budget\ncompany  million  companies  percent  business\ntime  world  people  life  good\niraq  war  military  american  united_states\ncomputer  internet  technology  web  software\nnew_york  son  daughter  president  father\nbedroom  room  bath  taxes  year\ncar  cars  train  drivers  traffic\ngovernment  political  president  minister  soviet\nplants  garden  trees  species  animals\nmusic  dance  opera  program  work\ntravel  hotel  airport  flight  airline\nfamily  beloved  wife  husband  late\nrestaurant  wine  food  restaurants  dinner\ngame  team  season  points  games\nofficials  board  yesterday  union  members\nisrael  israeli  palestinian  peace  palestinians\noil  water  power  energy  gas\nbuilding  city  street  square  buildings\nrace  year  won  horse  racing\npresident  bush  clinton  senate  congress\nwar  military  american  soldiers  troops\nlaw  court  state  judge  federal\nfilm  movie  theater  play  director\n"
     ]
    }
   ],
   "source": [
    "for idx, row in sorted_mallet.iterrows():\n",
    "    print(f\"\\n\\n===={row.input_dir} ({idx})====\\n{Path(row.path).parent.name}\")\n",
    "    for topic in row.topics:\n",
    "        print(\"  \".join(topic[:5]))"
   ]
  },
  {
   "source": [
    "Diagnosing nans:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "bad_words = Counter()\n",
    "n_bad_topics = 0\n",
    "for p in dvae_paths:\n",
    "    coherences = load_json(p)\n",
    "    try:\n",
    "        final_coherence = list(coherences[coherence_measure].values())[-1]\n",
    "    except KeyError:\n",
    "        final_coherence = list(coherences['c_npmi_10_full'].values())[-1]\n",
    "        print(f\"Missing coherence for {p.parent}, {final_coherence['aggregate']:0.3f}\")\n",
    "    topics = load_text(final_coherence[\"path\"])\n",
    "    bad_coherence = np.isnan(final_coherence[\"by_topic\"]) | np.isinf(final_coherence[\"by_topic\"])\n",
    "    #bad_coherence = np.isnan(final_coherence[\"by_topic\"])\n",
    "    if bad_coherence.sum() == 0:\n",
    "        continue\n",
    "    bad_topics = [topic for i, topic in enumerate(topics) if bad_coherence[i]]\n",
    "    print(f\"\\n\\n{p}\")\n",
    "    for bad_topic in bad_topics:\n",
    "        print(\" \".join(bad_topic[:10]))\n",
    "        bad_words.update(bad_topic[:10])\n",
    "        n_bad_topics += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(25,\n",
       " [('paula_vitaris', 22),\n",
       "  ('dana_scully', 18),\n",
       "  ('fox_mulder', 18),\n",
       "  ('gillian_anderson', 17),\n",
       "  ('lars_pearson', 15),\n",
       "  ('robert_shearman', 14),\n",
       "  ('mulder', 14),\n",
       "  ('scully', 14),\n",
       "  ('frank_spotnitz', 12),\n",
       "  ('david_duchovny', 10)])"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "n_bad_topics, bad_words.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}