{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd0724588c769277eec1559a818f4d33dcaba65e848ce2ee61833dc206a0b8113e6",
   "display_name": "Python 3.9.4 64-bit ('topic-evaluation': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "724588c769277eec1559a818f4d33dcaba65e848ce2ee61833dc206a0b8113e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "sys.path.append(\"/workspace/topic-preprocessing/soup_nuts/models/dvae/\")\n",
    "from utils import compute_to, compute_tu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path):\n",
    "    with open(path) as infile:\n",
    "        return json.load(infile)\n",
    "\n",
    "def load_yaml(path):\n",
    "    with open(path) as infile:\n",
    "        return yaml.load(infile, Loader=yaml.FullLoader)\n",
    "\n",
    "def load_text(path):\n",
    "    with open(path) as infile:\n",
    "        return [text.strip().split(\" \") for text in infile]\n",
    "\n",
    "def save_json(obj, path):\n",
    "    with open(path, 'w') as outfile:\n",
    "        return json.dump(obj, outfile, indent=2)"
   ]
  },
  {
   "source": [
    "## Coherences Computed Outside with calculate_coherence.py"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = \"./outputs/full-mindf_power_law-maxdf_0.9\"\n",
    "#run_dir = \"./outputs/vocab_25k-mindf_0.0001_or_3-maxdf_0.9\"\n",
    "coherence_measure = \"c_npmi_10_full\" # npmi test, npmi full yield same results\n",
    "\n",
    "overlapping_word_threshold = 5\n",
    "diversity_top_n = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_paths = [p for p in Path(run_dir).glob(\"**/mallet/**/coherences.json\")]\n",
    "dvae_paths = [p for p in Path(run_dir).glob(\"**/dvae/**/coherences.json\")]\n",
    "etm_paths = [p for p in Path(run_dir).glob(\"**/etm/**/coherences.json\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = Path(run_dir).name\n",
    "input_dir_map = {\n",
    "    f\"/workspace/topic-preprocessing/data/nytimes/processed/{run_name}\": \"nytimes\",\n",
    "    f\"/workspace/topic-preprocessing/data/wikitext/processed/{run_name}\": \"wikitext\",\n",
    "    f\"/workspace/topic-preprocessing/data/bbc/processed/{run_name}\": \"bbc\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_config_keys = ['alpha', 'beta', 'input_dir', 'run_seeds', 'iterations']\n",
    "mallet_results = []\n",
    "for p in mallet_paths:\n",
    "    coherences = load_json(p)\n",
    "    config = {k: v for k, v in load_yaml(p.parent / \"config.yml\").items() if k in mallet_config_keys}\n",
    "    config[\"input_dir\"] = input_dir_map[config[\"input_dir\"]] # dvae, mallet\n",
    "        \n",
    "    # select last coherence, TODO: select best among all if desired\n",
    "    final_coherence = list(coherences[coherence_measure].values())[-1]\n",
    "    # get coherence for top 5/15 words if available\n",
    "    # (not used for model selection, just reference)\n",
    "    missing_result = {None: {\"by_topic\": -np.inf}}\n",
    "    coh_5 = list(coherences.get(f\"{coherence_measure}_top5\", missing_result).values())[-1]\n",
    "    coh_15 = list(coherences.get(f\"{coherence_measure}_top15\", missing_result).values())[-1]\n",
    "\n",
    "    topics = load_text(final_coherence[\"path\"])\n",
    "    to, overlaps = compute_to(topics, n=diversity_top_n, return_overlaps=True)\n",
    "    tu = np.mean(compute_tu(topics, n=diversity_top_n))\n",
    "\n",
    "    coh_values = np.nan_to_num(final_coherence[\"by_topic\"], nan=0, posinf=0)\n",
    "    coh_5_values = np.nan_to_num(coh_5[\"by_topic\"], nan=0, posinf=0, neginf=np.nan)\n",
    "    coh_15_values = np.nan_to_num(coh_15[\"by_topic\"], nan=0, posinf=0, neginf=np.nan)\n",
    "    coh_top_n_means = np.mean(np.concatenate([coh_values, coh_5_values, coh_15_values]))\n",
    "    \n",
    "    mallet_results.append({\n",
    "        coherence_measure: np.mean(coh_values),\n",
    "        f\"{coherence_measure}_topn_mean\": coh_top_n_means,\n",
    "        f\"{coherence_measure}_sd\": np.std(coh_values),\n",
    "        \"tu\": tu,\n",
    "        \"to\": to,\n",
    "        f\"mean_{coherence_measure}_tu\": np.mean([tu, final_coherence[\"aggregate\"]]),\n",
    "        \"overlaps\": np.sum(overlaps >= overlapping_word_threshold),\n",
    "        **config,\n",
    "        \"topics\": topics,\n",
    "        f\"{coherence_measure}_all\": coh_values.tolist(),\n",
    "        f\"{coherence_measure}_top5_all\": coh_5_values.tolist(),\n",
    "        \"path\": str(p.parent),\n",
    "    })\n",
    "mallet_results = pd.DataFrame(mallet_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_top_coh = (\n",
    "    mallet_results.loc[mallet_results.overlaps == 0]\n",
    "                  .sort_values([\"input_dir\", coherence_measure], ascending=False)\n",
    "                  .groupby(\"input_dir\").head(1)\n",
    ")\n",
    "mallet_top_topics = {\n",
    "    input_dir: data.to_dict('records')[0]\n",
    "    for input_dir, data in mallet_top_coh.groupby(\"input_dir\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvae_config_keys = [\n",
    "    \"input_dir\",\n",
    "    \"alpha_prior\",\n",
    "    \"learning_rate\",\n",
    "    \"encoder_hidden_dim\",\n",
    "    \"topic_word_regularization\",\n",
    "    \"num_epochs\",\n",
    "    \"epochs_to_anneal_bn\",\n",
    "    \"epochs_to_anneal_kl\",\n",
    "    \"run_seeds\"\n",
    "]\n",
    "\n",
    "dvae_results = []\n",
    "for p in dvae_paths:\n",
    "    coherences = load_json(p)\n",
    "    config = {k: v for k, v in load_yaml(p.parent / \"config.yml\").items() if k in mallet_config_keys}\n",
    "    config[\"input_dir\"] = input_dir_map[config[\"input_dir\"]]\n",
    "    # select last coherence, TODO: select best among all if desired\n",
    "    final_coherence = list(coherences[coherence_measure].values())[-1]\n",
    "    # get coherence for top 5/15 words if available\n",
    "    # (not used for model selection, just reference)\n",
    "    missing_result = {None: {\"by_topic\": -np.inf}}\n",
    "    coh_5 = list(coherences.get(f\"{coherence_measure}_top5\", missing_result).values())[-1]\n",
    "    coh_15 = list(coherences.get(f\"{coherence_measure}_top15\", missing_result).values())[-1]\n",
    "\n",
    "    topics = load_text(final_coherence[\"path\"])\n",
    "    to, overlaps = compute_to(topics, n=diversity_top_n, return_overlaps=True)\n",
    "    tu = np.mean(compute_tu(topics, n=diversity_top_n))\n",
    "\n",
    "    coh_values = np.nan_to_num(final_coherence[\"by_topic\"], nan=0, posinf=0)\n",
    "    coh_5_values = np.nan_to_num(coh_5[\"by_topic\"], nan=0, posinf=0, neginf=np.nan)\n",
    "    coh_15_values = np.nan_to_num(coh_15[\"by_topic\"], nan=0, posinf=0, neginf=np.nan)\n",
    "    coh_top_n_means = np.mean(np.concatenate([coh_values, coh_5_values, coh_15_values]))\n",
    "    \n",
    "    dvae_results.append({\n",
    "        coherence_measure: np.mean(coh_values),\n",
    "        f\"{coherence_measure}_topn_mean\": coh_top_n_means,\n",
    "        f\"{coherence_measure}_sd\": np.std(coh_values),\n",
    "        \"tu\": tu,\n",
    "        \"to\": to,\n",
    "        \"overlaps\": np.sum(overlaps >= overlapping_word_threshold),\n",
    "        **config,\n",
    "        \"topics\": topics,\n",
    "        f\"{coherence_measure}_all\": coh_values.tolist(),\n",
    "        f\"{coherence_measure}_top5_all\": coh_5_values.tolist(),\n",
    "        \"path\": str(p.parent),\n",
    "    })\n",
    "dvae_results = pd.DataFrame(dvae_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvae_top_coh = (\n",
    "    dvae_results.loc[dvae_results.overlaps == 0]\n",
    "                .sort_values([\"input_dir\", coherence_measure], ascending=False)\n",
    "                .groupby(\"input_dir\").head(1)\n",
    ")\n",
    "dvae_top_topics = {\n",
    "    input_dir: data.to_dict('records')[0]\n",
    "    for input_dir, data in dvae_top_coh.groupby(\"input_dir\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "etm_config_keys = [\n",
    "    \"data_path\",\n",
    "    \"lr\",\n",
    "    \"anneal_lr\",\n",
    "    \"wdecay\",\n",
    "    \"epochs\",\n",
    "    \"seed\",\n",
    "]\n",
    "\n",
    "etm_results = []\n",
    "for p in etm_paths:\n",
    "    coherences = load_json(p)\n",
    "    config = {k: v for k, v in load_yaml(p.parent / \"config.yml\").items() if k in etm_config_keys}\n",
    "    config[\"input_dir\"] = input_dir_map[str(Path(config[\"data_path\"]).parent)]\n",
    "\n",
    "    # select last coherence, TODO: select best among all if desired\n",
    "    final_coherence = list(coherences[coherence_measure].values())[-1]\n",
    "    \n",
    "    topics = load_text(final_coherence[\"path\"])\n",
    "    to, overlaps = compute_to(topics, n=diversity_top_n, return_overlaps=True)\n",
    "    tu = np.mean(compute_tu(topics, n=diversity_top_n))\n",
    "\n",
    "    coh_values = np.nan_to_num(final_coherence[\"by_topic\"], nan=0, posinf=0)\n",
    "    \n",
    "    etm_results.append({\n",
    "        coherence_measure: np.mean(coh_values),\n",
    "        f\"{coherence_measure}_sd\": np.std(coh_values),\n",
    "        \"tu\": tu,\n",
    "        \"to\": to,\n",
    "        \"overlaps\": np.sum(overlaps >= overlapping_word_threshold),\n",
    "        **config,\n",
    "        \"topics\": topics,\n",
    "        f\"{coherence_measure}_all\": coh_values.tolist(),\n",
    "        \"path\": str(p.parent),\n",
    "    })\n",
    "etm_results = pd.DataFrame(etm_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "etm_top_coh = (\n",
    "    etm_results.loc[(etm_results.overlaps == 0) & (etm_results.tu > 0.7)]\n",
    "                .sort_values([\"input_dir\", coherence_measure], ascending=False)\n",
    "                .groupby(\"input_dir\").head(1)\n",
    ")\n",
    "etm_top_topics = {\n",
    "    input_dir: data.to_dict('records')[0]\n",
    "    for input_dir, data in etm_top_coh.groupby(\"input_dir\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = Path(\"./results\", Path(run_dir).name)\n",
    "out_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_json(mallet_top_topics, Path(out_path, f\"mallet-topics-best-{coherence_measure}.json\"))\n",
    "#save_json(dvae_top_topics, Path(out_path, f\"dvae-topics-best-{coherence_measure}.json\"))\n",
    "#save_json(etm_top_topics, f\"etm-topics-best-{coherence_measure}.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['c_npmi_10_full', 'c_npmi_10_full_sd', 'tu', 'to', 'overlaps', 'anneal_lr', 'data_path', 'epochs', 'lr', 'seed', 'wdecay', 'input_dir', 'topics', 'c_npmi_10_full_all', 'path'])"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "etm_top_topics['wikitext'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "pd.DataFrame(\n",
    "    [model, dataset, \", \".join(topic[:n])]\n",
    "    for (model, model_topics) in [('mallet',  mallet_top_topics), ('dvae', dvae_top_topics)]\n",
    "    for dataset, dataset_topics in model_topics.items()\n",
    "    for topic in dataset_topics['topics']\n",
    ").to_csv(out_path / f\"topics-best-{coherence_measure}.csv\", index=False)"
   ]
  },
  {
   "source": [
    "```\n",
    "Indices of top runs\n",
    "                      dvae        mallet\n",
    "                      wiki  nyt   wiki    nyt\n",
    "c_npmi_10_full_top5   45    127   12      112\n",
    "c_npmi_10_full [10]   74    130   63      134\n",
    "c_npmi_10_full_top15  66    130   12      100\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "49\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     c_npmi_10_full  c_npmi_10_full_topn_mean  c_npmi_10_full_sd    tu  \\\n",
       "74         0.223753                  0.225674           0.086427  0.94   \n",
       "130        0.253596                  0.261827           0.131670  0.96   \n",
       "\n",
       "           to  overlaps input_dir  run_seeds  \\\n",
       "74   0.055102         0  wikitext         42   \n",
       "130  0.046939         0   nytimes       5591   \n",
       "\n",
       "                                                topics  \\\n",
       "74   [[certifications, mtv_news, australian_recordi...   \n",
       "130  [[bridegroom, officiated, laude, bride, cum, m...   \n",
       "\n",
       "                                    c_npmi_10_full_all  \\\n",
       "74   [0.11697274235210336, 0.21964315492752154, 0.0...   \n",
       "130  [0.3596531982376284, 0.558160615278727, 0.1824...   \n",
       "\n",
       "                               c_npmi_10_full_top5_all  \\\n",
       "74   [0.05529666017500906, 0.18248189566097472, 0.0...   \n",
       "130  [0.4740114149250828, 0.6443805339961176, 0.153...   \n",
       "\n",
       "                                                  path  \n",
       "74   outputs/full-mindf_power_law-maxdf_0.9/wikitex...  \n",
       "130  outputs/full-mindf_power_law-maxdf_0.9/nytimes...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>c_npmi_10_full</th>\n      <th>c_npmi_10_full_topn_mean</th>\n      <th>c_npmi_10_full_sd</th>\n      <th>tu</th>\n      <th>to</th>\n      <th>overlaps</th>\n      <th>input_dir</th>\n      <th>run_seeds</th>\n      <th>topics</th>\n      <th>c_npmi_10_full_all</th>\n      <th>c_npmi_10_full_top5_all</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>74</th>\n      <td>0.223753</td>\n      <td>0.225674</td>\n      <td>0.086427</td>\n      <td>0.94</td>\n      <td>0.055102</td>\n      <td>0</td>\n      <td>wikitext</td>\n      <td>42</td>\n      <td>[[certifications, mtv_news, australian_recordi...</td>\n      <td>[0.11697274235210336, 0.21964315492752154, 0.0...</td>\n      <td>[0.05529666017500906, 0.18248189566097472, 0.0...</td>\n      <td>outputs/full-mindf_power_law-maxdf_0.9/wikitex...</td>\n    </tr>\n    <tr>\n      <th>130</th>\n      <td>0.253596</td>\n      <td>0.261827</td>\n      <td>0.131670</td>\n      <td>0.96</td>\n      <td>0.046939</td>\n      <td>0</td>\n      <td>nytimes</td>\n      <td>5591</td>\n      <td>[[bridegroom, officiated, laude, bride, cum, m...</td>\n      <td>[0.3596531982376284, 0.558160615278727, 0.1824...</td>\n      <td>[0.4740114149250828, 0.6443805339961176, 0.153...</td>\n      <td>outputs/full-mindf_power_law-maxdf_0.9/nytimes...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "print(np.sum(dvae_results.overlaps == 0))\n",
    "sorted_dvae = (dvae_results.loc[dvae_results.overlaps == 0]\n",
    "                .sort_values([\"input_dir\", f\"{coherence_measure}_topn_mean\"], ascending=False)\n",
    "                .groupby(\"input_dir\").head(1))\n",
    "sorted_dvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\n====wikitext (74)====\nalpha_0.01-lr_0.01-h2dim_0-reg_0.0-epochs_500-anneal_bn_1-anneal_kl_100\ntropical  landfall  cyclone  utc  weakening\nspore  basidia  spores  mycologist  hyphae\nmint  numismatic  obverse  coin  coins\nepisode  dana_scully  robert_shearman  gillian_anderson  fox_mulder\nnhl  national_hockey_league  playoffs  american_hockey_league  hockey\nwaterline  conning  turrets  boilers  amidships\ntouchdowns  quarterback  touchdown  yards  offense\nlandfall  gusts  flooding  hurricane  winds\nringo_starr  george_harrison  beatles  simon_leng  guitarist\nrepublican  democratic  democrat  democratic_party  republicans\ngameplay  gamespot  graphics  game  multiplayer\nrenumbering  intersection  intersects  intersections  national_highway_system\nmanhattan_project  los_alamos_laboratory  robert_oppenheimer  enrico_fermi  physicist\ninfantry  flank  casualties  battalion  battalions\naircraft  bombers  bomber  pilots  destroyers\nastronomers  orbit  brightest  orbiting  orbital\nmanga  anime  anime_news_network  famitsu  serialized\nsupreme_court  constitutional  courts  statutory  statute\nwicket  match  wrestlers  matches  innings\ncomposer  composers  orchestral  opera  soloists\ntrains  electrified  railway  traffic  terminus\ninvestigators  testified  prosecution  police  prosecutors\nhindu  inscriptions  dynasty  deity  temple\nalbum  albums  guitarist  band  bassist\nroyal_australian_air_force  raaf  australian_imperial_force  distinguished_flying_cross  distinguished_service_order\nfuselage  engine  cockpit  airframe  aerodynamic\njuveniles  females  iucn  males  species\nstonework  nave  castle  vaulted  architectural\nalbum  certifications  chart  billboard  recording_industry_association_of_america\nrotten_tomatoes  roger_ebert  film  screenplay  grossing\namidships  ships  conning  ship  torpedoed\nuefa  relegation  club  footballer  midfielder\nflows  tributaries  tributary  watershed  hiking\ncommunist  soviet_union  coup  communists  nationalist\nfilm  filmography  screenplay  roger_ebert  times_of_india\nepidemiology  symptoms  clinical  diagnosis  therapy\ntheory  philosopher  empirical  philosophers  thinkers\ncoaster  roller  ride  coasters  national_register_of_historic_places\nchronicler  archbishop  bishops  heir  archbishop_of_canterbury\npainting  paintings  painter  literary  poems\nrace  lap  laps  drivers  riders\nstorylines  episode  viewers  realises  alan_sepinwall\ncampus  alumni  faculty  students  undergraduate\ncertifications  mtv_news  australian_recording_industry_association  chart  sal_cinquemani\nlyrically  certifications  mtv_news  sal_cinquemani  chart\ncontinental_army  expedition  militia  frigate  musket\nnovel  novels  homer  warren_martyn  simpsons\nhouse_of_commons  church_of_england  protestant  highness  queen_victoria\ndemographics  census  capita  united_states_census_bureau  köppen\ndemography  parish  constituency  councillors  domesday\n\n\n====nytimes (130)====\nalpha_0.01-lr_0.01-h2dim_0-reg_0.1-epochs_500-anneal_bn_200-anneal_kl_200\ninc  otc  qtr  earns  rev\ninc  6mo  earns  otc  rev\ninc  9mo  earns  otc  qtr\nsaturdays  tuesdays  fridays  sundays  thursdays\narafat  hamas  gaza  palestinians  west_bank\ntablespoons  teaspoon  servings  tablespoon  garlic\ncondolences  mourns  mourn  board_of_directors  heartfelt\nbathrooms  bath  bedrooms  fireplace  broker\nbridegroom  officiated  laude  bride  cum\nwines  wine  cabernet  bordeaux  vineyards\nbishops  catholics  pope  priests  vatican\naddenda  billings  omnicom_group  interpublic_group_of_companies  interpublic\ninning  innings  torre  mets  hitter\nskirts  dresses  chanel  couture  fashion\ninterment  nee  cherished  loving  adored\ntouchdown  touchdowns  quarterback  parcells  linebacker\npaintings  sculptures  galleries  picasso  sculpture\nrebounds  knicks  nets  ewing  lakers\nmicrosoft  google  desktop  macintosh  software\nabc  nbc  cbs  nielsen  viewers\nconcerto  balanchine  mozart  orchestra  brahms\nalbum  pareles  albums  songs  guitar\nspecies  wildlife  salmon  fishermen  fishing\nnorth_korea  missiles  security_council  nuclear  warheads\ngardeners  bulbs  foliage  shrubs  gardening\ntenants  tenant  zoning  rents  landlords\ndetectives  precinct  police  robbery  police_department\nknopf  bantam  random_house  harpercollins  giroux\nteachers  curriculum  regents  educators  graders\ngenes  cells  vaccine  virus  infected\npg-13  screenplay  film  films  comedy\njustices  jurors  supreme_court  united_states_court_of_appeals  justice\nmedicare  republicans  gingrich  social_security  senate\nenron  stocks  investors  hedge  derivatives\nserbs  serbian  serb  bosnian  sunni\ntariffs  exports  international_monetary_fund  imports  world_bank\ndinkins  giuliani  ferrer  bloomberg  vallone\nshareholders  earnings  federated  mci  shares\nairlines  airline  fares  passengers  federal_aviation_administration\ndow  tenths  index  stocks  federal_reserve\nnasa  emissions  dioxide  ozone  spacecraft\ngrandchildren  survived  obituary  died  lieu\nlewinsky  meese  starr  gotti  prosecutors\nmedicaid  medicare  hospitals  welfare  uninsured\ntreas  telerate  yield  bonds  municipal_bond_index\nrhp  lhp  ahl  optioned  pcl\naristide  gorbachev  yeltsin  khmer_rouge  communist_party\nyea  nay  gore  dukakis  kerry\ndevils  islanders  puck  rangers  defenseman\nspade  derby  belmont  colt  spades\n"
     ]
    }
   ],
   "source": [
    "for idx, row in sorted_dvae.iterrows():\n",
    "    print(f\"\\n\\n===={row.input_dir} ({idx})====\\n{Path(row.path).parent.name}\")\n",
    "    for coh, topic in sorted(zip(row[f\"{coherence_measure}_all\"], row[\"topics\"]), key=lambda kv: -kv[0]):\n",
    "        print(\"  \".join(topic[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "156\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     c_npmi_10_full  c_npmi_10_full_topn_mean  c_npmi_10_full_sd     tu  \\\n",
       "63         0.135579                  0.136785           0.051036  0.760   \n",
       "134        0.158110                  0.157084           0.079265  0.816   \n",
       "\n",
       "           to  mean_c_npmi_10_full_tu  overlaps  alpha  beta input_dir  \\\n",
       "63   0.247959                0.447789         0   1.00  0.05  wikitext   \n",
       "134  0.197449                0.487055         0   0.25  0.10   nytimes   \n",
       "\n",
       "     iterations  run_seeds                                             topics  \\\n",
       "63         2000         42  [[water, area, river, park, miles, years, feet...   \n",
       "134        1000      11235  [[oil, water, plant, environmental, gas, power...   \n",
       "\n",
       "                                    c_npmi_10_full_all  \\\n",
       "63   [0.09887072076525676, 0.14084096323202053, 0.1...   \n",
       "134  [0.09673317404139083, 0.17755340952100082, 0.1...   \n",
       "\n",
       "                               c_npmi_10_full_top5_all  \\\n",
       "63   [0.15049582125247446, 0.24808454580946612, 0.1...   \n",
       "134  [0.1439363657411738, 0.17843608064157981, 0.24...   \n",
       "\n",
       "                                                  path  \n",
       "63   outputs/full-mindf_power_law-maxdf_0.9/wikitex...  \n",
       "134  outputs/full-mindf_power_law-maxdf_0.9/nytimes...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>c_npmi_10_full</th>\n      <th>c_npmi_10_full_topn_mean</th>\n      <th>c_npmi_10_full_sd</th>\n      <th>tu</th>\n      <th>to</th>\n      <th>mean_c_npmi_10_full_tu</th>\n      <th>overlaps</th>\n      <th>alpha</th>\n      <th>beta</th>\n      <th>input_dir</th>\n      <th>iterations</th>\n      <th>run_seeds</th>\n      <th>topics</th>\n      <th>c_npmi_10_full_all</th>\n      <th>c_npmi_10_full_top5_all</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>63</th>\n      <td>0.135579</td>\n      <td>0.136785</td>\n      <td>0.051036</td>\n      <td>0.760</td>\n      <td>0.247959</td>\n      <td>0.447789</td>\n      <td>0</td>\n      <td>1.00</td>\n      <td>0.05</td>\n      <td>wikitext</td>\n      <td>2000</td>\n      <td>42</td>\n      <td>[[water, area, river, park, miles, years, feet...</td>\n      <td>[0.09887072076525676, 0.14084096323202053, 0.1...</td>\n      <td>[0.15049582125247446, 0.24808454580946612, 0.1...</td>\n      <td>outputs/full-mindf_power_law-maxdf_0.9/wikitex...</td>\n    </tr>\n    <tr>\n      <th>134</th>\n      <td>0.158110</td>\n      <td>0.157084</td>\n      <td>0.079265</td>\n      <td>0.816</td>\n      <td>0.197449</td>\n      <td>0.487055</td>\n      <td>0</td>\n      <td>0.25</td>\n      <td>0.10</td>\n      <td>nytimes</td>\n      <td>1000</td>\n      <td>11235</td>\n      <td>[[oil, water, plant, environmental, gas, power...</td>\n      <td>[0.09673317404139083, 0.17755340952100082, 0.1...</td>\n      <td>[0.1439363657411738, 0.17843608064157981, 0.24...</td>\n      <td>outputs/full-mindf_power_law-maxdf_0.9/nytimes...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "print(np.sum(mallet_results.overlaps == 0))\n",
    "\n",
    "sorted_mallet = (mallet_results.loc[mallet_results.overlaps == 0]\n",
    "                .sort_values([\"input_dir\", coherence_measure], ascending=False)\n",
    "                .groupby(\"input_dir\").head(1))\n",
    "sorted_mallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\n====wikitext (63)====\nalpha_1.0-beta_0.05-iter_2000-opt_500\nroute  highway  road  state  north\nclub  season  team  cup  match\nalbum  band  music  song  released\ntropical  storm  hurricane  cyclone  depression\nsong  album  number  video  music\naustralia  test  match  england  australian\naircraft  air  flight  squadron  war\narab  muslim  israel  egypt  jewish\ngame  team  season  yards  yard\nseason  game  team  games  league\nstorm  damage  hurricane  people  winds\nstation  line  bridge  railway  trains\nepisode  homer  season  series  simpsons\nschool  students  university  college  year\nmatch  championship  team  event  title\nbook  published  story  work  writing\nmusic  musical  opera  works  composer\nbuilding  built  century  house  site\nelection  president  state  government  party\nspecies  brown  fruit  cap  plants\ndisease  cells  blood  cell  risk\nforces  war  attack  division  troops\nbritish  ship  ships  french  island\nepisode  series  doctor  mulder  character\nspecies  birds  males  females  bird\nhorses  horse  breed  coins  silver\nepisode  season  series  episodes  character\narmy  emperor  city  battle  war\nspecies  found  animals  large  long\nworld  won  race  games  time\ncity  town  area  population  local\ngame  player  games  released  players\nship  ships  guns  war  class\nfilm  films  production  role  million\nwar  government  german  military  soviet\nlaw  court  act  government  case\nwater  area  river  park  miles\nking  england  english  royal  scotland\nart  white  painting  work  flag\nearth  star  mass  formula  planet\nrace  stage  lap  team  time\nindia  temple  indian  century  king\nfamily  life  years  time  father\npolice  people  found  death  prison\nsystem  design  power  production  engine\namerican  war  united_states  washington  new_york\nchinese  china  century  government  world\nseries  character  story  characters  bond\nwomen  god  social  people  world\nmillion  company  year  announced  business\n\n\n====nytimes (134)====\nalpha_0.25-beta_0.1-iter_1000-opt_10\nnet  share  earns  company  reports\nfamily  beloved  wife  husband  late\nbedroom  room  bath  taxes  year\nmusic  band  songs  jazz  rock\nbill  senate  congress  house  republican\ngame  rangers  team  season  goal\ngame  season  giants  yards  team\ngame  points  team  knicks  season\npercent  bonds  million  rate  bond\nstreet  tickets  sunday  avenue  information\nminutes  add  salt  oil  cup\ncase  trial  charges  judge  federal\ncampaign  election  political  republican  party\nyankees  game  mets  season  run\nhealth  drug  patients  medical  people\nwar  military  american  iraq  officials\nart  work  museum  artist  artists\nrestaurant  wine  food  restaurants  dinner\ntelevision  network  news  cable  nbc\npercent  year  market  prices  economy\npresident  bush  clinton  administration  white_house\nisrael  israeli  peace  palestinian  united_nations\nschool  students  children  schools  education\ntravel  airport  flight  airline  hotel\nmusic  dance  opera  program  work\ncourt  law  judge  case  state\nfilm  theater  movie  play  director\nunited_states  american  china  japan  trade\ncomputer  internet  technology  web  software\nbank  money  fund  stock  banks\nnew_york  son  father  daughter  died\nbook  books  life  author  history\nyear  players  contract  team  coach\narticle  page  editor  advertising  president\nscientists  research  space  science  human\nyear  won  world  round  race\npolice  officers  yesterday  man  year\ncompany  million  companies  business  percent\ntax  year  percent  million  money\noil  water  plant  environmental  gas\ncar  cars  ford  auto  vehicles\nlife  story  man  love  young\ncity  mayor  state  new_york  new_york_city\ngovernment  political  minister  soviet  president\nbuilding  city  street  square  buildings\nofficials  board  report  union  members\nblack  women  church  white  people\nwater  year  trees  summer  miles\npeople  time  day  years  home\npeople  editor  time  world  good\n"
     ]
    }
   ],
   "source": [
    "for idx, row in sorted_mallet.iterrows():\n",
    "    print(f\"\\n\\n===={row.input_dir} ({idx})====\\n{Path(row.path).parent.name}\")\n",
    "    for coh, topic in sorted(zip(row[f\"{coherence_measure}_all\"], row[\"topics\"]), key=lambda kv: -kv[0]):\n",
    "        print(\"  \".join(topic[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "143\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    c_npmi_10_full  c_npmi_10_full_sd     tu        to  overlaps  anneal_lr  \\\n",
       "56        0.113287           0.067950  0.940  0.030612         0          0   \n",
       "96        0.113789           0.090883  0.904  0.077041         0          0   \n",
       "\n",
       "                                            data_path  epochs     lr   seed  \\\n",
       "56  /workspace/topic-preprocessing/data/wikitext/p...    1000  0.001     42   \n",
       "96  /workspace/topic-preprocessing/data/nytimes/pr...    1000  0.020  11235   \n",
       "\n",
       "      wdecay input_dir                                             topics  \\\n",
       "56  0.000012  wikitext  [[new, use, development, world, design, create...   \n",
       "96  0.000001   nytimes  [[campaign, bush, clinton, vote, state, congre...   \n",
       "\n",
       "                                   c_npmi_10_full_all  \\\n",
       "56  [0.03828346256626948, 0.1038583234675748, 0.01...   \n",
       "96  [0.14624615320916104, 0.1842349463761919, 0.09...   \n",
       "\n",
       "                                                 path  \n",
       "56  outputs/full-mindf_power_law-maxdf_0.9/wikitex...  \n",
       "96  outputs/full-mindf_power_law-maxdf_0.9/nytimes...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>c_npmi_10_full</th>\n      <th>c_npmi_10_full_sd</th>\n      <th>tu</th>\n      <th>to</th>\n      <th>overlaps</th>\n      <th>anneal_lr</th>\n      <th>data_path</th>\n      <th>epochs</th>\n      <th>lr</th>\n      <th>seed</th>\n      <th>wdecay</th>\n      <th>input_dir</th>\n      <th>topics</th>\n      <th>c_npmi_10_full_all</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>56</th>\n      <td>0.113287</td>\n      <td>0.067950</td>\n      <td>0.940</td>\n      <td>0.030612</td>\n      <td>0</td>\n      <td>0</td>\n      <td>/workspace/topic-preprocessing/data/wikitext/p...</td>\n      <td>1000</td>\n      <td>0.001</td>\n      <td>42</td>\n      <td>0.000012</td>\n      <td>wikitext</td>\n      <td>[[new, use, development, world, design, create...</td>\n      <td>[0.03828346256626948, 0.1038583234675748, 0.01...</td>\n      <td>outputs/full-mindf_power_law-maxdf_0.9/wikitex...</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>0.113789</td>\n      <td>0.090883</td>\n      <td>0.904</td>\n      <td>0.077041</td>\n      <td>0</td>\n      <td>0</td>\n      <td>/workspace/topic-preprocessing/data/nytimes/pr...</td>\n      <td>1000</td>\n      <td>0.020</td>\n      <td>11235</td>\n      <td>0.000001</td>\n      <td>nytimes</td>\n      <td>[[campaign, bush, clinton, vote, state, congre...</td>\n      <td>[0.14624615320916104, 0.1842349463761919, 0.09...</td>\n      <td>outputs/full-mindf_power_law-maxdf_0.9/nytimes...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "print(np.sum((etm_results.overlaps == 0) & (etm_results.tu > 0.7)))\n",
    "\n",
    "sorted_etm = (etm_results.loc[(etm_results.overlaps == 0) & (etm_results.tu > 0.7)]\n",
    "                .sort_values([\"input_dir\", coherence_measure], ascending=False)\n",
    "                .groupby(\"input_dir\").head(1))\n",
    "sorted_etm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\n====wikitext (1)====\nlr_0.01-reg_1.2e-06-epochs_1000-anneal_lr_0\noutputs/full-mindf_power_law-maxdf_0.9/../etm_full/wikitext/k-50/etm/lr_0.01-reg_1.2e-06-epochs_1000-anneal_lr_0/5591\nstorm  tropical  hurricane  mph  winds  depression  cyclone\nepisode  series  season  episodes  television  viewers  watched\nroad  route  highway  state  north  bridge  south\nalbum  song  band  music  number  released  songs\nship  aircraft  ships  fleet  squadron  naval  navy\nseason  team  game  league  games  club  scored\nmatch  defeated  championship  team  event  ring  win\nbook  published  work  novel  author  works  books\nbuilding  built  church  site  tower  stone  buildings\nspecies  genus  animal  specimens  specimen  fish  birds\nmusic  performed  performance  musical  rock  performing  concert\nfilm  films  cast  production  movie  released  role\ngovernment  president  state  party  political  minister  election\nearth  mass  planet  chemical  solar  planets  sun\nschool  college  schools  students  years  year  student\nworld  team  cup  won  round  games  final\nforces  war  men  battle  army  division  attack\nstation  line  town  built  construction  street  park\nfrench  german  france  military  war  germany  russian\ngame  player  games  released  players  release  version\nrace  car  seconds  stage  second  lead  ahead\nfamily  life  death  father  children  died  born\nwater  area  river  sea  near  lake  mountain\nking  empire  emperor  roman  battle  army  military\nlanguage  god  christian  religious  religion  temple  ancient\nwrote  love  written  received  critics  writing  featured\nlaw  court  police  case  trial  act  legal\ncharacter  characters  story  plot  storyline  kill  tells\nmarch  june  april  november  january  december  october\nengland  london  king  english  british  century  royal\nserved  joined  training  staff  captain  service  chief\nguns  class  design  gun  long  fire  tons\nsystem  space  theory  systems  model  function  element\nstyle  art  silver  painting  pieces  artist  contemporary\nsecond  played  best  final  play  career  series\ncompany  business  financial  public  cost  tax  pay\nhuman  evidence  social  report  health  research  issues\nsaid  like  described  felt  stated  way  good\namerican  million  united_states  world  japan  california  canada\ncity  century  local  population  land  state  west\ntook  left  forced  able  return  sent  attempted\nwork  original  development  produced  production  based  included\nfound  known  white  black  long  like  small\naustralia  australian  american  new_york  washington  new_zealand  harrison\nexample  order  use  increase  process  lack  free\nman  live  night  weeks  room  home  going\nnew  use  number  including  large  different  increased\nled  group  war  began  support  members  general\ntime  later  years  new  called  early  including\npeople  power  point  caused  reported  states  instead\n\n\n====nytimes (22)====\nlr_0.02-reg_1.2e-07-epochs_1000-anneal_lr_0\noutputs/full-mindf_power_law-maxdf_0.9/../etm_full/nytimes/k-50/etm/lr_0.02-reg_1.2e-07-epochs_1000-anneal_lr_0/11235\nnet  share  inc  company  earns  reports  loss\nwife  family  died  late  devoted  husband  services\nstreet  avenue  manhattan  room  west  east  taxes\nmusic  dance  rock  concert  jazz  band  pop\nart  museum  century  artist  artists  exhibition  works\nisrael  political  minister  prime  peace  soviet  israeli\nmedical  drug  health  doctors  study  patients  drugs\npresident  campaign  bush  political  vote  clinton  election\ngame  team  season  games  play  player  players\nnew_york  father  son  daughter  graduated  received  married\ninternet  technology  computer  web  computers  cable  system\npresident  director  chief  chairman  board  washington  named\nfood  wine  restaurant  bread  cooking  taste  minutes\nstudents  school  schools  college  education  high  class\npercent  market  rates  prices  rate  year  economy\ncase  trial  prison  judge  charges  federal  investigation\nfilm  movie  production  directed  films  plays  theater\nwon  club  cup  win  race  team  match\nbudget  tax  plan  spending  billion  cuts  cut\nmillion  money  financial  bank  billion  investment  stock\ncar  air  miles  cars  flight  traffic  travel\nwar  officials  iraq  military  american  united_states  president\ncoach  points  yards  football  sports  field  basketball\nlaw  court  rights  legal  federal  rules  commission\nbuilding  town  city  space  area  construction  built\nbook  books  world  story  english  wrote  magazine\ncompany  business  companies  amp  executive  executives  chief\nsaid  police  killed  officers  men  dead  fire\neditor  members  article  report  page  news  review\nthink  going  got  want  time  know  way\nwater  trees  tree  hair  foot  feet  inches\nunited_states  american  world  country  government  foreign  international\nchildren  life  family  man  love  home  mother\nday  week  night  days  friday  time  sunday\ntoday  deal  general  meeting  agreement  contract  major\nstate  city  said  officials  mayor  new_york  new_jersey\nyear  years  old  ago  time  half  long\nsecond  run  record  left  final  lost  series\noil  power  water  energy  plant  lines  high\nlike  white  black  work  small  look  hand\npeople  women  world  television  history  men  role\nchange  control  problems  clear  far  problem  term\nsaid  people  year  added  today  going  interview\ndivision_i-  self  human  social  nature  history  struggle\nasked  called  told  time  know  day  talk\nnumber  use  work  help  list  available  free\ncame  took  began  went  found  turned  home\nlike  way  says  time  high  long  end\nnew  group  called  including  work  recent  based\nbest  good  great  long  better  different  real\n"
     ]
    }
   ],
   "source": [
    "for idx, row in sorted_etm.iterrows():\n",
    "    print(f\"\\n\\n===={row.input_dir} ({idx})====\\n{Path(row.path).parent.name}\")\n",
    "    print(row.path)\n",
    "    for coh, topic in sorted(zip(row[f\"{coherence_measure}_all\"], row[\"topics\"]), key=lambda kv: -kv[0]):\n",
    "        print(\"  \".join(topic[:7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                           coh_rank  c_npmi_10_full\n",
       "variable  value                                    \n",
       "anneal_lr 0.00000000     0.35447932      0.10523681\n",
       "lr        0.02000000     0.39542065      0.10235219\n",
       "          0.01000000     0.44740815      0.10200579\n",
       "seed      42.00000000    0.48056081      0.10176129\n",
       "epochs    1000.00000000  0.48056866      0.10095152\n",
       "seed      5591.00000000  0.48074573      0.10085187\n",
       "wdecay    0.00000120     0.49265374      0.09978961\n",
       "          0.00000012     0.50884879      0.10010662\n",
       "          0.00001200     0.51614760      0.10050472\n",
       "epochs    500.00000000   0.53290291      0.09929412\n",
       "lr        0.00100000     0.56284397      0.09966395\n",
       "seed      11235.00000000 0.56411423      0.09747196\n",
       "lr        0.00200000     0.63631944      0.09627949\n",
       "anneal_lr 1.00000000     0.63704059      0.09574387"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>coh_rank</th>\n      <th>c_npmi_10_full</th>\n    </tr>\n    <tr>\n      <th>variable</th>\n      <th>value</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>anneal_lr</th>\n      <th>0.00000000</th>\n      <td>0.35447932</td>\n      <td>0.10523681</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">lr</th>\n      <th>0.02000000</th>\n      <td>0.39542065</td>\n      <td>0.10235219</td>\n    </tr>\n    <tr>\n      <th>0.01000000</th>\n      <td>0.44740815</td>\n      <td>0.10200579</td>\n    </tr>\n    <tr>\n      <th>seed</th>\n      <th>42.00000000</th>\n      <td>0.48056081</td>\n      <td>0.10176129</td>\n    </tr>\n    <tr>\n      <th>epochs</th>\n      <th>1000.00000000</th>\n      <td>0.48056866</td>\n      <td>0.10095152</td>\n    </tr>\n    <tr>\n      <th>seed</th>\n      <th>5591.00000000</th>\n      <td>0.48074573</td>\n      <td>0.10085187</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">wdecay</th>\n      <th>0.00000120</th>\n      <td>0.49265374</td>\n      <td>0.09978961</td>\n    </tr>\n    <tr>\n      <th>0.00000012</th>\n      <td>0.50884879</td>\n      <td>0.10010662</td>\n    </tr>\n    <tr>\n      <th>0.00001200</th>\n      <td>0.51614760</td>\n      <td>0.10050472</td>\n    </tr>\n    <tr>\n      <th>epochs</th>\n      <th>500.00000000</th>\n      <td>0.53290291</td>\n      <td>0.09929412</td>\n    </tr>\n    <tr>\n      <th>lr</th>\n      <th>0.00100000</th>\n      <td>0.56284397</td>\n      <td>0.09966395</td>\n    </tr>\n    <tr>\n      <th>seed</th>\n      <th>11235.00000000</th>\n      <td>0.56411423</td>\n      <td>0.09747196</td>\n    </tr>\n    <tr>\n      <th>lr</th>\n      <th>0.00200000</th>\n      <td>0.63631944</td>\n      <td>0.09627949</td>\n    </tr>\n    <tr>\n      <th>anneal_lr</th>\n      <th>1.00000000</th>\n      <td>0.63704059</td>\n      <td>0.09574387</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "etm_results['coh_rank'] = etm_results.groupby(\"input_dir\")[coherence_measure].rank(pct=True, ascending=False)\n",
    "pd.set_option('display.float_format', lambda x: '%.8f' % x)\n",
    "\n",
    "\n",
    "etm_config_keys = [k for k in etm_config_keys if k != \"data_path\"]\n",
    "(\n",
    "    pd.melt(etm_results, id_vars=['path', coherence_measure, 'to', 'coh_rank'], value_vars=etm_config_keys)\n",
    "      .groupby([\"variable\", \"value\"])[[\"coh_rank\", coherence_measure]]\n",
    "      .mean()\n",
    "      .sort_values(\"coh_rank\")\n",
    ")"
   ]
  },
  {
   "source": [
    "## Synthetic bad topics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "First, get topics from every run, then eliminate topics that are too close to ones seen in the top"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "100%|██████████| 8100/8100 [00:07<00:00, 1050.95it/s]\n",
      "100%|██████████| 8300/8300 [00:07<00:00, 1099.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "print('', flush=True) # can help a broken tqdm\n",
    "def jaccard(i, j):\n",
    "    i, j = set(i), set(j)\n",
    "    return len(i & j) / len(i | j)\n",
    "\n",
    "def retain_topic(topic, topics_to_compare, top_n=50, threshold=0.1):\n",
    "    k = len(topics)\n",
    "    dists = np.array([\n",
    "        jaccard(topic[:top_n], topic_j[:top_n])\n",
    "        for topic_j in topics_to_compare\n",
    "    ])\n",
    "    return np.all(dists < threshold)\n",
    "\n",
    "wikitext_topics = [\n",
    "    t\n",
    "    for topics in pd.concat([\n",
    "        mallet_results.loc[mallet_results.input_dir == \"wikitext\"].topics,\n",
    "        dvae_results.loc[dvae_results.input_dir == \"wikitext\"].topics\n",
    "    ])\n",
    "    for t in topics\n",
    "]\n",
    "\n",
    "top_wiki_topics = dvae_top_topics['wikitext']['topics'] + mallet_top_topics['wikitext']['topics']\n",
    "wikitext_topics = [t for t in tqdm(wikitext_topics) if retain_topic(t, top_wiki_topics)]\n",
    "\n",
    "nytimes_topics = [\n",
    "    t\n",
    "    for topics in pd.concat([\n",
    "        mallet_results.loc[mallet_results.input_dir == \"nytimes\"].topics,\n",
    "        dvae_results.loc[dvae_results.input_dir == \"nytimes\"].topics\n",
    "    ])\n",
    "    for t in topics\n",
    "]\n",
    "top_nyt_topics = dvae_top_topics['nytimes']['topics'] + mallet_top_topics['nytimes']['topics']\n",
    "nytimes_topics = [t for t in tqdm(nytimes_topics) if retain_topic(t, top_nyt_topics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_wikitext = Counter(\n",
    "    w\n",
    "    for topic in wikitext_topics\n",
    "    for w in topic\n",
    ")\n",
    "terms_nytimes = Counter(\n",
    "    w\n",
    "    for topic in nytimes_topics\n",
    "    for w in topic\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudoword_data = pd.read_csv(\"../human_evaluation/pwords.txt\", sep=\"\\s+\", names=[\"prob\", \"order\", \"pword\"])\n",
    "pseudoword_data = pseudoword_data.loc[pseudoword_data.prob <= np.quantile(pseudoword_data.prob, 0.25)]\n",
    "pseudowords = pseudoword_data.pword.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "n = 10\n",
    "num_topics = 8\n",
    "\n",
    "top_wiki_terms = [\n",
    "    t for t, c in terms_wikitext.most_common(n*num_topics*4) \n",
    "    if \"_\" not in t and len(t) > 3\n",
    "]\n",
    "top_nyt_terms = [\n",
    "    t for t, c in terms_nytimes.most_common(n*num_topics*4)\n",
    "    if \"_\" not in t and len(t) > 3\n",
    "]\n",
    "bad_topics = {\n",
    "    \"wikitext\": {\n",
    "        \"in_vocab\": [\n",
    "            random.sample(top_wiki_terms, n)\n",
    "            for i in range(num_topics)\n",
    "        ],\n",
    "        \"pseudo_word\": [\n",
    "            random.sample(random.sample(wikitext_topics[i],n//2) + random.sample(pseudowords,n//2),n)\n",
    "            for i in range(num_topics)\n",
    "        ],\n",
    "    },\n",
    "    \"nytimes\": {\n",
    "        \"in_vocab\": [\n",
    "            random.sample(top_nyt_terms, n)\n",
    "            for i in range(num_topics)\n",
    "        ],\n",
    "        \"pseudo_word\": [\n",
    "            random.sample(random.sample(nytimes_topics[i*3],n//2) + random.sample(pseudowords,n//2),n)\n",
    "            for i in range(num_topics)\n",
    "        ],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_topics[\"wikitext\"].pop(\"pseudo_word\")\n",
    "bad_topics[\"nytimes\"].pop(\"pseudo_word\")\n",
    "save_json(bad_topics, f\"{out_path}/bad_topics.json\")"
   ]
  },
  {
   "source": [
    "## Tables for Paper"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Table 1 (Examples)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"wikitext\"\n",
    "mallet_top_coh_topics = pd.DataFrame({\n",
    "    \"topics\": mallet_top_coh.loc[mallet_top_coh.input_dir == dataset][\"topics\"].values[0],\n",
    "    \"coherences\": mallet_top_coh.loc[mallet_top_coh.input_dir == dataset][f\"{coherence_measure}_top5_all\"].values[0]\n",
    "}).sort_values(\"coherences\", ascending=False)\n",
    "\n",
    "dvae_top_coh_topics = pd.DataFrame({\n",
    "    \"topics\": dvae_top_coh.loc[dvae_top_coh.input_dir == dataset][\"topics\"].values[0],\n",
    "    \"coherences\": dvae_top_coh.loc[dvae_top_coh.input_dir == dataset][f\"{coherence_measure}_top5_all\"].values[0]\n",
    "}).sort_values(\"coherences\", ascending=False)"
   ]
  },
  {
   "source": [
    "for idx, row in mallet_top_coh_topics.head(10).iterrows():\n",
    "    print(f\"{idx:3} | {row['coherences']:0.3f} |\", \" \".join(row.topics[:5]))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 37 | 0.394 | tropical storm hurricane cyclone depression\n 16 | 0.285 | album band music song released\n 20 | 0.274 | station line bridge railway trains\n  8 | 0.250 | route highway road state north\n  1 | 0.248 | species birds males females bird\n 12 | 0.247 | arab muslim israel egypt jewish\n 32 | 0.244 | season game team games league\n 39 | 0.241 | storm damage hurricane people winds\n  4 | 0.231 | club season team cup match\n 27 | 0.222 | episode homer season series simpsons\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  4 | 0.470 | manhattan_project los_alamos_laboratory robert_oppenheimer enrico_fermi physicist\n 41 | 0.456 | spore basidia spores mycologist hyphae\n 42 | 0.449 | touchdowns quarterback touchdown yards offense\n 33 | 0.446 | tropical landfall cyclone utc weakening\n 45 | 0.426 | mint numismatic obverse coin coins\n 26 | 0.399 | episode dana_scully robert_shearman gillian_anderson fox_mulder\n  9 | 0.386 | nhl national_hockey_league playoffs american_hockey_league hockey\n 15 | 0.385 | landfall gusts flooding hurricane winds\n 20 | 0.369 | waterline conning turrets boilers amidships\n 49 | 0.343 | gameplay gamespot graphics game multiplayer\n"
     ]
    }
   ],
   "source": [
    "for idx, row in dvae_top_coh_topics.head(10).iterrows():\n",
    "    print(f\"{idx:3} | {row['coherences']:0.3f} |\", \" \".join(row.topics[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect the \n",
    "high_npmi_examples = [\n",
    "    mallet_top_coh_topics.loc[16],\n",
    "    mallet_top_coh_topics.loc[37],\n",
    "    dvae_top_coh_topics.loc[33],\n",
    "    dvae_top_coh_topics.loc[41],\n",
    "    dvae_top_coh_topics.loc[4],\n",
    "]\n",
    "\n",
    "# row values\n",
    "npmis = [t.coherences for t in high_npmi_examples]\n",
    "words = list(zip(*[t.topics[:5] for t in high_npmi_examples]))\n",
    "# make sure nothing screwy happened\n",
    "assert(words[0] == (\"album\", \"tropical\", \"tropical\", \"spore\", \"manhattan_project\"))\n",
    "\n",
    "# make the rows\n",
    "npmi_row = \" & \".join(f\"{n:0.3f}\" for n in npmis) + r\" \\\\\"\n",
    "word_rows = \"\\\\\\\\ \\n \".join(\" & \".join([f\"{w:21}\".replace(\"_\", r\"\\_\") for w in row]) for row in words) + r\"\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "album                 & tropical              & tropical              & spore                 & manhattan\\_project    \\\\ \n band                  & storm                 & landfall              & basidia               & los\\_alamos\\_laboratory\\\\ \n music                 & hurricane             & cyclone               & spores                & robert\\_oppenheimer   \\\\ \n song                  & cyclone               & utc                   & mycologist            & enrico\\_fermi         \\\\ \n released              & depression            & weakening             & hyphae                & physicist            \\\\\n\\midrule\n0.285 & 0.394 & 0.446 & 0.456 & 0.470 \\\\\n"
     ]
    }
   ],
   "source": [
    "print(word_rows)\n",
    "print(r\"\\midrule\")\n",
    "print(npmi_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mean NPMIs @ 5\nmallet: 0.156 dvae: 0.256\n"
     ]
    }
   ],
   "source": [
    "print(\"mean NPMIs @ 5\")\n",
    "print(f\"mallet: {mallet_top_coh_topics.coherences.mean():0.3f} dvae: {dvae_top_coh_topics.coherences.mean():0.3f}\")"
   ]
  },
  {
   "source": [
    "### Stats on variation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.09071832404845975"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "dvae_results[coherence_measure].quantile(0.75) - dvae_results[coherence_measure].quantile(0.25)"
   ]
  },
  {
   "source": [
    "## Good example topics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'brushwork\", \"canvases\", \"expressionism\", \"cubism\", \"museum_of_fine_arts\", \"cubist\", \"lifes\", \"national_gallery_of_art\", \"sotheby\", \"curators\", \"reliefs\", \"abstract_expressionism\", \"frank_stella\", \"whitney_museum_of_american_art\", \"glueck\", \"national_gallery\", \"donald_judd\", \"sculptural\", \"impressionists\", \"jasper_johns\", \"biomorphic\", \"paleontologists\", \"modernism\", \"impressionism\", \"curatorial\", \"sculptures\", \"portraiture\", \"antiquities\", \"expressionist\", \"gestural\", \"painterly\", \"manet\", \"modernist\", \"etchings\", \"paintings\", \"geometric\", \"figuration\", \"motifs\", \"rohe\", \"archeologists\", \"cindy_sherman\", \"kooning\", \"bronzes\", \"surrealist\", \"printmaking\", \"inlaid\", \"degas\", \"calligraphic\", \"fossils\", \"glazes'"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "'\", \"'.join(nytimes_topics[0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}